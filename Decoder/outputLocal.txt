[0;32m========================================[0m
[0;32mSentence Splitting - 7 Strategies[0m
[0;32m========================================[0m

[1;33mChecking CUDA...[0m
CUDA: True, Device: NVIDIA RTX A4500

[0;32mRunning ALL strategies with LOCAL models on dev+ood[0m
`torch_dtype` is deprecated! Use `dtype` instead!
Running strategies: [1, 2, 3, 4, 5, 6, 7]
Models: ['llama-3.1-1b', 'llama-3.1-3b']
Datasets: ['dev', 'ood']

============================================================
[1/28] Strategy 1 (sliding_window) - llama-3.1-1b - dev
============================================================

Strategy 1: Sliding Window Binary Classification
Model: llama-3.1-1b
Dataset: dev (9343 tokens)
  Found 626 punctuation marks to classify
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Classifying:   0%|          | 0/40 [00:00<?, ?it/s]Classifying:   2%|â–Ž         | 1/40 [00:00<00:22,  1.74it/s]Classifying:   5%|â–Œ         | 2/40 [00:00<00:12,  3.15it/s]Classifying:   8%|â–Š         | 3/40 [00:00<00:08,  4.25it/s]Classifying:  10%|â–ˆ         | 4/40 [00:00<00:07,  5.08it/s]Classifying:  12%|â–ˆâ–Ž        | 5/40 [00:01<00:06,  5.70it/s]Classifying:  15%|â–ˆâ–Œ        | 6/40 [00:01<00:05,  6.12it/s]Classifying:  18%|â–ˆâ–Š        | 7/40 [00:01<00:05,  6.45it/s]Classifying:  20%|â–ˆâ–ˆ        | 8/40 [00:01<00:04,  6.77it/s]Classifying:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:01<00:04,  6.92it/s]Classifying:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:01<00:04,  7.00it/s]Classifying:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:01<00:04,  7.01it/s]Classifying:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:02<00:03,  7.06it/s]Classifying:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:02<00:03,  7.22it/s]Classifying:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:02<00:03,  7.25it/s]Classifying:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:02<00:03,  7.26it/s]Classifying:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:02<00:03,  7.28it/s]Classifying:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:02<00:03,  7.31it/s]Classifying:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:02<00:03,  7.30it/s]Classifying:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:03<00:02,  7.30it/s]Classifying:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:03<00:02,  7.38it/s]Classifying:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:03<00:02,  7.35it/s]Classifying:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:03<00:02,  7.34it/s]Classifying:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:03<00:02,  7.34it/s]Classifying:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:03<00:02,  7.42it/s]Classifying:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:03<00:02,  7.38it/s]Classifying:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:03<00:01,  7.33it/s]Classifying:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:04<00:01,  7.27it/s]Classifying:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:04<00:01,  7.27it/s]Classifying:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:04<00:01,  7.24it/s]Classifying:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:04<00:01,  7.33it/s]Classifying:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:04<00:01,  7.40it/s]Classifying:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:04<00:01,  7.45it/s]Classifying:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:04<00:00,  7.51it/s]Classifying:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:05<00:00,  7.46it/s]Classifying:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:05<00:00,  7.40it/s]Classifying:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:05<00:00,  7.46it/s]Classifying:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:05<00:00,  7.42it/s]Classifying:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:05<00:00,  7.33it/s]Classifying:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:05<00:00,  7.26it/s]Classifying: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:05<00:00,  6.91it/s]

============================================================
Results for llama-3.1-1b with strategy_1
============================================================
Accuracy:  0.9653
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  9019      0
  Actual 1:   324      0
============================================================

Saved predictions to /workspace/results/dev/sliding_window_1/llama_3.1_1b.csv

============================================================
[2/28] Strategy 1 (sliding_window) - llama-3.1-1b - ood
============================================================

Strategy 1: Sliding Window Binary Classification
Model: llama-3.1-1b
Dataset: ood (1522 tokens)
  Found 128 punctuation marks to classify
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Classifying:   0%|          | 0/8 [00:00<?, ?it/s]Classifying:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:00,  7.18it/s]Classifying:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:00,  7.16it/s]Classifying:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00,  7.23it/s]Classifying:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:00<00:00,  7.17it/s]Classifying:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00,  7.15it/s]Classifying:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:00<00:00,  7.13it/s]Classifying:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00,  7.18it/s]Classifying: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.19it/s]Classifying: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.17it/s]

============================================================
Results for llama-3.1-1b with strategy_1
============================================================
Accuracy:  0.9369
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1426      0
  Actual 1:    96      0
============================================================

Saved predictions to /workspace/results/ood/sliding_window_1/llama_3.1_1b.csv

============================================================
[3/28] Strategy 1 (sliding_window) - llama-3.1-3b - dev
============================================================

Strategy 1: Sliding Window Binary Classification
Model: llama-3.1-3b
Dataset: dev (9343 tokens)
  Found 626 punctuation marks to classify
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.72it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.93it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.65it/s]
Model compiled with torch.compile
Model loaded successfully
Classifying:   0%|          | 0/40 [00:00<?, ?it/s]Classifying:   2%|â–Ž         | 1/40 [00:00<00:14,  2.73it/s]Classifying:   5%|â–Œ         | 2/40 [00:00<00:13,  2.72it/s]Classifying:   8%|â–Š         | 3/40 [00:01<00:13,  2.72it/s]Classifying:  10%|â–ˆ         | 4/40 [00:01<00:13,  2.72it/s]Classifying:  12%|â–ˆâ–Ž        | 5/40 [00:01<00:12,  2.72it/s]Classifying:  15%|â–ˆâ–Œ        | 6/40 [00:02<00:12,  2.72it/s]Classifying:  18%|â–ˆâ–Š        | 7/40 [00:02<00:12,  2.71it/s]Classifying:  20%|â–ˆâ–ˆ        | 8/40 [00:02<00:11,  2.75it/s]Classifying:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:03<00:11,  2.74it/s]Classifying:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:03<00:10,  2.73it/s]Classifying:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:04<00:10,  2.72it/s]Classifying:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:04<00:10,  2.72it/s]Classifying:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:04<00:09,  2.76it/s]Classifying:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:05<00:09,  2.76it/s]Classifying:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:05<00:09,  2.75it/s]Classifying:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:05<00:08,  2.75it/s]Classifying:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:06<00:08,  2.75it/s]Classifying:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:06<00:08,  2.75it/s]Classifying:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:06<00:07,  2.74it/s]Classifying:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:07<00:07,  2.78it/s]Classifying:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:07<00:06,  2.76it/s]Classifying:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:08<00:06,  2.76it/s]Classifying:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:08<00:06,  2.76it/s]Classifying:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:08<00:05,  2.79it/s]Classifying:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:09<00:05,  2.77it/s]Classifying:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:09<00:05,  2.76it/s]Classifying:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:09<00:04,  2.74it/s]Classifying:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:10<00:04,  2.74it/s]Classifying:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:10<00:04,  2.74it/s]Classifying:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:10<00:03,  2.77it/s]Classifying:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:11<00:03,  2.79it/s]Classifying:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:11<00:02,  2.81it/s]Classifying:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:11<00:02,  2.82it/s]Classifying:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:12<00:02,  2.80it/s]Classifying:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:12<00:01,  2.78it/s]Classifying:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:13<00:01,  2.80it/s]Classifying:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:13<00:01,  2.78it/s]Classifying:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:13<00:00,  2.75it/s]Classifying:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:14<00:00,  2.73it/s]Classifying: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.81it/s]

============================================================
Results for llama-3.1-3b with strategy_1
============================================================
Accuracy:  0.9653
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  9019      0
  Actual 1:   324      0
============================================================

Saved predictions to /workspace/results/dev/sliding_window_1/llama_3.1_3b.csv

============================================================
[4/28] Strategy 1 (sliding_window) - llama-3.1-3b - ood
============================================================

Strategy 1: Sliding Window Binary Classification
Model: llama-3.1-3b
Dataset: ood (1522 tokens)
  Found 128 punctuation marks to classify
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.74it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.96it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.68it/s]
Model compiled with torch.compile
Model loaded successfully
Classifying:   0%|          | 0/8 [00:00<?, ?it/s]Classifying:  12%|â–ˆâ–Ž        | 1/8 [00:00<00:02,  2.74it/s]Classifying:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:00<00:02,  2.72it/s]Classifying:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:01<00:01,  2.72it/s]Classifying:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:01<00:01,  2.71it/s]Classifying:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:01<00:01,  2.70it/s]Classifying:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:02<00:00,  2.70it/s]Classifying:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:02<00:00,  2.70it/s]Classifying: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.70it/s]Classifying: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  2.71it/s]

============================================================
Results for llama-3.1-3b with strategy_1
============================================================
Accuracy:  0.9369
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1426      0
  Actual 1:    96      0
============================================================

Saved predictions to /workspace/results/ood/sliding_window_1/llama_3.1_3b.csv

============================================================
[5/28] Strategy 2 (next_token_prob) - llama-3.1-1b - dev
============================================================

Strategy 2: Next-Token Probability Analysis
Model: llama-3.1-1b
Dataset: dev (9343 tokens)
Threshold: 0.15
  Found 626 punctuation marks to analyze
  Loading model: meta-llama/Llama-3.2-1B-Instruct
Analyzing probabilities:   0%|          | 0/626 [00:00<?, ?it/s]Analyzing probabilities:   1%|â–         | 9/626 [00:00<00:07, 83.12it/s]Analyzing probabilities:   3%|â–Ž         | 18/626 [00:00<00:07, 86.75it/s]Analyzing probabilities:   4%|â–         | 27/626 [00:00<00:06, 87.89it/s]Analyzing probabilities:   6%|â–Œ         | 36/626 [00:00<00:06, 88.64it/s]Analyzing probabilities:   7%|â–‹         | 45/626 [00:00<00:06, 89.12it/s]Analyzing probabilities:   9%|â–Š         | 54/626 [00:00<00:06, 89.18it/s]Analyzing probabilities:  10%|â–ˆ         | 63/626 [00:00<00:06, 89.29it/s]Analyzing probabilities:  12%|â–ˆâ–        | 72/626 [00:00<00:06, 89.41it/s]Analyzing probabilities:  13%|â–ˆâ–Ž        | 81/626 [00:00<00:06, 89.35it/s]Analyzing probabilities:  14%|â–ˆâ–        | 90/626 [00:01<00:06, 89.15it/s]Analyzing probabilities:  16%|â–ˆâ–Œ        | 99/626 [00:01<00:05, 89.15it/s]Analyzing probabilities:  17%|â–ˆâ–‹        | 108/626 [00:01<00:05, 89.35it/s]Analyzing probabilities:  19%|â–ˆâ–‰        | 118/626 [00:01<00:05, 89.67it/s]Analyzing probabilities:  20%|â–ˆâ–ˆ        | 128/626 [00:01<00:05, 89.81it/s]Analyzing probabilities:  22%|â–ˆâ–ˆâ–       | 137/626 [00:01<00:05, 89.61it/s]Analyzing probabilities:  23%|â–ˆâ–ˆâ–Ž       | 146/626 [00:01<00:05, 89.31it/s]Analyzing probabilities:  25%|â–ˆâ–ˆâ–       | 155/626 [00:01<00:05, 88.91it/s]Analyzing probabilities:  26%|â–ˆâ–ˆâ–Œ       | 164/626 [00:01<00:05, 88.32it/s]Analyzing probabilities:  28%|â–ˆâ–ˆâ–Š       | 173/626 [00:01<00:05, 88.10it/s]Analyzing probabilities:  29%|â–ˆâ–ˆâ–‰       | 182/626 [00:02<00:05, 85.83it/s]Analyzing probabilities:  31%|â–ˆâ–ˆâ–ˆ       | 191/626 [00:02<00:05, 84.35it/s]Analyzing probabilities:  32%|â–ˆâ–ˆâ–ˆâ–      | 201/626 [00:02<00:04, 86.42it/s]Analyzing probabilities:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 210/626 [00:02<00:04, 86.70it/s]Analyzing probabilities:  35%|â–ˆâ–ˆâ–ˆâ–      | 219/626 [00:02<00:04, 85.82it/s]Analyzing probabilities:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 228/626 [00:02<00:04, 83.93it/s]Analyzing probabilities:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 237/626 [00:02<00:04, 85.19it/s]Analyzing probabilities:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 246/626 [00:02<00:04, 86.23it/s]Analyzing probabilities:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 255/626 [00:02<00:04, 86.44it/s]Analyzing probabilities:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 264/626 [00:03<00:04, 86.50it/s]Analyzing probabilities:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 273/626 [00:03<00:04, 85.93it/s]Analyzing probabilities:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 282/626 [00:03<00:03, 86.99it/s]Analyzing probabilities:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 291/626 [00:03<00:03, 85.03it/s]Analyzing probabilities:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 300/626 [00:03<00:03, 82.15it/s]Analyzing probabilities:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 309/626 [00:03<00:03, 82.16it/s]Analyzing probabilities:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 318/626 [00:03<00:03, 83.21it/s]Analyzing probabilities:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 327/626 [00:03<00:03, 84.15it/s]Analyzing probabilities:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 336/626 [00:03<00:03, 84.52it/s]Analyzing probabilities:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 345/626 [00:03<00:03, 84.99it/s]Analyzing probabilities:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 354/626 [00:04<00:03, 84.86it/s]Analyzing probabilities:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 363/626 [00:04<00:03, 85.20it/s]Analyzing probabilities:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 373/626 [00:04<00:02, 87.85it/s]Analyzing probabilities:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 382/626 [00:04<00:02, 87.35it/s]Analyzing probabilities:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 391/626 [00:04<00:02, 87.13it/s]Analyzing probabilities:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 400/626 [00:04<00:02, 86.76it/s]Analyzing probabilities:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 409/626 [00:04<00:02, 86.47it/s]Analyzing probabilities:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 418/626 [00:04<00:02, 86.67it/s]Analyzing probabilities:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 427/626 [00:04<00:02, 86.46it/s]Analyzing probabilities:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 436/626 [00:05<00:02, 86.39it/s]Analyzing probabilities:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 445/626 [00:05<00:02, 86.52it/s]Analyzing probabilities:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 454/626 [00:05<00:01, 86.54it/s]Analyzing probabilities:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 463/626 [00:05<00:01, 86.49it/s]Analyzing probabilities:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 473/626 [00:05<00:01, 90.16it/s]Analyzing probabilities:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 483/626 [00:05<00:01, 88.97it/s]Analyzing probabilities:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 492/626 [00:05<00:01, 88.76it/s]Analyzing probabilities:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 501/626 [00:05<00:01, 87.77it/s]Analyzing probabilities:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 510/626 [00:05<00:01, 87.68it/s]Analyzing probabilities:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 520/626 [00:05<00:01, 88.58it/s]Analyzing probabilities:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 529/626 [00:06<00:01, 88.29it/s]Analyzing probabilities:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 538/626 [00:06<00:01, 87.79it/s]Analyzing probabilities:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 547/626 [00:06<00:00, 87.20it/s]Analyzing probabilities:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 556/626 [00:06<00:00, 87.11it/s]Analyzing probabilities:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 565/626 [00:06<00:00, 86.72it/s]Analyzing probabilities:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 574/626 [00:06<00:00, 86.64it/s]Analyzing probabilities:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 583/626 [00:06<00:00, 86.31it/s]Analyzing probabilities:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 592/626 [00:06<00:00, 86.49it/s]Analyzing probabilities:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 601/626 [00:06<00:00, 86.48it/s]Analyzing probabilities:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 610/626 [00:07<00:00, 85.97it/s]Analyzing probabilities:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 619/626 [00:07<00:00, 86.01it/s]Analyzing probabilities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 626/626 [00:07<00:00, 86.85it/s]
  Score stats: min=0.0002, max=0.0626, mean=0.0079

============================================================
Results for llama-3.1-1b with strategy_2
============================================================
Accuracy:  0.9653
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  9019      0
  Actual 1:   324      0
============================================================

Saved predictions to /workspace/results/dev/next_token_prob_2/llama_3.1_1b.csv

============================================================
[6/28] Strategy 2 (next_token_prob) - llama-3.1-1b - ood
============================================================

Strategy 2: Next-Token Probability Analysis
Model: llama-3.1-1b
Dataset: ood (1522 tokens)
Threshold: 0.15
  Found 128 punctuation marks to analyze
  Loading model: meta-llama/Llama-3.2-1B-Instruct
Analyzing probabilities:   0%|          | 0/128 [00:00<?, ?it/s]Analyzing probabilities:   7%|â–‹         | 9/128 [00:00<00:01, 81.70it/s]Analyzing probabilities:  14%|â–ˆâ–        | 18/128 [00:00<00:01, 83.31it/s]Analyzing probabilities:  21%|â–ˆâ–ˆ        | 27/128 [00:00<00:01, 83.91it/s]Analyzing probabilities:  28%|â–ˆâ–ˆâ–Š       | 36/128 [00:00<00:01, 82.29it/s]Analyzing probabilities:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [00:00<00:01, 82.23it/s]Analyzing probabilities:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [00:00<00:00, 82.58it/s]Analyzing probabilities:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 63/128 [00:00<00:00, 83.76it/s]Analyzing probabilities:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 72/128 [00:00<00:00, 84.17it/s]Analyzing probabilities:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 81/128 [00:00<00:00, 84.83it/s]Analyzing probabilities:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [00:01<00:00, 85.08it/s]Analyzing probabilities:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 99/128 [00:01<00:00, 85.40it/s]Analyzing probabilities:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 108/128 [00:01<00:00, 85.21it/s]Analyzing probabilities:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:01<00:00, 85.91it/s]Analyzing probabilities:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [00:01<00:00, 86.16it/s]Analyzing probabilities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:01<00:00, 84.47it/s]
  Score stats: min=0.0002, max=0.0789, mean=0.0097

============================================================
Results for llama-3.1-1b with strategy_2
============================================================
Accuracy:  0.9369
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1426      0
  Actual 1:    96      0
============================================================

Saved predictions to /workspace/results/ood/next_token_prob_2/llama_3.1_1b.csv

============================================================
[7/28] Strategy 2 (next_token_prob) - llama-3.1-3b - dev
============================================================

Strategy 2: Next-Token Probability Analysis
Model: llama-3.1-3b
Dataset: dev (9343 tokens)
Threshold: 0.15
  Found 626 punctuation marks to analyze
  Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.56it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.67it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.41it/s]
Analyzing probabilities:   0%|          | 0/626 [00:00<?, ?it/s]Analyzing probabilities:   1%|          | 5/626 [00:00<00:13, 44.74it/s]Analyzing probabilities:   2%|â–         | 10/626 [00:00<00:13, 44.88it/s]Analyzing probabilities:   2%|â–         | 15/626 [00:00<00:13, 44.49it/s]Analyzing probabilities:   3%|â–Ž         | 20/626 [00:00<00:13, 45.36it/s]Analyzing probabilities:   4%|â–         | 25/626 [00:00<00:13, 45.34it/s]Analyzing probabilities:   5%|â–         | 30/626 [00:00<00:13, 45.27it/s]Analyzing probabilities:   6%|â–Œ         | 35/626 [00:00<00:13, 44.86it/s]Analyzing probabilities:   6%|â–‹         | 40/626 [00:00<00:13, 44.74it/s]Analyzing probabilities:   7%|â–‹         | 45/626 [00:01<00:13, 44.50it/s]Analyzing probabilities:   8%|â–Š         | 50/626 [00:01<00:12, 44.76it/s]Analyzing probabilities:   9%|â–‰         | 55/626 [00:01<00:12, 45.11it/s]Analyzing probabilities:  10%|â–‰         | 60/626 [00:01<00:12, 45.05it/s]Analyzing probabilities:  10%|â–ˆ         | 65/626 [00:01<00:12, 44.87it/s]Analyzing probabilities:  11%|â–ˆ         | 70/626 [00:01<00:12, 44.70it/s]Analyzing probabilities:  12%|â–ˆâ–        | 75/626 [00:01<00:12, 44.99it/s]Analyzing probabilities:  13%|â–ˆâ–Ž        | 80/626 [00:01<00:12, 45.48it/s]Analyzing probabilities:  14%|â–ˆâ–Ž        | 85/626 [00:01<00:11, 45.74it/s]Analyzing probabilities:  14%|â–ˆâ–        | 90/626 [00:01<00:11, 46.08it/s]Analyzing probabilities:  15%|â–ˆâ–Œ        | 95/626 [00:02<00:11, 45.71it/s]Analyzing probabilities:  16%|â–ˆâ–Œ        | 100/626 [00:02<00:11, 45.49it/s]Analyzing probabilities:  17%|â–ˆâ–‹        | 105/626 [00:02<00:11, 45.07it/s]Analyzing probabilities:  18%|â–ˆâ–Š        | 110/626 [00:02<00:11, 44.90it/s]Analyzing probabilities:  18%|â–ˆâ–Š        | 115/626 [00:02<00:11, 44.37it/s]Analyzing probabilities:  19%|â–ˆâ–‰        | 120/626 [00:02<00:11, 44.45it/s]Analyzing probabilities:  20%|â–ˆâ–‰        | 125/626 [00:02<00:11, 44.18it/s]Analyzing probabilities:  21%|â–ˆâ–ˆ        | 130/626 [00:02<00:11, 44.58it/s]Analyzing probabilities:  22%|â–ˆâ–ˆâ–       | 135/626 [00:03<00:10, 44.70it/s]Analyzing probabilities:  22%|â–ˆâ–ˆâ–       | 140/626 [00:03<00:10, 45.02it/s]Analyzing probabilities:  23%|â–ˆâ–ˆâ–Ž       | 145/626 [00:03<00:10, 44.66it/s]Analyzing probabilities:  24%|â–ˆâ–ˆâ–       | 150/626 [00:03<00:10, 45.25it/s]Analyzing probabilities:  25%|â–ˆâ–ˆâ–       | 155/626 [00:03<00:10, 45.11it/s]Analyzing probabilities:  26%|â–ˆâ–ˆâ–Œ       | 160/626 [00:03<00:10, 44.73it/s]Analyzing probabilities:  26%|â–ˆâ–ˆâ–‹       | 165/626 [00:03<00:10, 44.66it/s]Analyzing probabilities:  27%|â–ˆâ–ˆâ–‹       | 170/626 [00:03<00:10, 45.43it/s]Analyzing probabilities:  28%|â–ˆâ–ˆâ–Š       | 175/626 [00:03<00:09, 45.20it/s]Analyzing probabilities:  29%|â–ˆâ–ˆâ–‰       | 180/626 [00:04<00:09, 44.87it/s]Analyzing probabilities:  30%|â–ˆâ–ˆâ–‰       | 185/626 [00:04<00:09, 45.27it/s]Analyzing probabilities:  30%|â–ˆâ–ˆâ–ˆ       | 190/626 [00:04<00:09, 45.08it/s]Analyzing probabilities:  31%|â–ˆâ–ˆâ–ˆ       | 195/626 [00:04<00:09, 44.74it/s]Analyzing probabilities:  32%|â–ˆâ–ˆâ–ˆâ–      | 200/626 [00:04<00:09, 44.50it/s]Analyzing probabilities:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 205/626 [00:04<00:09, 44.28it/s]Analyzing probabilities:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 210/626 [00:04<00:09, 44.34it/s]Analyzing probabilities:  34%|â–ˆâ–ˆâ–ˆâ–      | 215/626 [00:04<00:09, 44.13it/s]Analyzing probabilities:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 220/626 [00:04<00:09, 44.04it/s]Analyzing probabilities:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 225/626 [00:05<00:09, 44.43it/s]Analyzing probabilities:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 230/626 [00:05<00:08, 44.26it/s]Analyzing probabilities:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 235/626 [00:05<00:08, 44.64it/s]Analyzing probabilities:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 240/626 [00:05<00:08, 45.09it/s]Analyzing probabilities:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 245/626 [00:05<00:08, 44.92it/s]Analyzing probabilities:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 250/626 [00:05<00:08, 44.67it/s]Analyzing probabilities:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 255/626 [00:05<00:08, 44.71it/s]Analyzing probabilities:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 260/626 [00:05<00:08, 44.86it/s]Analyzing probabilities:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 265/626 [00:05<00:08, 44.48it/s]Analyzing probabilities:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 270/626 [00:06<00:08, 44.06it/s]Analyzing probabilities:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 275/626 [00:06<00:08, 43.85it/s]Analyzing probabilities:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 280/626 [00:06<00:07, 43.67it/s]Analyzing probabilities:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 285/626 [00:06<00:07, 44.08it/s]Analyzing probabilities:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 290/626 [00:06<00:07, 44.01it/s]Analyzing probabilities:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 295/626 [00:06<00:07, 44.15it/s]Analyzing probabilities:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 300/626 [00:06<00:07, 44.51it/s]Analyzing probabilities:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 305/626 [00:06<00:07, 44.31it/s]Analyzing probabilities:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 310/626 [00:06<00:07, 44.27it/s]Analyzing probabilities:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 315/626 [00:07<00:07, 44.09it/s]Analyzing probabilities:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 320/626 [00:07<00:06, 43.96it/s]Analyzing probabilities:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 325/626 [00:07<00:06, 44.19it/s]Analyzing probabilities:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 330/626 [00:07<00:06, 44.11it/s]Analyzing probabilities:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 335/626 [00:07<00:06, 44.25it/s]Analyzing probabilities:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 340/626 [00:07<00:06, 44.11it/s]Analyzing probabilities:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 345/626 [00:07<00:06, 43.93it/s]Analyzing probabilities:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 350/626 [00:07<00:06, 44.03it/s]Analyzing probabilities:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 355/626 [00:07<00:06, 44.09it/s]Analyzing probabilities:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 360/626 [00:08<00:06, 43.78it/s]Analyzing probabilities:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 365/626 [00:08<00:05, 43.74it/s]Analyzing probabilities:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 370/626 [00:08<00:05, 44.34it/s]Analyzing probabilities:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 375/626 [00:08<00:05, 44.94it/s]Analyzing probabilities:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 380/626 [00:08<00:05, 44.56it/s]Analyzing probabilities:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 385/626 [00:08<00:05, 44.24it/s]Analyzing probabilities:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 390/626 [00:08<00:05, 44.20it/s]Analyzing probabilities:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 395/626 [00:08<00:05, 43.77it/s]Analyzing probabilities:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 400/626 [00:08<00:05, 43.86it/s]Analyzing probabilities:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 405/626 [00:09<00:04, 44.52it/s]Analyzing probabilities:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 410/626 [00:09<00:04, 44.46it/s]Analyzing probabilities:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 415/626 [00:09<00:04, 44.71it/s]Analyzing probabilities:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 420/626 [00:09<00:04, 44.76it/s]Analyzing probabilities:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 425/626 [00:09<00:04, 44.81it/s]Analyzing probabilities:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 430/626 [00:09<00:04, 44.42it/s]Analyzing probabilities:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 435/626 [00:09<00:04, 44.82it/s]Analyzing probabilities:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 440/626 [00:09<00:04, 44.26it/s]Analyzing probabilities:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 445/626 [00:09<00:04, 43.82it/s]Analyzing probabilities:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 450/626 [00:10<00:04, 43.90it/s]Analyzing probabilities:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 455/626 [00:10<00:03, 43.94it/s]Analyzing probabilities:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 460/626 [00:10<00:03, 44.20it/s]Analyzing probabilities:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 465/626 [00:10<00:03, 44.34it/s]Analyzing probabilities:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 470/626 [00:10<00:03, 45.47it/s]Analyzing probabilities:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 475/626 [00:10<00:03, 45.57it/s]Analyzing probabilities:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 480/626 [00:10<00:03, 45.10it/s]Analyzing probabilities:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 485/626 [00:10<00:03, 44.84it/s]Analyzing probabilities:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 490/626 [00:10<00:03, 44.53it/s]Analyzing probabilities:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 495/626 [00:11<00:02, 44.44it/s]Analyzing probabilities:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 500/626 [00:11<00:02, 44.31it/s]Analyzing probabilities:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 505/626 [00:11<00:02, 44.06it/s]Analyzing probabilities:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 510/626 [00:11<00:02, 43.99it/s]Analyzing probabilities:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 515/626 [00:11<00:02, 45.16it/s]Analyzing probabilities:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 520/626 [00:11<00:02, 44.94it/s]Analyzing probabilities:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 525/626 [00:11<00:02, 45.05it/s]Analyzing probabilities:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 530/626 [00:11<00:02, 44.90it/s]Analyzing probabilities:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 535/626 [00:11<00:02, 44.63it/s]Analyzing probabilities:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 540/626 [00:12<00:01, 44.28it/s]Analyzing probabilities:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 545/626 [00:12<00:01, 44.22it/s]Analyzing probabilities:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 550/626 [00:12<00:01, 44.09it/s]Analyzing probabilities:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 555/626 [00:12<00:01, 44.49it/s]Analyzing probabilities:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 560/626 [00:12<00:01, 45.15it/s]Analyzing probabilities:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 565/626 [00:12<00:01, 44.47it/s]Analyzing probabilities:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 570/626 [00:12<00:01, 44.30it/s]Analyzing probabilities:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 575/626 [00:12<00:01, 43.72it/s]Analyzing probabilities:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 580/626 [00:13<00:01, 43.89it/s]Analyzing probabilities:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 585/626 [00:13<00:00, 44.22it/s]Analyzing probabilities:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 590/626 [00:13<00:00, 44.34it/s]Analyzing probabilities:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 595/626 [00:13<00:00, 44.53it/s]Analyzing probabilities:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 600/626 [00:13<00:00, 45.07it/s]Analyzing probabilities:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 605/626 [00:13<00:00, 44.92it/s]Analyzing probabilities:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 610/626 [00:13<00:00, 45.03it/s]Analyzing probabilities:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 615/626 [00:13<00:00, 45.33it/s]Analyzing probabilities:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 620/626 [00:13<00:00, 44.99it/s]Analyzing probabilities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 625/626 [00:14<00:00, 44.72it/s]Analyzing probabilities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 626/626 [00:14<00:00, 44.59it/s]
  Score stats: min=0.0001, max=0.1157, mean=0.0059

============================================================
Results for llama-3.1-3b with strategy_2
============================================================
Accuracy:  0.9653
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  9019      0
  Actual 1:   324      0
============================================================

Saved predictions to /workspace/results/dev/next_token_prob_2/llama_3.1_3b.csv

============================================================
[8/28] Strategy 2 (next_token_prob) - llama-3.1-3b - ood
============================================================

Strategy 2: Next-Token Probability Analysis
Model: llama-3.1-3b
Dataset: ood (1522 tokens)
Threshold: 0.15
  Found 128 punctuation marks to analyze
  Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.50it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.60it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.34it/s]
Analyzing probabilities:   0%|          | 0/128 [00:00<?, ?it/s]Analyzing probabilities:   5%|â–         | 6/128 [00:00<00:02, 50.34it/s]Analyzing probabilities:   9%|â–‰         | 12/128 [00:00<00:02, 47.75it/s]Analyzing probabilities:  13%|â–ˆâ–Ž        | 17/128 [00:00<00:02, 46.52it/s]Analyzing probabilities:  17%|â–ˆâ–‹        | 22/128 [00:00<00:02, 44.01it/s]Analyzing probabilities:  21%|â–ˆâ–ˆ        | 27/128 [00:00<00:02, 44.26it/s]Analyzing probabilities:  25%|â–ˆâ–ˆâ–Œ       | 32/128 [00:00<00:02, 45.03it/s]Analyzing probabilities:  29%|â–ˆâ–ˆâ–‰       | 37/128 [00:00<00:02, 44.71it/s]Analyzing probabilities:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/128 [00:00<00:01, 44.72it/s]Analyzing probabilities:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 47/128 [00:01<00:01, 44.32it/s]Analyzing probabilities:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 52/128 [00:01<00:01, 44.49it/s]Analyzing probabilities:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [00:01<00:01, 44.44it/s]Analyzing probabilities:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [00:01<00:01, 44.57it/s]Analyzing probabilities:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/128 [00:01<00:01, 45.19it/s]Analyzing probabilities:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 72/128 [00:01<00:01, 44.98it/s]Analyzing probabilities:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [00:01<00:01, 45.30it/s]Analyzing probabilities:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [00:01<00:01, 45.14it/s]Analyzing probabilities:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 87/128 [00:01<00:00, 45.26it/s]Analyzing probabilities:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/128 [00:02<00:00, 44.75it/s]Analyzing probabilities:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [00:02<00:00, 45.27it/s]Analyzing probabilities:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [00:02<00:00, 45.10it/s]Analyzing probabilities:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 107/128 [00:02<00:00, 45.55it/s]Analyzing probabilities:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 112/128 [00:02<00:00, 45.06it/s]Analyzing probabilities:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [00:02<00:00, 44.68it/s]Analyzing probabilities:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [00:02<00:00, 44.41it/s]Analyzing probabilities:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 127/128 [00:02<00:00, 44.54it/s]Analyzing probabilities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:02<00:00, 44.98it/s]
  Score stats: min=0.0004, max=0.0350, mean=0.0047

============================================================
Results for llama-3.1-3b with strategy_2
============================================================
Accuracy:  0.9369
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1426      0
  Actual 1:    96      0
============================================================

Saved predictions to /workspace/results/ood/next_token_prob_2/llama_3.1_3b.csv

============================================================
[9/28] Strategy 3 (marker_insertion) - llama-3.1-1b - dev
============================================================

Strategy 3: Marker Insertion
Model: llama-3.1-1b
Dataset: dev (9343 tokens)
  Processing 47 chunks
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/6 [00:00<?, ?it/s]Generating:  17%|â–ˆâ–‹        | 1/6 [00:04<00:21,  4.29s/it]Generating:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:08<00:17,  4.37s/it]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:12<00:12,  4.31s/it]Generating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:16<00:08,  4.19s/it]Generating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:21<00:04,  4.16s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:25<00:00,  4.13s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:25<00:00,  4.19s/it]

============================================================
Results for llama-3.1-1b with strategy_3
============================================================
Accuracy:  0.9617
Precision: 0.2703
Recall:    0.0617
F1 Score:  0.1005

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  8965     54
  Actual 1:   304     20
============================================================

Saved predictions to /workspace/results/dev/marker_insertion_3/llama_3.1_1b.csv

============================================================
[10/28] Strategy 3 (marker_insertion) - llama-3.1-1b - ood
============================================================

Strategy 3: Marker Insertion
Model: llama-3.1-1b
Dataset: ood (1522 tokens)
  Processing 8 chunks
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/1 [00:00<?, ?it/s]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.42s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.42s/it]

============================================================
Results for llama-3.1-1b with strategy_3
============================================================
Accuracy:  0.9396
Precision: 1.0000
Recall:    0.0417
F1 Score:  0.0800

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1426      0
  Actual 1:    92      4
============================================================

Saved predictions to /workspace/results/ood/marker_insertion_3/llama_3.1_1b.csv

============================================================
[11/28] Strategy 3 (marker_insertion) - llama-3.1-3b - dev
============================================================

Strategy 3: Marker Insertion
Model: llama-3.1-3b
Dataset: dev (9343 tokens)
  Processing 47 chunks
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.71it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.93it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.65it/s]
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/6 [00:00<?, ?it/s]Generating:  17%|â–ˆâ–‹        | 1/6 [00:10<00:51, 10.35s/it]Generating:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:21<00:43, 10.91s/it]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:31<00:31, 10.59s/it]Generating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:42<00:20, 10.44s/it]Generating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:52<00:10, 10.41s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [01:07<00:00, 11.91s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [01:07<00:00, 11.21s/it]

============================================================
Results for llama-3.1-3b with strategy_3
============================================================
Accuracy:  0.9647
Precision: 0.4805
Recall:    0.2284
F1 Score:  0.3096

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  8939     80
  Actual 1:   250     74
============================================================

Saved predictions to /workspace/results/dev/marker_insertion_3/llama_3.1_3b.csv

============================================================
[12/28] Strategy 3 (marker_insertion) - llama-3.1-3b - ood
============================================================

Strategy 3: Marker Insertion
Model: llama-3.1-3b
Dataset: ood (1522 tokens)
  Processing 8 chunks
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.69it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.77it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.53it/s]
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/1 [00:00<?, ?it/s]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.13s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.13s/it]

============================================================
Results for llama-3.1-3b with strategy_3
============================================================
Accuracy:  0.9428
Precision: 0.9091
Recall:    0.1042
F1 Score:  0.1869

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1425      1
  Actual 1:    86     10
============================================================

Saved predictions to /workspace/results/ood/marker_insertion_3/llama_3.1_3b.csv

============================================================
[13/28] Strategy 4 (structured_json) - llama-3.1-1b - dev
============================================================

Strategy 4: Structured JSON Output
Model: llama-3.1-1b
Dataset: dev (9343 tokens)
Output format: JSON
  Processing 63 chunks (JSON mode: True)
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/8 [00:00<?, ?it/s]Generating:  12%|â–ˆâ–Ž        | 1/8 [00:06<00:45,  6.53s/it]Generating:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:13<00:39,  6.52s/it]Generating:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:19<00:32,  6.51s/it]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:26<00:26,  6.51s/it]Generating:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:32<00:19,  6.50s/it]Generating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:39<00:13,  6.51s/it]Generating:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:45<00:06,  6.48s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:51<00:00,  6.29s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:51<00:00,  6.42s/it]

============================================================
Results for llama-3.1-1b with strategy_4
============================================================
Accuracy:  0.2114
Precision: 0.0340
Recall:    0.7932
F1 Score:  0.0652

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1718   7301
  Actual 1:    67    257
============================================================

Saved predictions to /workspace/results/dev/structured_json_4/llama_3.1_1b.csv

============================================================
[14/28] Strategy 4 (structured_json) - llama-3.1-1b - ood
============================================================

Strategy 4: Structured JSON Output
Model: llama-3.1-1b
Dataset: ood (1522 tokens)
Output format: JSON
  Processing 11 chunks (JSON mode: True)
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/2 [00:00<?, ?it/s]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.52s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.29s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.48s/it]

============================================================
Results for llama-3.1-1b with strategy_4
============================================================
Accuracy:  0.1800
Precision: 0.0643
Recall:    0.8854
F1 Score:  0.1199

Confusion Matrix:
  Predicted:  0      1
  Actual 0:   189   1237
  Actual 1:    11     85
============================================================

Saved predictions to /workspace/results/ood/structured_json_4/llama_3.1_1b.csv

============================================================
[15/28] Strategy 4 (structured_json) - llama-3.1-3b - dev
============================================================

Strategy 4: Structured JSON Output
Model: llama-3.1-3b
Dataset: dev (9343 tokens)
Output format: JSON
  Processing 63 chunks (JSON mode: True)
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.71it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.93it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.65it/s]
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/8 [00:00<?, ?it/s]Generating:  12%|â–ˆâ–Ž        | 1/8 [00:11<01:21, 11.70s/it]Generating:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:17<00:51,  8.51s/it]Generating:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:25<00:40,  8.01s/it]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:30<00:28,  7.03s/it]Generating:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:43<00:26,  8.86s/it]Generating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:48<00:15,  7.74s/it]Generating:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:55<00:07,  7.56s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:00<00:00,  6.63s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:00<00:00,  7.55s/it]

============================================================
Results for llama-3.1-3b with strategy_4
============================================================
Accuracy:  0.8474
Precision: 0.0506
Recall:    0.1914
F1 Score:  0.0800

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  7855   1164
  Actual 1:   262     62
============================================================

Saved predictions to /workspace/results/dev/structured_json_4/llama_3.1_3b.csv

============================================================
[16/28] Strategy 4 (structured_json) - llama-3.1-3b - ood
============================================================

Strategy 4: Structured JSON Output
Model: llama-3.1-3b
Dataset: ood (1522 tokens)
Output format: JSON
  Processing 11 chunks (JSON mode: True)
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.71it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.94it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.66it/s]
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/2 [00:00<?, ?it/s]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.74s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  6.78s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.37s/it]

============================================================
Results for llama-3.1-3b with strategy_4
============================================================
Accuracy:  0.8095
Precision: 0.1151
Recall:    0.3021
F1 Score:  0.1667

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1203    223
  Actual 1:    67     29
============================================================

Saved predictions to /workspace/results/ood/structured_json_4/llama_3.1_3b.csv

============================================================
[17/28] Strategy 5 (few_shot_hard) - llama-3.1-1b - dev
============================================================

Strategy 5: Few-Shot Learning with Hard Examples
Model: llama-3.1-1b
Dataset: dev (9343 tokens)
  Processing 94 chunks with few-shot examples
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/12 [00:00<?, ?it/s]Generating:   8%|â–Š         | 1/12 [00:04<00:52,  4.74s/it]Generating:  17%|â–ˆâ–‹        | 2/12 [00:09<00:47,  4.73s/it]Generating:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:14<00:42,  4.74s/it]Generating:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:18<00:38,  4.75s/it]Generating:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:23<00:33,  4.75s/it]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:28<00:28,  4.74s/it]Generating:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:33<00:23,  4.74s/it]Generating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:37<00:18,  4.74s/it]Generating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:42<00:14,  4.74s/it]Generating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:47<00:09,  4.74s/it]Generating:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:52<00:04,  4.74s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:56<00:00,  4.54s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:56<00:00,  4.69s/it]

============================================================
Results for llama-3.1-1b with strategy_5
============================================================
Accuracy:  0.9647
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  9013      6
  Actual 1:   324      0
============================================================

Saved predictions to /workspace/results/dev/few_shot_hard_5/llama_3.1_1b.csv

============================================================
[18/28] Strategy 5 (few_shot_hard) - llama-3.1-1b - ood
============================================================

Strategy 5: Few-Shot Learning with Hard Examples
Model: llama-3.1-1b
Dataset: ood (1522 tokens)
  Processing 16 chunks with few-shot examples
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/2 [00:00<?, ?it/s]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:04<00:04,  4.74s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.76s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.76s/it]

============================================================
Results for llama-3.1-1b with strategy_5
============================================================
Accuracy:  0.9356
Precision: 0.0000
Recall:    0.0000
F1 Score:  0.0000

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1424      2
  Actual 1:    96      0
============================================================

Saved predictions to /workspace/results/ood/few_shot_hard_5/llama_3.1_1b.csv

============================================================
[19/28] Strategy 5 (few_shot_hard) - llama-3.1-3b - dev
============================================================

Strategy 5: Few-Shot Learning with Hard Examples
Model: llama-3.1-3b
Dataset: dev (9343 tokens)
  Processing 94 chunks with few-shot examples
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.65it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.86it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.57it/s]
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/12 [00:00<?, ?it/s]Generating:   8%|â–Š         | 1/12 [00:11<02:04, 11.30s/it]Generating:  17%|â–ˆâ–‹        | 2/12 [00:22<01:52, 11.28s/it]Generating:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:33<01:41, 11.31s/it]Generating:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:45<01:30, 11.32s/it]Generating:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:56<01:19, 11.30s/it]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [01:07<01:07, 11.30s/it]Generating:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [01:19<00:56, 11.29s/it]Generating:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [01:30<00:45, 11.28s/it]Generating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [01:41<00:33, 11.29s/it]Generating:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [01:52<00:22, 11.27s/it]Generating:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [02:04<00:11, 11.29s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [02:13<00:00, 10.82s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [02:13<00:00, 11.16s/it]

============================================================
Results for llama-3.1-3b with strategy_5
============================================================
Accuracy:  0.9213
Precision: 0.0443
Recall:    0.0617
F1 Score:  0.0516

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  8588    431
  Actual 1:   304     20
============================================================

Saved predictions to /workspace/results/dev/few_shot_hard_5/llama_3.1_3b.csv

============================================================
[20/28] Strategy 5 (few_shot_hard) - llama-3.1-3b - ood
============================================================

Strategy 5: Few-Shot Learning with Hard Examples
Model: llama-3.1-3b
Dataset: ood (1522 tokens)
  Processing 16 chunks with few-shot examples
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.73it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.95it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.66it/s]
Model compiled with torch.compile
Model loaded successfully
Generating:   0%|          | 0/2 [00:00<?, ?it/s]Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:11<00:11, 11.31s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:22<00:00, 11.35s/it]Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:22<00:00, 11.34s/it]

============================================================
Results for llama-3.1-3b with strategy_5
============================================================
Accuracy:  0.8200
Precision: 0.0762
Recall:    0.1667
F1 Score:  0.1046

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1232    194
  Actual 1:    80     16
============================================================

Saved predictions to /workspace/results/ood/few_shot_hard_5/llama_3.1_3b.csv

============================================================
[21/28] Strategy 6 (chain_of_thought) - llama-3.1-1b - dev
============================================================

Strategy 6: Chain-of-Thought Reasoning
Model: llama-3.1-1b
Dataset: dev (9343 tokens)
  Found 626 punctuation marks for CoT analysis
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
CoT Reasoning:   0%|          | 0/79 [00:00<?, ?it/s]CoT Reasoning:   1%|â–         | 1/79 [00:01<02:19,  1.79s/it]CoT Reasoning:   3%|â–Ž         | 2/79 [00:03<01:59,  1.55s/it]CoT Reasoning:   4%|â–         | 3/79 [00:04<01:51,  1.47s/it]CoT Reasoning:   5%|â–Œ         | 4/79 [00:05<01:37,  1.31s/it]CoT Reasoning:   6%|â–‹         | 5/79 [00:07<02:00,  1.63s/it]CoT Reasoning:   8%|â–Š         | 6/79 [00:09<01:54,  1.57s/it]CoT Reasoning:   9%|â–‰         | 7/79 [00:10<01:48,  1.51s/it]CoT Reasoning:  10%|â–ˆ         | 8/79 [00:12<01:51,  1.57s/it]CoT Reasoning:  11%|â–ˆâ–        | 9/79 [00:13<01:47,  1.54s/it]CoT Reasoning:  13%|â–ˆâ–Ž        | 10/79 [00:15<01:43,  1.50s/it]CoT Reasoning:  14%|â–ˆâ–        | 11/79 [00:16<01:38,  1.44s/it]CoT Reasoning:  15%|â–ˆâ–Œ        | 12/79 [00:17<01:34,  1.41s/it]CoT Reasoning:  16%|â–ˆâ–‹        | 13/79 [00:19<01:32,  1.40s/it]CoT Reasoning:  18%|â–ˆâ–Š        | 14/79 [00:20<01:29,  1.38s/it]CoT Reasoning:  19%|â–ˆâ–‰        | 15/79 [00:21<01:28,  1.38s/it]CoT Reasoning:  20%|â–ˆâ–ˆ        | 16/79 [00:23<01:28,  1.41s/it]CoT Reasoning:  22%|â–ˆâ–ˆâ–       | 17/79 [00:24<01:24,  1.37s/it]CoT Reasoning:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [00:26<01:27,  1.44s/it]CoT Reasoning:  24%|â–ˆâ–ˆâ–       | 19/79 [00:27<01:27,  1.46s/it]CoT Reasoning:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [00:29<01:25,  1.45s/it]CoT Reasoning:  27%|â–ˆâ–ˆâ–‹       | 21/79 [00:30<01:22,  1.42s/it]CoT Reasoning:  28%|â–ˆâ–ˆâ–Š       | 22/79 [00:32<01:23,  1.46s/it]CoT Reasoning:  29%|â–ˆâ–ˆâ–‰       | 23/79 [00:34<01:32,  1.65s/it]CoT Reasoning:  30%|â–ˆâ–ˆâ–ˆ       | 24/79 [00:35<01:32,  1.68s/it]CoT Reasoning:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [00:37<01:26,  1.60s/it]CoT Reasoning:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/79 [00:38<01:19,  1.50s/it]CoT Reasoning:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [00:40<01:17,  1.49s/it]CoT Reasoning:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/79 [00:41<01:15,  1.49s/it]CoT Reasoning:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/79 [00:43<01:14,  1.48s/it]CoT Reasoning:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [00:44<01:14,  1.52s/it]CoT Reasoning:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/79 [00:46<01:14,  1.56s/it]CoT Reasoning:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/79 [00:48<01:17,  1.64s/it]CoT Reasoning:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/79 [00:49<01:13,  1.60s/it]CoT Reasoning:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/79 [00:51<01:08,  1.53s/it]CoT Reasoning:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [00:52<01:04,  1.47s/it]CoT Reasoning:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [00:53<01:02,  1.46s/it]CoT Reasoning:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/79 [00:55<01:02,  1.49s/it]CoT Reasoning:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/79 [00:56<01:01,  1.51s/it]CoT Reasoning:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/79 [00:58<01:00,  1.51s/it]CoT Reasoning:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [00:59<00:56,  1.45s/it]CoT Reasoning:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/79 [01:01<00:53,  1.41s/it]CoT Reasoning:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/79 [01:02<00:56,  1.52s/it]CoT Reasoning:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/79 [01:04<01:00,  1.69s/it]CoT Reasoning:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/79 [01:06<00:59,  1.69s/it]CoT Reasoning:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [01:08<00:54,  1.61s/it]CoT Reasoning:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/79 [01:10<00:58,  1.78s/it]CoT Reasoning:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/79 [01:11<00:53,  1.68s/it]CoT Reasoning:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/79 [01:13<00:54,  1.76s/it]CoT Reasoning:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/79 [01:15<00:51,  1.72s/it]CoT Reasoning:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [01:16<00:46,  1.61s/it]CoT Reasoning:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/79 [01:18<00:46,  1.68s/it]CoT Reasoning:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/79 [01:19<00:43,  1.60s/it]CoT Reasoning:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/79 [01:21<00:42,  1.63s/it]CoT Reasoning:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [01:22<00:38,  1.55s/it]CoT Reasoning:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [01:24<00:37,  1.54s/it]CoT Reasoning:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/79 [01:25<00:34,  1.51s/it]CoT Reasoning:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/79 [01:27<00:33,  1.54s/it]CoT Reasoning:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/79 [01:28<00:30,  1.46s/it]CoT Reasoning:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/79 [01:30<00:33,  1.69s/it]CoT Reasoning:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [01:32<00:29,  1.55s/it]CoT Reasoning:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/79 [01:34<00:30,  1.67s/it]CoT Reasoning:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/79 [01:35<00:26,  1.56s/it]CoT Reasoning:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [01:37<00:27,  1.70s/it]CoT Reasoning:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/79 [01:39<00:24,  1.66s/it]CoT Reasoning:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [01:40<00:22,  1.60s/it]CoT Reasoning:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/79 [01:41<00:20,  1.56s/it]CoT Reasoning:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/79 [01:43<00:17,  1.47s/it]CoT Reasoning:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/79 [01:44<00:15,  1.38s/it]CoT Reasoning:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/79 [01:46<00:15,  1.52s/it]CoT Reasoning:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [01:48<00:15,  1.73s/it]CoT Reasoning:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/79 [01:50<00:13,  1.74s/it]CoT Reasoning:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [01:52<00:13,  1.87s/it]CoT Reasoning:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/79 [01:53<00:10,  1.75s/it]CoT Reasoning:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/79 [01:55<00:08,  1.74s/it]CoT Reasoning:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [01:56<00:06,  1.63s/it]CoT Reasoning:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/79 [01:58<00:05,  1.74s/it]CoT Reasoning:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/79 [02:00<00:03,  1.65s/it]CoT Reasoning:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/79 [02:01<00:01,  1.55s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [02:02<00:00,  1.40s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [02:02<00:00,  1.55s/it]

============================================================
Results for llama-3.1-1b with strategy_6
============================================================
Accuracy:  0.9681
Precision: 0.5546
Recall:    0.4074
F1 Score:  0.4698

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  8913    106
  Actual 1:   192    132
============================================================

Saved predictions to /workspace/results/dev/chain_of_thought_6/llama_3.1_1b.csv

============================================================
[22/28] Strategy 6 (chain_of_thought) - llama-3.1-1b - ood
============================================================

Strategy 6: Chain-of-Thought Reasoning
Model: llama-3.1-1b
Dataset: ood (1522 tokens)
  Found 128 punctuation marks for CoT analysis
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
CoT Reasoning:   0%|          | 0/16 [00:00<?, ?it/s]CoT Reasoning:   6%|â–‹         | 1/16 [00:01<00:20,  1.34s/it]CoT Reasoning:  12%|â–ˆâ–Ž        | 2/16 [00:03<00:21,  1.54s/it]CoT Reasoning:  19%|â–ˆâ–‰        | 3/16 [00:05<00:23,  1.80s/it]CoT Reasoning:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:21,  1.78s/it]CoT Reasoning:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.57s/it]CoT Reasoning:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.64s/it]CoT Reasoning:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.66s/it]CoT Reasoning:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.59s/it]CoT Reasoning:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.69s/it]CoT Reasoning:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:16<00:09,  1.64s/it]CoT Reasoning:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:07,  1.49s/it]CoT Reasoning:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.56s/it]CoT Reasoning:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:20<00:04,  1.55s/it]CoT Reasoning:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:02,  1.47s/it]CoT Reasoning:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:23<00:01,  1.47s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:24<00:00,  1.40s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:24<00:00,  1.55s/it]

============================================================
Results for llama-3.1-1b with strategy_6
============================================================
Accuracy:  0.9488
Precision: 0.7368
Recall:    0.2917
F1 Score:  0.4179

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1416     10
  Actual 1:    68     28
============================================================

Saved predictions to /workspace/results/ood/chain_of_thought_6/llama_3.1_1b.csv

============================================================
[23/28] Strategy 6 (chain_of_thought) - llama-3.1-3b - dev
============================================================

Strategy 6: Chain-of-Thought Reasoning
Model: llama-3.1-3b
Dataset: dev (9343 tokens)
  Found 626 punctuation marks for CoT analysis
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.73it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.96it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.67it/s]
Model compiled with torch.compile
Model loaded successfully
CoT Reasoning:   0%|          | 0/79 [00:00<?, ?it/s]CoT Reasoning:   1%|â–         | 1/79 [00:04<06:24,  4.92s/it]CoT Reasoning:   3%|â–Ž         | 2/79 [00:09<06:18,  4.92s/it]CoT Reasoning:   4%|â–         | 3/79 [00:14<06:13,  4.92s/it]CoT Reasoning:   5%|â–Œ         | 4/79 [00:19<06:08,  4.91s/it]CoT Reasoning:   6%|â–‹         | 5/79 [00:24<06:02,  4.90s/it]CoT Reasoning:   8%|â–Š         | 6/79 [00:29<05:58,  4.91s/it]CoT Reasoning:   9%|â–‰         | 7/79 [00:34<05:53,  4.91s/it]CoT Reasoning:  10%|â–ˆ         | 8/79 [00:39<05:48,  4.91s/it]CoT Reasoning:  11%|â–ˆâ–        | 9/79 [00:44<05:43,  4.91s/it]CoT Reasoning:  13%|â–ˆâ–Ž        | 10/79 [00:49<05:39,  4.92s/it]CoT Reasoning:  14%|â–ˆâ–        | 11/79 [00:54<05:34,  4.92s/it]CoT Reasoning:  15%|â–ˆâ–Œ        | 12/79 [00:59<05:30,  4.94s/it]CoT Reasoning:  16%|â–ˆâ–‹        | 13/79 [01:03<05:25,  4.93s/it]CoT Reasoning:  18%|â–ˆâ–Š        | 14/79 [01:08<05:19,  4.92s/it]CoT Reasoning:  19%|â–ˆâ–‰        | 15/79 [01:13<05:14,  4.91s/it]CoT Reasoning:  20%|â–ˆâ–ˆ        | 16/79 [01:18<05:09,  4.91s/it]CoT Reasoning:  22%|â–ˆâ–ˆâ–       | 17/79 [01:23<05:04,  4.91s/it]CoT Reasoning:  23%|â–ˆâ–ˆâ–Ž       | 18/79 [01:28<04:59,  4.92s/it]CoT Reasoning:  24%|â–ˆâ–ˆâ–       | 19/79 [01:33<04:55,  4.92s/it]CoT Reasoning:  25%|â–ˆâ–ˆâ–Œ       | 20/79 [01:38<04:50,  4.92s/it]CoT Reasoning:  27%|â–ˆâ–ˆâ–‹       | 21/79 [01:43<04:46,  4.93s/it]CoT Reasoning:  28%|â–ˆâ–ˆâ–Š       | 22/79 [01:48<04:40,  4.93s/it]CoT Reasoning:  29%|â–ˆâ–ˆâ–‰       | 23/79 [01:53<04:36,  4.93s/it]CoT Reasoning:  30%|â–ˆâ–ˆâ–ˆ       | 24/79 [01:58<04:30,  4.92s/it]CoT Reasoning:  32%|â–ˆâ–ˆâ–ˆâ–      | 25/79 [02:02<04:25,  4.91s/it]CoT Reasoning:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/79 [02:07<04:19,  4.90s/it]CoT Reasoning:  34%|â–ˆâ–ˆâ–ˆâ–      | 27/79 [02:12<04:14,  4.89s/it]CoT Reasoning:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/79 [02:17<04:09,  4.90s/it]CoT Reasoning:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 29/79 [02:22<04:05,  4.90s/it]CoT Reasoning:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/79 [02:27<04:00,  4.91s/it]CoT Reasoning:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/79 [02:32<03:55,  4.90s/it]CoT Reasoning:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/79 [02:37<03:50,  4.91s/it]CoT Reasoning:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/79 [02:42<03:45,  4.90s/it]CoT Reasoning:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 34/79 [02:47<03:40,  4.89s/it]CoT Reasoning:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/79 [02:51<03:35,  4.90s/it]CoT Reasoning:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/79 [02:56<03:31,  4.91s/it]CoT Reasoning:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/79 [03:01<03:26,  4.91s/it]CoT Reasoning:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/79 [03:06<03:21,  4.91s/it]CoT Reasoning:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/79 [03:11<03:15,  4.90s/it]CoT Reasoning:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/79 [03:16<03:10,  4.90s/it]CoT Reasoning:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/79 [03:21<03:06,  4.90s/it]CoT Reasoning:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 42/79 [03:26<03:01,  4.91s/it]CoT Reasoning:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/79 [03:31<02:56,  4.91s/it]CoT Reasoning:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/79 [03:36<02:51,  4.90s/it]CoT Reasoning:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/79 [03:40<02:46,  4.90s/it]CoT Reasoning:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/79 [03:45<02:41,  4.89s/it]CoT Reasoning:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/79 [03:50<02:36,  4.88s/it]CoT Reasoning:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/79 [03:55<02:31,  4.89s/it]CoT Reasoning:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/79 [04:00<02:26,  4.89s/it]CoT Reasoning:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 50/79 [04:05<02:21,  4.90s/it]CoT Reasoning:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/79 [04:10<02:17,  4.91s/it]CoT Reasoning:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/79 [04:15<02:12,  4.91s/it]CoT Reasoning:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/79 [04:20<02:07,  4.92s/it]CoT Reasoning:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/79 [04:25<02:02,  4.92s/it]CoT Reasoning:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/79 [04:29<01:57,  4.91s/it]CoT Reasoning:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/79 [04:34<01:52,  4.91s/it]CoT Reasoning:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/79 [04:39<01:48,  4.92s/it]CoT Reasoning:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 58/79 [04:44<01:43,  4.91s/it]CoT Reasoning:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/79 [04:49<01:38,  4.90s/it]CoT Reasoning:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/79 [04:54<01:32,  4.89s/it]CoT Reasoning:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/79 [04:58<01:25,  4.76s/it]CoT Reasoning:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/79 [05:03<01:21,  4.79s/it]CoT Reasoning:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/79 [05:08<01:17,  4.83s/it]CoT Reasoning:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/79 [05:13<01:12,  4.83s/it]CoT Reasoning:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/79 [05:18<01:07,  4.84s/it]CoT Reasoning:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 66/79 [05:23<01:03,  4.85s/it]CoT Reasoning:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/79 [05:28<00:58,  4.86s/it]CoT Reasoning:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/79 [05:33<00:53,  4.87s/it]CoT Reasoning:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/79 [05:37<00:48,  4.88s/it]CoT Reasoning:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/79 [05:42<00:44,  4.89s/it]CoT Reasoning:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/79 [05:47<00:39,  4.89s/it]CoT Reasoning:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/79 [05:52<00:34,  4.89s/it]CoT Reasoning:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/79 [05:57<00:29,  4.90s/it]CoT Reasoning:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 74/79 [06:02<00:24,  4.90s/it]CoT Reasoning:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/79 [06:07<00:19,  4.91s/it]CoT Reasoning:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/79 [06:12<00:14,  4.93s/it]CoT Reasoning:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/79 [06:17<00:09,  4.94s/it]CoT Reasoning:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/79 [06:22<00:04,  4.93s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [06:25<00:00,  4.56s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [06:25<00:00,  4.89s/it]

============================================================
Results for llama-3.1-3b with strategy_6
============================================================
Accuracy:  0.9649
Precision: 0.4286
Recall:    0.0370
F1 Score:  0.0682

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  9003     16
  Actual 1:   312     12
============================================================

Saved predictions to /workspace/results/dev/chain_of_thought_6/llama_3.1_3b.csv

============================================================
[24/28] Strategy 6 (chain_of_thought) - llama-3.1-3b - ood
============================================================

Strategy 6: Chain-of-Thought Reasoning
Model: llama-3.1-3b
Dataset: ood (1522 tokens)
  Found 128 punctuation marks for CoT analysis
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.64it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.85it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.56it/s]
Model compiled with torch.compile
Model loaded successfully
CoT Reasoning:   0%|          | 0/16 [00:00<?, ?it/s]CoT Reasoning:   6%|â–‹         | 1/16 [00:04<01:14,  4.95s/it]CoT Reasoning:  12%|â–ˆâ–Ž        | 2/16 [00:09<01:09,  4.94s/it]CoT Reasoning:  19%|â–ˆâ–‰        | 3/16 [00:14<01:04,  4.93s/it]CoT Reasoning:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:19<00:59,  4.93s/it]CoT Reasoning:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:24<00:54,  4.92s/it]CoT Reasoning:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:29<00:49,  4.92s/it]CoT Reasoning:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:34<00:44,  4.92s/it]CoT Reasoning:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:39<00:39,  4.94s/it]CoT Reasoning:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:44<00:34,  4.94s/it]CoT Reasoning:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 10/16 [00:49<00:29,  4.94s/it]CoT Reasoning:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:53<00:24,  4.85s/it]CoT Reasoning:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:58<00:19,  4.88s/it]CoT Reasoning:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [01:03<00:14,  4.91s/it]CoT Reasoning:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [01:08<00:09,  4.90s/it]CoT Reasoning:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [01:13<00:04,  4.90s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:18<00:00,  4.92s/it]CoT Reasoning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:18<00:00,  4.92s/it]

============================================================
Results for llama-3.1-3b with strategy_6
============================================================
Accuracy:  0.9409
Precision: 0.8000
Recall:    0.0833
F1 Score:  0.1509

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1424      2
  Actual 1:    88      8
============================================================

Saved predictions to /workspace/results/ood/chain_of_thought_6/llama_3.1_3b.csv

============================================================
[25/28] Strategy 7 (iterative_refinement) - llama-3.1-1b - dev
============================================================

Strategy 7: Iterative Refinement
Model: llama-3.1-1b
Dataset: dev (9343 tokens)
  Pass 1: Initial predictions
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Pass 1:   0%|          | 0/12 [00:00<?, ?it/s]Pass 1:   8%|â–Š         | 1/12 [00:02<00:31,  2.85s/it]Pass 1:  17%|â–ˆâ–‹        | 2/12 [00:05<00:28,  2.84s/it]Pass 1:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:08<00:25,  2.84s/it]Pass 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:11<00:22,  2.85s/it]Pass 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:14<00:19,  2.85s/it]Pass 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:17<00:17,  2.85s/it]Pass 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:19<00:14,  2.84s/it]Pass 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:22<00:11,  2.83s/it]Pass 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:25<00:08,  2.84s/it]Pass 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:28<00:05,  2.84s/it]Pass 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:31<00:02,  2.84s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:33<00:00,  2.77s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:33<00:00,  2.82s/it]
  Pass 2: Verification
    Found 637 positions to verify
Pass 2:   0%|          | 0/8 [00:00<?, ?it/s]Pass 2:  12%|â–ˆâ–Ž        | 1/8 [00:02<00:18,  2.57s/it]Pass 2:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:05<00:15,  2.58s/it]Pass 2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:07<00:12,  2.59s/it]Pass 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:10<00:10,  2.58s/it]Pass 2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:12<00:07,  2.57s/it]Pass 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:15<00:05,  2.58s/it]Pass 2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:18<00:02,  2.58s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:20<00:00,  2.58s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:20<00:00,  2.58s/it]

============================================================
Results for llama-3.1-1b with strategy_7
============================================================
Accuracy:  0.9606
Precision: 0.0417
Recall:    0.0062
F1 Score:  0.0108

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  8973     46
  Actual 1:   322      2
============================================================

Saved predictions to /workspace/results/dev/iterative_refinement_7/llama_3.1_1b.csv

============================================================
[26/28] Strategy 7 (iterative_refinement) - llama-3.1-1b - ood
============================================================

Strategy 7: Iterative Refinement
Model: llama-3.1-1b
Dataset: ood (1522 tokens)
  Pass 1: Initial predictions
Loading model: meta-llama/Llama-3.2-1B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Model compiled with torch.compile
Model loaded successfully
Pass 1:   0%|          | 0/2 [00:00<?, ?it/s]Pass 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.85s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.87s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00:00,  2.86s/it]
  Pass 2: Verification
    Found 125 positions to verify
Pass 2:   0%|          | 0/2 [00:00<?, ?it/s]Pass 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.60s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.36s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.39s/it]

============================================================
Results for llama-3.1-1b with strategy_7
============================================================
Accuracy:  0.9330
Precision: 0.1250
Recall:    0.0104
F1 Score:  0.0192

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  1419      7
  Actual 1:    95      1
============================================================

Saved predictions to /workspace/results/ood/iterative_refinement_7/llama_3.1_1b.csv

============================================================
[27/28] Strategy 7 (iterative_refinement) - llama-3.1-3b - dev
============================================================

Strategy 7: Iterative Refinement
Model: llama-3.1-3b
Dataset: dev (9343 tokens)
  Pass 1: Initial predictions
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.74it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.94it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.66it/s]
Model compiled with torch.compile
Model loaded successfully
Pass 1:   0%|          | 0/12 [00:00<?, ?it/s]Pass 1:   8%|â–Š         | 1/12 [00:06<01:10,  6.39s/it]Pass 1:  17%|â–ˆâ–‹        | 2/12 [00:12<01:03,  6.36s/it]Pass 1:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:19<00:57,  6.37s/it]Pass 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:25<00:51,  6.38s/it]Pass 1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:31<00:44,  6.37s/it]Pass 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:38<00:38,  6.37s/it]Pass 1:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:44<00:31,  6.34s/it]Pass 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:50<00:25,  6.34s/it]Pass 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:57<00:19,  6.36s/it]Pass 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [01:03<00:12,  6.35s/it]Pass 1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [01:09<00:06,  6.36s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [01:15<00:00,  6.20s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [01:15<00:00,  6.32s/it]
  Pass 2: Verification
    Found 4263 positions to verify
Pass 2:   0%|          | 0/54 [00:00<?, ?it/s]Pass 2:   2%|â–         | 1/54 [00:04<04:24,  4.99s/it]Pass 2:   4%|â–Ž         | 2/54 [00:09<04:14,  4.89s/it]Pass 2:   6%|â–Œ         | 3/54 [00:14<04:07,  4.85s/it]Pass 2:   7%|â–‹         | 4/54 [00:19<03:56,  4.73s/it]Pass 2:   9%|â–‰         | 5/54 [00:23<03:51,  4.72s/it]Pass 2:  11%|â–ˆ         | 6/54 [00:29<04:06,  5.14s/it]Pass 2:  13%|â–ˆâ–Ž        | 7/54 [00:35<04:07,  5.27s/it]Pass 2:  15%|â–ˆâ–        | 8/54 [00:39<03:51,  5.02s/it]Pass 2:  17%|â–ˆâ–‹        | 9/54 [00:44<03:40,  4.90s/it]Pass 2:  19%|â–ˆâ–Š        | 10/54 [00:48<03:29,  4.76s/it]Pass 2:  20%|â–ˆâ–ˆ        | 11/54 [00:54<03:32,  4.94s/it]Pass 2:  22%|â–ˆâ–ˆâ–       | 12/54 [01:00<03:41,  5.28s/it]Pass 2:  24%|â–ˆâ–ˆâ–       | 13/54 [01:05<03:34,  5.24s/it]Pass 2:  26%|â–ˆâ–ˆâ–Œ       | 14/54 [01:11<03:39,  5.49s/it]Pass 2:  28%|â–ˆâ–ˆâ–Š       | 15/54 [01:16<03:23,  5.21s/it]Pass 2:  30%|â–ˆâ–ˆâ–‰       | 16/54 [01:21<03:16,  5.16s/it]Pass 2:  31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [01:25<03:01,  4.90s/it]Pass 2:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 18/54 [01:30<03:01,  5.03s/it]Pass 2:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [01:35<02:57,  5.07s/it]Pass 2:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [01:41<02:53,  5.09s/it]Pass 2:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [01:45<02:42,  4.94s/it]Pass 2:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [01:51<02:48,  5.26s/it]Pass 2:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 23/54 [01:57<02:50,  5.51s/it]Pass 2:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [02:02<02:39,  5.33s/it]Pass 2:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [02:07<02:29,  5.14s/it]Pass 2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [02:13<02:31,  5.41s/it]Pass 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [02:19<02:30,  5.59s/it]Pass 2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [02:23<02:16,  5.25s/it]Pass 2:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 29/54 [02:29<02:14,  5.39s/it]Pass 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [02:35<02:12,  5.54s/it]Pass 2:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [02:39<01:59,  5.18s/it]Pass 2:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [02:45<01:59,  5.44s/it]Pass 2:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [02:50<01:51,  5.33s/it]Pass 2:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 34/54 [02:56<01:45,  5.28s/it]Pass 2:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [03:00<01:32,  4.89s/it]Pass 2:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [03:06<01:33,  5.19s/it]Pass 2:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [03:11<01:30,  5.34s/it]Pass 2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [03:16<01:21,  5.10s/it]Pass 2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [03:20<01:13,  4.90s/it]Pass 2:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [03:26<01:13,  5.26s/it]Pass 2:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [03:32<01:09,  5.38s/it]Pass 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [03:38<01:07,  5.60s/it]Pass 2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [03:43<00:58,  5.34s/it]Pass 2:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [03:49<00:55,  5.56s/it]Pass 2:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 45/54 [03:55<00:50,  5.66s/it]Pass 2:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [04:01<00:45,  5.74s/it]Pass 2:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [04:07<00:40,  5.78s/it]Pass 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [04:12<00:34,  5.76s/it]Pass 2:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [04:18<00:28,  5.68s/it]Pass 2:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 50/54 [04:22<00:21,  5.41s/it]Pass 2:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [04:29<00:16,  5.62s/it]Pass 2:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [04:34<00:11,  5.69s/it]Pass 2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [04:39<00:05,  5.32s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [04:42<00:00,  4.62s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [04:42<00:00,  5.23s/it]

============================================================
Results for llama-3.1-3b with strategy_7
============================================================
Accuracy:  0.5865
Precision: 0.0398
Recall:    0.4722
F1 Score:  0.0734

Confusion Matrix:
  Predicted:  0      1
  Actual 0:  5327   3692
  Actual 1:   171    153
============================================================

Saved predictions to /workspace/results/dev/iterative_refinement_7/llama_3.1_3b.csv

============================================================
[28/28] Strategy 7 (iterative_refinement) - llama-3.1-3b - ood
============================================================

Strategy 7: Iterative Refinement
Model: llama-3.1-3b
Dataset: ood (1522 tokens)
  Pass 1: Initial predictions
Loading model: meta-llama/Llama-3.2-3B-Instruct
CUDA available: NVIDIA RTX A4500
CUDA memory: 21.2 GB
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.66it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.83it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.56it/s]
Model compiled with torch.compile
Model loaded successfully
Pass 1:   0%|          | 0/2 [00:00<?, ?it/s]Pass 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.39s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.42s/it]Pass 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.41s/it]
  Pass 2: Verification
    Found 658 positions to verify
Pass 2:   0%|          | 0/9 [00:00<?, ?it/s]Pass 2:  11%|â–ˆ         | 1/9 [00:04<00:38,  4.87s/it]Pass 2:  22%|â–ˆâ–ˆâ–       | 2/9 [00:10<00:36,  5.25s/it]Pass 2:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:14<00:27,  4.65s/it]Pass 2:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:20<00:25,  5.18s/it]Pass 2:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [00:26<00:22,  5.55s/it]Pass 2:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [00:30<00:15,  5.18s/it]Pass 2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [00:37<00:10,  5.47s/it]Pass 2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:43<00:05,  5.70s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:47<00:00,  5.17s/it]Pass 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:47<00:00,  5.25s/it]

============================================================
Results for llama-3.1-3b with strategy_7
============================================================
Accuracy:  0.6143
Precision: 0.0670
Recall:    0.3958
F1 Score:  0.1146

Confusion Matrix:
  Predicted:  0      1
  Actual 0:   897    529
  Actual 1:    58     38
============================================================

Saved predictions to /workspace/results/ood/iterative_refinement_7/llama_3.1_3b.csv

====================================================================================================
RESULTS SUMMARY
====================================================================================================
Strategy                  Model              Dataset  F1         Prec       Recall    
----------------------------------------------------------------------------------------------------
sliding_window            llama-3.1-1b       dev      0.0000    0.0000    0.0000
sliding_window            llama-3.1-1b       ood      0.0000    0.0000    0.0000
sliding_window            llama-3.1-3b       dev      0.0000    0.0000    0.0000
sliding_window            llama-3.1-3b       ood      0.0000    0.0000    0.0000
next_token_prob           llama-3.1-1b       dev      0.0000    0.0000    0.0000
next_token_prob           llama-3.1-1b       ood      0.0000    0.0000    0.0000
next_token_prob           llama-3.1-3b       dev      0.0000    0.0000    0.0000
next_token_prob           llama-3.1-3b       ood      0.0000    0.0000    0.0000
marker_insertion          llama-3.1-1b       dev      0.1005    0.2703    0.0617
marker_insertion          llama-3.1-1b       ood      0.0800    1.0000    0.0417
marker_insertion          llama-3.1-3b       dev      0.3096    0.4805    0.2284
marker_insertion          llama-3.1-3b       ood      0.1869    0.9091    0.1042
structured_json           llama-3.1-1b       dev      0.0652    0.0340    0.7932
structured_json           llama-3.1-1b       ood      0.1199    0.0643    0.8854
structured_json           llama-3.1-3b       dev      0.0800    0.0506    0.1914
structured_json           llama-3.1-3b       ood      0.1667    0.1151    0.3021
few_shot_hard             llama-3.1-1b       dev      0.0000    0.0000    0.0000
few_shot_hard             llama-3.1-1b       ood      0.0000    0.0000    0.0000
few_shot_hard             llama-3.1-3b       dev      0.0516    0.0443    0.0617
few_shot_hard             llama-3.1-3b       ood      0.1046    0.0762    0.1667
chain_of_thought          llama-3.1-1b       dev      0.4698    0.5546    0.4074
chain_of_thought          llama-3.1-1b       ood      0.4179    0.7368    0.2917
chain_of_thought          llama-3.1-3b       dev      0.0682    0.4286    0.0370
chain_of_thought          llama-3.1-3b       ood      0.1509    0.8000    0.0833
iterative_refinement      llama-3.1-1b       dev      0.0108    0.0417    0.0062
iterative_refinement      llama-3.1-1b       ood      0.0192    0.1250    0.0104
iterative_refinement      llama-3.1-3b       dev      0.0734    0.0398    0.4722
iterative_refinement      llama-3.1-3b       ood      0.1146    0.0670    0.3958
====================================================================================================

Summary saved to: results/strategies_summary_20251222_093432.json

[0;32m========================================[0m
[0;32mDone![0m
[0;32mResults in: ./results/{dev,ood}/{strategy_name}_{id}/[0m
[0;32m========================================[0m

[1;33mGenerated files:[0m
results/dev/chain_of_thought_6/llama_3.1_1b.csv
results/dev/chain_of_thought_6/llama_3.1_3b.csv
results/dev/few_shot_hard_5/llama_3.1_1b.csv
results/dev/few_shot_hard_5/llama_3.1_3b.csv
results/dev/iterative_refinement_7/llama_3.1_1b.csv
results/dev/iterative_refinement_7/llama_3.1_3b.csv
results/dev/marker_insertion_3/llama_3.1_1b.csv
results/dev/marker_insertion_3/llama_3.1_3b.csv
results/dev/next_token_prob_2/llama_3.1_1b.csv
results/dev/next_token_prob_2/llama_3.1_3b.csv
results/dev/sliding_window_1/llama_3.1_1b.csv
results/dev/sliding_window_1/llama_3.1_3b.csv
results/dev/structured_json_4/llama_3.1_1b.csv
results/dev/structured_json_4/llama_3.1_3b.csv
results/ood/chain_of_thought_6/llama_3.1_1b.csv
results/ood/chain_of_thought_6/llama_3.1_3b.csv
results/ood/few_shot_hard_5/llama_3.1_1b.csv
results/ood/few_shot_hard_5/llama_3.1_3b.csv
results/ood/iterative_refinement_7/llama_3.1_1b.csv
results/ood/iterative_refinement_7/llama_3.1_3b.csv
results/ood/marker_insertion_3/llama_3.1_1b.csv
results/ood/marker_insertion_3/llama_3.1_3b.csv
results/ood/next_token_prob_2/llama_3.1_1b.csv
results/ood/next_token_prob_2/llama_3.1_3b.csv
results/ood/sliding_window_1/llama_3.1_1b.csv
results/ood/sliding_window_1/llama_3.1_3b.csv
results/ood/structured_json_4/llama_3.1_1b.csv
results/ood/structured_json_4/llama_3.1_3b.csv
