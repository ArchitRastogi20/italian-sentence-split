val_samples_per_second': 256.086, 'eval_steps_per_second': 16.598, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0255, 'grad_norm': 4.516438007354736, 'learning_rate': 8.568623290463492e-06, 'epoch': 7.14}                                                                                                  
{'loss': 0.0223, 'grad_norm': 0.7695356607437134, 'learning_rate': 6.630020736059987e-06, 'epoch': 7.8}                                                                                                  
{'eval_loss': 0.01817949302494526, 'eval_precision': 0.8914473684210527, 'eval_recall': 0.8364197530864198, 'eval_f1': 0.8630573248407644, 'eval_accuracy': 0.9925236894723116, 'eval_runtime': 2.2213, 'eval_samples_per_second': 145.86, 'eval_steps_per_second': 9.454, 'epoch': 8.0}                                                                                                                          
{'loss': 0.0194, 'grad_norm': 2.0757904052734375, 'learning_rate': 4.691418181656482e-06, 'epoch': 8.44}                                                                                                 
{'eval_loss': 0.030514320358633995, 'eval_precision': 0.8018867924528302, 'eval_recall': 0.7870370370370371, 'eval_f1': 0.794392523364486, 'eval_accuracy': 0.9885247326784317, 'eval_runtime': 2.2093, 'eval_samples_per_second': 146.655, 'eval_steps_per_second': 9.505, 'epoch': 9.0}                                                                                                                         
{'loss': 0.0176, 'grad_norm': 1.0986653566360474, 'learning_rate': 2.752815627252977e-06, 'epoch': 9.09}                                                                                                 
{'loss': 0.0165, 'grad_norm': 0.8754209876060486, 'learning_rate': 8.14213072849472e-07, 'epoch': 9.75}                                                                                                  
{'eval_loss': 0.022635547444224358, 'eval_precision': 0.8679867986798679, 'eval_recall': 0.8117283950617284, 'eval_f1': 0.8389154704944178, 'eval_accuracy': 0.9912196818221334, 'eval_runtime': 2.2079, 'eval_samples_per_second': 146.743, 'eval_steps_per_second': 9.511, 'epoch': 10.0}                                                                                                                       
{'train_runtime': 659.7061, 'train_samples_per_second': 37.092, 'train_steps_per_second': 1.167, 'train_loss': 0.05872042585502971, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [10:59<00:00,  1.17it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 11.91it/s]
[I 2025-11-08 00:56:03,323] Trial 19 finished with value: 0.8630573248407644 and parameters: {'lr': 2.6093590382271176e-05, 'weight_decay': 0.08646720678318333, 'warmup_ratio': 0.12511151070997056, 'batch_size': 8}. Best is trial 17 with value: 0.8679867986798679.
Best trial: 17. Best value: 0.867987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [3:26:28<00:00, 619.41s/it]

Best params: {'lr': 2.5081549960992703e-05, 'weight_decay': 0.08006206928413431, 'warmup_ratio': 0.29137537214538467, 'batch_size': 8}
Best F1: 0.8680

Training final model for bert-base-italian-xxl-cased...
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /workspace/wandb/run-20251108_005603-68q3wqbz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bert-base-italian-xxl-cased_final
wandb: â­ï¸ View project at https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder
wandb: ðŸš€ View run at https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder/runs/68q3wqbz
Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-xxl-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 0.7925, 'grad_norm': 10.77214527130127, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                    
{'loss': 0.2369, 'grad_norm': 0.2886684238910675, 'learning_rate': 3.181818181818182e-05, 'epoch': 0.65}                                                                                                 
{'eval_loss': 0.10198729485273361, 'eval_precision': 0.7894736842105263, 'eval_recall': 0.18518518518518517, 'eval_f1': 0.3, 'eval_accuracy': 0.97565852386334, 'eval_runtime': 2.2307, 'eval_samples_per_second': 145.245, 'eval_steps_per_second': 9.414, 'epoch': 1.0}                                                                                                                                         
{'loss': 0.0946, 'grad_norm': 0.29626524448394775, 'learning_rate': 4.841269841269841e-05, 'epoch': 1.3}                                                                                                 
{'loss': 0.0724, 'grad_norm': 1.2097454071044922, 'learning_rate': 4.4805194805194805e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.06927061825990677, 'eval_precision': 0.8229166666666666, 'eval_recall': 0.24382716049382716, 'eval_f1': 0.3761904761904762, 'eval_accuracy': 0.9772233330435539, 'eval_runtime': 1.2175, 'eval_samples_per_second': 266.119, 'eval_steps_per_second': 17.248, 'epoch': 2.0}                                                                                                                       
{'loss': 0.0565, 'grad_norm': 0.5918695330619812, 'learning_rate': 4.1197691197691204e-05, 'epoch': 2.6}                                                                                                 
{'eval_loss': 0.042801421135663986, 'eval_precision': 0.7807017543859649, 'eval_recall': 0.5493827160493827, 'eval_f1': 0.644927536231884, 'eval_accuracy': 0.982960966704338, 'eval_runtime': 2.2599, 'eval_samples_per_second': 143.367, 'eval_steps_per_second': 9.292, 'epoch': 3.0}                                                                                                                          
{'loss': 0.0476, 'grad_norm': 0.7305269241333008, 'learning_rate': 3.759018759018759e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0413, 'grad_norm': 0.7518466114997864, 'learning_rate': 3.398268398268398e-05, 'epoch': 3.9}                                                                                                  
{'eval_loss': 0.03957093134522438, 'eval_precision': 0.6936026936026936, 'eval_recall': 0.6358024691358025, 'eval_f1': 0.6634460547504025, 'eval_accuracy': 0.9818308267408502, 'eval_runtime': 2.2092, 'eval_samples_per_second': 146.662, 'eval_steps_per_second': 9.506, 'epoch': 4.0}                                                                                                                         
{'loss': 0.0363, 'grad_norm': 1.420822262763977, 'learning_rate': 3.0375180375180378e-05, 'epoch': 4.55}                                                                                                 
{'eval_loss': 0.031067999079823494, 'eval_precision': 0.8178294573643411, 'eval_recall': 0.6512345679012346, 'eval_f1': 0.7250859106529209, 'eval_accuracy': 0.9860905850647658, 'eval_runtime': 2.2264, 'eval_samples_per_second': 145.527, 'eval_steps_per_second': 9.432, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0338, 'grad_norm': 0.9104102253913879, 'learning_rate': 2.676767676767677e-05, 'epoch': 5.2}                                                                                                  
{'loss': 0.0266, 'grad_norm': 2.4187004566192627, 'learning_rate': 2.3160173160173163e-05, 'epoch': 5.85}                                                                                                
{'eval_loss': 0.04845152050256729, 'eval_precision': 0.703971119133574, 'eval_recall': 0.6018518518518519, 'eval_f1': 0.64891846921797, 'eval_accuracy': 0.9816569590541598, 'eval_runtime': 2.2227, 'eval_samples_per_second': 145.767, 'eval_steps_per_second': 9.448, 'epoch': 6.0}                                                                                                                            
{'loss': 0.0263, 'grad_norm': 1.4187369346618652, 'learning_rate': 1.9552669552669552e-05, 'epoch': 6.5}                                                                                                 
{'eval_loss': 0.01956963911652565, 'eval_precision': 0.8932384341637011, 'eval_recall': 0.7746913580246914, 'eval_f1': 0.8297520661157025, 'eval_accuracy': 0.9910458141354429, 'eval_runtime': 1.9502, 'eval_samples_per_second': 166.139, 'eval_steps_per_second': 10.768, 'epoch': 7.0}                                                                                                                        
{'loss': 0.0207, 'grad_norm': 0.7630268335342407, 'learning_rate': 1.5945165945165948e-05, 'epoch': 7.14}                                                                                                
{'loss': 0.0177, 'grad_norm': 1.1115351915359497, 'learning_rate': 1.2337662337662339e-05, 'epoch': 7.8}                                                                                                 
{'eval_loss': 0.018797816708683968, 'eval_precision': 0.8996282527881041, 'eval_recall': 0.7469135802469136, 'eval_f1': 0.8161888701517707, 'eval_accuracy': 0.9905242110753717, 'eval_runtime': 2.2226, 'eval_samples_per_second': 145.774, 'eval_steps_per_second': 9.448, 'epoch': 8.0}                                                                                                                        
{'loss': 0.017, 'grad_norm': 0.7888602614402771, 'learning_rate': 8.73015873015873e-06, 'epoch': 8.44}                                                                                                   
{'eval_loss': 0.022777577862143517, 'eval_precision': 0.8543689320388349, 'eval_recall': 0.8148148148148148, 'eval_f1': 0.8341232227488151, 'eval_accuracy': 0.9908719464487525, 'eval_runtime': 2.2313, 'eval_samples_per_second': 145.206, 'eval_steps_per_second': 9.412, 'epoch': 9.0}                                                                                                                        
{'loss': 0.0119, 'grad_norm': 1.1251357793807983, 'learning_rate': 5.122655122655123e-06, 'epoch': 9.09}                                                                                                 
{'loss': 0.0099, 'grad_norm': 0.5592589974403381, 'learning_rate': 1.5151515151515152e-06, 'epoch': 9.75}                                                                                                
{'eval_loss': 0.023780595511198044, 'eval_precision': 0.8594771241830066, 'eval_recall': 0.8117283950617284, 'eval_f1': 0.834920634920635, 'eval_accuracy': 0.9909588802920977, 'eval_runtime': 2.2391, 'eval_samples_per_second': 144.701, 'eval_steps_per_second': 9.379, 'epoch': 10.0}                                                                                                                        
{'train_runtime': 658.698, 'train_samples_per_second': 37.149, 'train_steps_per_second': 1.169, 'train_loss': 0.04962986210336933, 'epoch': 10.0}                                                        
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [10:58<00:00,  1.17it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 11.99it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.65it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 11.92it/s]

bert-base-italian-xxl-cased Results:
  Dev F1: 0.8349
  Dev Acc: 0.9910
  OOD F1: 0.6778
  OOD Acc: 0.9629
wandb: 
wandb: Run history:
wandb:   bert-base-italian-xxl-cased/best_batch_size â–
wandb:           bert-base-italian-xxl-cased/best_lr â–
wandb: bert-base-italian-xxl-cased/best_warmup_ratio â–
wandb: bert-base-italian-xxl-cased/best_weight_decay â–
wandb:      bert-base-italian-xxl-cased/dev_accuracy â–
wandb:            bert-base-italian-xxl-cased/dev_f1 â–
wandb:     bert-base-italian-xxl-cased/dev_precision â–
wandb:        bert-base-italian-xxl-cased/dev_recall â–
wandb:      bert-base-italian-xxl-cased/ood_accuracy â–
wandb:            bert-base-italian-xxl-cased/ood_f1 â–
wandb:                                           +15 ...
wandb: 
wandb: Run summary:
wandb:   bert-base-italian-xxl-cased/best_batch_size 8
wandb:           bert-base-italian-xxl-cased/best_lr 3e-05
wandb: bert-base-italian-xxl-cased/best_warmup_ratio 0.29138
wandb: bert-base-italian-xxl-cased/best_weight_decay 0.08006
wandb:      bert-base-italian-xxl-cased/dev_accuracy 0.99096
wandb:            bert-base-italian-xxl-cased/dev_f1 0.83492
wandb:     bert-base-italian-xxl-cased/dev_precision 0.85948
wandb:        bert-base-italian-xxl-cased/dev_recall 0.81173
wandb:      bert-base-italian-xxl-cased/ood_accuracy 0.96289
wandb:            bert-base-italian-xxl-cased/ood_f1 0.67778
wandb:                                           +20 ...
wandb: 
wandb: ðŸš€ View run bert-base-italian-xxl-cased_final at: https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder/runs/68q3wqbz
wandb: â­ï¸ View project at: https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251108_005603-68q3wqbz/logs

================================================================================
TRAINING: answerdotai/ModernBERT-base
================================================================================
Preparing datasets...
Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2447/2447 [00:00<00:00, 4312.80it/s]
Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 324/324 [00:00<00:00, 4783.97it/s]
Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:00<00:00, 4917.12it/s]

Hyperparameter tuning for ModernBERT-base...
[I 2025-11-08 01:07:11,393] A new study created in memory with name: ModernBERT-base_study
  0%|                                                                                                                                                                             | 0/20 [00:00<?, ?it/s]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.0631, 'grad_norm': 41.31413650512695, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                    
{'loss': 0.2291, 'grad_norm': 0.5273454785346985, 'learning_rate': 2.5250615775269622e-05, 'epoch': 0.65}                                                                                                
{'eval_loss': 0.06333592534065247, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.41975308641975306, 'eval_f1': 0.570230607966457, 'eval_accuracy': 0.9788725136555705, 'eval_runtime': 3.7485, 'eval_samples_per_second': 86.435, 'eval_steps_per_second': 5.602, 'epoch': 1.0}                                                                                                                          
{'loss': 0.0539, 'grad_norm': 0.2391543686389923, 'learning_rate': 3.78662707191569e-05, 'epoch': 1.3}                                                                                                   
{'loss': 0.0237, 'grad_norm': 0.23047077655792236, 'learning_rate': 3.504464100834044e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.017445076256990433, 'eval_precision': 0.9278350515463918, 'eval_recall': 0.8333333333333334, 'eval_f1': 0.8780487804878049, 'eval_accuracy': 0.9922704318252087, 'eval_runtime': 3.4851, 'eval_samples_per_second': 92.968, 'eval_steps_per_second': 6.026, 'epoch': 2.0}                                                                                                                         
{'loss': 0.012, 'grad_norm': 0.8331477046012878, 'learning_rate': 3.222301129752398e-05, 'epoch': 2.6}                                                                                                   
{'eval_loss': 0.00960321631282568, 'eval_precision': 0.959731543624161, 'eval_recall': 0.8827160493827161, 'eval_f1': 0.9196141479099679, 'eval_accuracy': 0.9948469545501392, 'eval_runtime': 3.4823, 'eval_samples_per_second': 93.043, 'eval_steps_per_second': 6.031, 'epoch': 3.0}                                                                                                                           
{'loss': 0.0094, 'grad_norm': 0.8306092023849487, 'learning_rate': 2.940138158670752e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0076, 'grad_norm': 0.21153515577316284, 'learning_rate': 2.657975187589106e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.007358472794294357, 'eval_precision': 0.9418960244648318, 'eval_recall': 0.9506172839506173, 'eval_f1': 0.946236559139785, 'eval_accuracy': 0.9963928681850974, 'eval_runtime': 3.4947, 'eval_samples_per_second': 92.712, 'eval_steps_per_second': 6.009, 'epoch': 4.0}                                                                                                                          
{'loss': 0.0069, 'grad_norm': 0.4614449739456177, 'learning_rate': 2.3758122165074598e-05, 'epoch': 4.55}                                                                                                
{'eval_loss': 0.008489745669066906, 'eval_precision': 0.9626168224299065, 'eval_recall': 0.9537037037037037, 'eval_f1': 0.958139534883721, 'eval_accuracy': 0.9972173554570751, 'eval_runtime': 3.4396, 'eval_samples_per_second': 94.197, 'eval_steps_per_second': 6.105, 'epoch': 5.0}                                                                                                                          
{'loss': 0.0031, 'grad_norm': 0.40240129828453064, 'learning_rate': 2.093649245425814e-05, 'epoch': 5.2}                                                                                                 
{'loss': 0.0031, 'grad_norm': 0.4943605065345764, 'learning_rate': 1.8114862743441676e-05, 'epoch': 5.85}                                                                                                
{'eval_loss': 0.004857982974499464, 'eval_precision': 0.9634146341463414, 'eval_recall': 0.9753086419753086, 'eval_f1': 0.9693251533742331, 'eval_accuracy': 0.9979387818200557, 'eval_runtime': 2.7379, 'eval_samples_per_second': 118.338, 'eval_steps_per_second': 7.67, 'epoch': 6.0}                                                                                                                         
{'loss': 0.0019, 'grad_norm': 0.13882684707641602, 'learning_rate': 1.5293233032625217e-05, 'epoch': 6.5}                                                                                                
{'eval_loss': 0.009049708023667336, 'eval_precision': 0.9716088328075709, 'eval_recall': 0.9506172839506173, 'eval_f1': 0.9609984399375975, 'eval_accuracy': 0.9974234772750695, 'eval_runtime': 2.8142, 'eval_samples_per_second': 115.132, 'eval_steps_per_second': 7.462, 'epoch': 7.0}                                                                                                                        
{'loss': 0.0021, 'grad_norm': 0.03573048859834671, 'learning_rate': 1.2471603321808754e-05, 'epoch': 7.14}                                                                                               
{'loss': 0.0014, 'grad_norm': 0.1160503551363945, 'learning_rate': 9.649973610992295e-06, 'epoch': 7.8}                                                                                                  
{'eval_loss': 0.00880762841552496, 'eval_precision': 0.9658385093167702, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9628482972136223, 'eval_accuracy': 0.9975265381840668, 'eval_runtime': 3.4732, 'eval_samples_per_second': 93.285, 'eval_steps_per_second': 6.046, 'epoch': 8.0}                                                                                                                          
{'loss': 0.0003, 'grad_norm': 0.010585784912109375, 'learning_rate': 6.828343900175835e-06, 'epoch': 8.44}                                                                                               
{'eval_loss': 0.01273186132311821, 'eval_precision': 0.9625, 'eval_recall': 0.9506172839506173, 'eval_f1': 0.9565217391304348, 'eval_accuracy': 0.9971142945480779, 'eval_runtime': 3.4819, 'eval_samples_per_second': 93.052, 'eval_steps_per_second': 6.031, 'epoch': 9.0}                                                                                                                                      
  0%|                                                                                                                                                                             | 0/20 [13:52<?, ?it/sCould not locate the best model at outputs/ModernBERT-base/checkpoint-462/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.3it/s]
{'train_runtime': 831.6398, 'train_samples_per_second': 29.424, 'train_steps_per_second': 0.926, 'train_loss': 0.026800426903139118, 'epoch': 9.0}                                                       
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 693/770 [13:51<01:32,  1.20s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:02<00:00,  7.38it/s]
[I 2025-11-08 01:21:08,706] Trial 0 finished with value: 0.9565217391304348 and parameters: {'lr': 3.916422038613247e-05, 'weight_decay': 0.06365336440496062, 'warmup_ratio': 0.09861874806327604, 'batch_size': 8}. Best is trial 0 with value: 0.9565217391304348.
Best trial: 0. Best value: 0.956522:   5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                      | 1/20 [13:57<4:25:08, 837.31s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 0.8778, 'grad_norm': 41.664302825927734, 'learning_rate': 0.0, 'epoch': 0.05}                                                                                                                   
{'eval_loss': 0.12153024971485138, 'eval_precision': 0.4888888888888889, 'eval_recall': 0.06790123456790123, 'eval_f1': 0.11924119241192412, 'eval_accuracy': 0.9665052045759044, 'eval_runtime': 2.9607, 'eval_samples_per_second': 109.432, 'eval_steps_per_second': 2.027, 'epoch': 1.0}                                                                                                                       
{'eval_loss': 0.08044642955064774, 'eval_precision': 0.6918604651162791, 'eval_recall': 0.36728395061728397, 'eval_f1': 0.4798387096774194, 'eval_accuracy': 0.9734102854787179, 'eval_runtime': 2.1431, 'eval_samples_per_second': 151.18, 'eval_steps_per_second': 2.8, 'epoch': 2.0}                                                                                                                           
{'loss': 0.1811, 'grad_norm': 0.2016369104385376, 'learning_rate': 1.9918674293856145e-05, 'epoch': 2.52}                                                                                                
{'eval_loss': 0.0575614869594574, 'eval_precision': 0.9141104294478528, 'eval_recall': 0.45987654320987653, 'eval_f1': 0.6119096509240246, 'eval_accuracy': 0.9805214881995259, 'eval_runtime': 2.4775, 'eval_samples_per_second': 130.779, 'eval_steps_per_second': 2.422, 'epoch': 3.0}                                                                                                                         
{'eval_loss': 0.03944878652691841, 'eval_precision': 0.9033816425120773, 'eval_recall': 0.5771604938271605, 'eval_f1': 0.704331450094162, 'eval_accuracy': 0.9838194372874369, 'eval_runtime': 2.9505, 'eval_samples_per_second': 109.812, 'eval_steps_per_second': 2.034, 'epoch': 4.0}                                                                                                                          
{'loss': 0.0444, 'grad_norm': 0.6339120268821716, 'learning_rate': 1.332308677933424e-05, 'epoch': 5.0}                                                                                                  
{'eval_loss': 0.03434067592024803, 'eval_precision': 0.823321554770318, 'eval_recall': 0.7191358024691358, 'eval_f1': 0.7677100494233937, 'eval_accuracy': 0.9854684118313923, 'eval_runtime': 2.948, 'eval_samples_per_second': 109.903, 'eval_steps_per_second': 2.035, 'epoch': 5.0}                                                                                                                           
{'eval_loss': 0.03102716989815235, 'eval_precision': 0.91701244813278, 'eval_recall': 0.6820987654320988, 'eval_f1': 0.7823008849557522, 'eval_accuracy': 0.9873235081933422, 'eval_runtime': 2.9582, 'eval_samples_per_second': 109.525, 'eval_steps_per_second': 2.028, 'epoch': 6.0}                                                                                                                           
{'eval_loss': 0.025095157325267792, 'eval_precision': 0.9051094890510949, 'eval_recall': 0.7654320987654321, 'eval_f1': 0.8294314381270903, 'eval_accuracy': 0.9894877872822838, 'eval_runtime': 2.9597, 'eval_samples_per_second': 109.47, 'eval_steps_per_second': 2.027, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0251, 'grad_norm': 0.34330663084983826, 'learning_rate': 6.72749926481234e-06, 'epoch': 7.52}                                                                                                 
{'eval_loss': 0.026696287095546722, 'eval_precision': 0.8966789667896679, 'eval_recall': 0.75, 'eval_f1': 0.8168067226890756, 'eval_accuracy': 0.9887663609193033, 'eval_runtime': 2.9501, 'eval_samples_per_second': 109.826, 'eval_steps_per_second': 2.034, 'epoch': 8.0}                                                                                                                                      
{'eval_loss': 0.02295820415019989, 'eval_precision': 0.8758169934640523, 'eval_recall': 0.8271604938271605, 'eval_f1': 0.8507936507936508, 'eval_accuracy': 0.9903122745542615, 'eval_runtime': 2.9685, 'eval_samples_per_second': 109.145, 'eval_steps_per_second': 2.021, 'epoch': 9.0}                                                                                                                         
{'loss': 0.0159, 'grad_norm': 0.7228196263313293, 'learning_rate': 1.3191175029043803e-07, 'epoch': 10.0}                                                                                                
{'eval_loss': 0.022479578852653503, 'eval_precision': 0.8782894736842105, 'eval_recall': 0.8240740740740741, 'eval_f1': 0.8503184713375797, 'eval_accuracy': 0.9903122745542615, 'eval_runtime': 2.9525, 'eval_samples_per_second': 109.737, 'eval_steps_per_second': 2.032, 'epoch': 10.0}                                                                                                                       
{'train_runtime': 785.4755, 'train_samples_per_second': 31.153, 'train_steps_per_second': 0.255, 'train_loss': 0.07012193411588669, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:05<00:00,  3.93s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.98it/s]
[I 2025-11-08 01:34:17,990] Trial 1 finished with value: 0.8507936507936508 and parameters: {'lr': 2.1765438797922276e-05, 'weight_decay': 0.07944398010854947, 'warmup_ratio': 0.17479767586661304, 'batch_size': 32}. Best is trial 0 with value: 0.9565217391304348.
Best trial: 0. Best value: 0.956522:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                | 2/20 [27:06<4:02:43, 809.06s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.4753, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.03}                                                                                                                                  
{'eval_loss': 0.0876498892903328, 'eval_precision': 0.5817307692307693, 'eval_recall': 0.3734567901234568, 'eval_f1': 0.4548872180451128, 'eval_accuracy': 0.970112336390807, 'eval_runtime': 3.0471, 'eval_samples_per_second': 106.33, 'eval_steps_per_second': 3.61, 'epoch': 1.0}                                                                                                                             
{'loss': 0.2431, 'grad_norm': 2.9914886951446533, 'learning_rate': 1.3918565488489613e-05, 'epoch': 1.29}                                                                                                
{'eval_loss': 0.07289004325866699, 'eval_precision': 0.7592592592592593, 'eval_recall': 0.37962962962962965, 'eval_f1': 0.5061728395061729, 'eval_accuracy': 0.9752653818406678, 'eval_runtime': 3.0522, 'eval_samples_per_second': 106.152, 'eval_steps_per_second': 3.604, 'epoch': 2.0}                                                                                                                        
{'loss': 0.0611, 'grad_norm': 0.830677330493927, 'learning_rate': 1.187772010894568e-05, 'epoch': 2.58}                                                                                                  
{'eval_loss': 0.044481370598077774, 'eval_precision': 0.8259109311740891, 'eval_recall': 0.6296296296296297, 'eval_f1': 0.7145359019264448, 'eval_accuracy': 0.9832010718334536, 'eval_runtime': 3.0422, 'eval_samples_per_second': 106.501, 'eval_steps_per_second': 3.616, 'epoch': 3.0}                                                                                                                        
{'loss': 0.034, 'grad_norm': 0.5761436820030212, 'learning_rate': 9.83687472940175e-06, 'epoch': 3.86}                                                                                                   
{'eval_loss': 0.02821466699242592, 'eval_precision': 0.9098039215686274, 'eval_recall': 0.7160493827160493, 'eval_f1': 0.8013816925734024, 'eval_accuracy': 0.98814799546532, 'eval_runtime': 3.0509, 'eval_samples_per_second': 106.198, 'eval_steps_per_second': 3.605, 'epoch': 4.0}                                                                                                                           
{'eval_loss': 0.019420618191361427, 'eval_precision': 0.9328859060402684, 'eval_recall': 0.8580246913580247, 'eval_f1': 0.8938906752411575, 'eval_accuracy': 0.9931979800061836, 'eval_runtime': 3.0709, 'eval_samples_per_second': 105.508, 'eval_steps_per_second': 3.582, 'epoch': 5.0}                                                                                                                        
{'loss': 0.018, 'grad_norm': 0.9414354562759399, 'learning_rate': 7.796029349857818e-06, 'epoch': 5.13}                                                                                                  
{'eval_loss': 0.017291462048888206, 'eval_precision': 0.926984126984127, 'eval_recall': 0.9012345679012346, 'eval_f1': 0.9139280125195618, 'eval_accuracy': 0.994331650005153, 'eval_runtime': 3.0582, 'eval_samples_per_second': 105.943, 'eval_steps_per_second': 3.597, 'epoch': 6.0}                                                                                                                          
{'loss': 0.0113, 'grad_norm': 3.092442512512207, 'learning_rate': 5.755183970313886e-06, 'epoch': 6.42}                                                                                                  
{'eval_loss': 0.01657082326710224, 'eval_precision': 0.9258064516129032, 'eval_recall': 0.8858024691358025, 'eval_f1': 0.9053627760252366, 'eval_accuracy': 0.993816345460167, 'eval_runtime': 3.0849, 'eval_samples_per_second': 105.027, 'eval_steps_per_second': 3.566, 'epoch': 7.0}                                                                                                                          
{'loss': 0.0081, 'grad_norm': 0.4995883107185364, 'learning_rate': 3.7143385907699552e-06, 'epoch': 7.71}                                                                                                
{'eval_loss': 0.017922930419445038, 'eval_precision': 0.9301587301587302, 'eval_recall': 0.904320987654321, 'eval_f1': 0.917057902973396, 'eval_accuracy': 0.9945377718231475, 'eval_runtime': 3.0754, 'eval_samples_per_second': 105.351, 'eval_steps_per_second': 3.577, 'epoch': 8.0}                                                                                                                          
{'loss': 0.0048, 'grad_norm': 0.9036582112312317, 'learning_rate': 1.6734932112260237e-06, 'epoch': 8.99}                                                                                                
{'eval_loss': 0.01604877971112728, 'eval_precision': 0.9516129032258065, 'eval_recall': 0.9104938271604939, 'eval_f1': 0.9305993690851735, 'eval_accuracy': 0.9954653200041225, 'eval_runtime': 3.0427, 'eval_samples_per_second': 106.486, 'eval_steps_per_second': 3.615, 'epoch': 9.0}                                                                                                                         
{'eval_loss': 0.016886118799448013, 'eval_precision': 0.9483870967741935, 'eval_recall': 0.9074074074074074, 'eval_f1': 0.9274447949526814, 'eval_accuracy': 0.995259198186128, 'eval_runtime': 3.0722, 'eval_samples_per_second': 105.462, 'eval_steps_per_second': 3.581, 'epoch': 10.0}                                                                                                                        
{'train_runtime': 845.817, 'train_samples_per_second': 28.931, 'train_steps_per_second': 0.461, 'train_loss': 0.05225992963100091, 'epoch': 10.0}                                                        
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [14:05<00:00,  2.17s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.69it/s]
[I 2025-11-08 01:48:27,756] Trial 2 finished with value: 0.9657320872274143 and parameters: {'lr': 1.4938988178261578e-05, 'weight_decay': 0.09437240530581059, 'warmup_ratio': 0.05915371742939515, 'batch_size': 16}. Best is trial 2 with value: 0.9657320872274143.
Best trial: 2. Best value: 0.965732:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                          | 3/20 [41:16<3:54:30, 827.65s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.4604, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.05}                                                                                                                                  
{'eval_loss': 0.13717982172966003, 'eval_precision': 0.5, 'eval_recall': 0.015432098765432098, 'eval_f1': 0.029940119760479042, 'eval_accuracy': 0.9666082654849015, 'eval_runtime': 1.6772, 'eval_samples_per_second': 193.174, 'eval_steps_per_second': 3.577, 'epoch': 1.0}                                                                                                                                    
{'eval_loss': 0.08297131210565567, 'eval_precision': 0.7112676056338029, 'eval_recall': 0.3117283950617284, 'eval_f1': 0.4334763948497854, 'eval_accuracy': 0.9727919200247346, 'eval_runtime': 2.9684, 'eval_samples_per_second': 109.149, 'eval_steps_per_second': 2.021, 'epoch': 2.0}                                                                                                                         
{'loss': 0.2693, 'grad_norm': 1.2951868772506714, 'learning_rate': 2.2321158337233622e-05, 'epoch': 2.52}                                                                                                
{'eval_loss': 0.06718992441892624, 'eval_precision': 0.6974358974358974, 'eval_recall': 0.41975308641975306, 'eval_f1': 0.5240847784200385, 'eval_accuracy': 0.9745439554776874, 'eval_runtime': 2.9989, 'eval_samples_per_second': 108.04, 'eval_steps_per_second': 2.001, 'epoch': 3.0}                                                                                                                         
{'eval_loss': 0.047348055988550186, 'eval_precision': 0.8066037735849056, 'eval_recall': 0.5277777777777778, 'eval_f1': 0.6380597014925373, 'eval_accuracy': 0.9800061836545398, 'eval_runtime': 2.9593, 'eval_samples_per_second': 109.486, 'eval_steps_per_second': 2.028, 'epoch': 4.0}                                                                                                                        
{'loss': 0.0481, 'grad_norm': 1.3096187114715576, 'learning_rate': 1.5748018983028405e-05, 'epoch': 5.0}                                                                                                 
{'eval_loss': 0.03143259137868881, 'eval_precision': 0.9004149377593361, 'eval_recall': 0.6697530864197531, 'eval_f1': 0.768141592920354, 'eval_accuracy': 0.9864990209213645, 'eval_runtime': 2.9982, 'eval_samples_per_second': 108.066, 'eval_steps_per_second': 2.001, 'epoch': 5.0}                                                                                                                          
{'eval_loss': 0.026653390377759933, 'eval_precision': 0.8653198653198653, 'eval_recall': 0.7932098765432098, 'eval_f1': 0.8276972624798712, 'eval_accuracy': 0.9889724827372978, 'eval_runtime': 2.9676, 'eval_samples_per_second': 109.179, 'eval_steps_per_second': 2.022, 'epoch': 6.0}                                                                                                                        
{'eval_loss': 0.017995821312069893, 'eval_precision': 0.9177631578947368, 'eval_recall': 0.8611111111111112, 'eval_f1': 0.8885350318471338, 'eval_accuracy': 0.9927857363701947, 'eval_runtime': 2.966, 'eval_samples_per_second': 109.239, 'eval_steps_per_second': 2.023, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0182, 'grad_norm': 1.0496113300323486, 'learning_rate': 7.951969981529195e-06, 'epoch': 7.52}                                                                                                 
{'eval_loss': 0.015373690985143185, 'eval_precision': 0.9235668789808917, 'eval_recall': 0.8950617283950617, 'eval_f1': 0.9090909090909091, 'eval_accuracy': 0.9940224672781613, 'eval_runtime': 2.945, 'eval_samples_per_second': 110.015, 'eval_steps_per_second': 2.037, 'epoch': 8.0}                                                                                                                         
{'eval_loss': 0.015849143266677856, 'eval_precision': 0.9076433121019108, 'eval_recall': 0.8796296296296297, 'eval_f1': 0.8934169278996865, 'eval_accuracy': 0.9929918581881892, 'eval_runtime': 2.959, 'eval_samples_per_second': 109.495, 'eval_steps_per_second': 2.028, 'epoch': 9.0}                                                                                                                         
{'loss': 0.0072, 'grad_norm': 0.4815521240234375, 'learning_rate': 1.559209800299842e-07, 'epoch': 10.0}                                                                                                 
{'eval_loss': 0.01486307941377163, 'eval_precision': 0.9294871794871795, 'eval_recall': 0.8950617283950617, 'eval_f1': 0.9119496855345912, 'eval_accuracy': 0.9942285890961559, 'eval_runtime': 2.9466, 'eval_samples_per_second': 109.956, 'eval_steps_per_second': 2.036, 'epoch': 10.0}                                                                                                                        
{'train_runtime': 779.6965, 'train_samples_per_second': 31.384, 'train_steps_per_second': 0.257, 'train_loss': 0.09164192855358123, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [12:59<00:00,  3.90s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.99it/s]
[I 2025-11-08 02:01:31,315] Trial 3 finished with value: 0.9119496855345912 and parameters: {'lr': 2.3232226024467647e-05, 'weight_decay': 0.07728797989467873, 'warmup_ratio': 0.2508802595551491, 'batch_size': 32}. Best is trial 2 with value: 0.9657320872274143.
Best trial: 2. Best value: 0.965732:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                    | 4/20 [54:19<3:36:03, 810.24s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.4604, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.05}                                                                                                                                  
{'eval_loss': 0.09518316388130188, 'eval_precision': 0.6929133858267716, 'eval_recall': 0.2716049382716049, 'eval_f1': 0.3902439024390244, 'eval_accuracy': 0.9716582500257652, 'eval_runtime': 2.9729, 'eval_samples_per_second': 108.983, 'eval_steps_per_second': 2.018, 'epoch': 1.0}                                                                                                                         
{'eval_loss': 0.06986302137374878, 'eval_precision': 0.6642335766423357, 'eval_recall': 0.2808641975308642, 'eval_f1': 0.3947939262472885, 'eval_accuracy': 0.9712460063897763, 'eval_runtime': 2.9548, 'eval_samples_per_second': 109.652, 'eval_steps_per_second': 2.031, 'epoch': 2.0}                                                                                                                         
{'loss': 0.1613, 'grad_norm': 0.15754005312919617, 'learning_rate': 2.255807070951441e-05, 'epoch': 2.52}                                                                                                
{'eval_loss': 0.060484085232019424, 'eval_precision': 0.711864406779661, 'eval_recall': 0.3888888888888889, 'eval_f1': 0.5029940119760479, 'eval_accuracy': 0.9743378336596928, 'eval_runtime': 1.9411, 'eval_samples_per_second': 166.914, 'eval_steps_per_second': 3.091, 'epoch': 3.0}                                                                                                                         
{'eval_loss': 0.03554074093699455, 'eval_precision': 0.8268551236749117, 'eval_recall': 0.7222222222222222, 'eval_f1': 0.771004942339374, 'eval_accuracy': 0.9856745336493868, 'eval_runtime': 2.6371, 'eval_samples_per_second': 122.862, 'eval_steps_per_second': 2.275, 'epoch': 4.0}                                                                                                                          
{'loss': 0.04, 'grad_norm': 1.2641371488571167, 'learning_rate': 1.5088510871926858e-05, 'epoch': 5.0}                                                                                                   
{'eval_loss': 0.04266798123717308, 'eval_precision': 0.7721088435374149, 'eval_recall': 0.7006172839506173, 'eval_f1': 0.7346278317152104, 'eval_accuracy': 0.9830980109244564, 'eval_runtime': 2.9489, 'eval_samples_per_second': 109.871, 'eval_steps_per_second': 2.035, 'epoch': 5.0}                                                                                                                         
{'eval_loss': 0.017520753666758537, 'eval_precision': 0.9228187919463087, 'eval_recall': 0.8487654320987654, 'eval_f1': 0.8842443729903537, 'eval_accuracy': 0.9925796145522003, 'eval_runtime': 2.9738, 'eval_samples_per_second': 108.952, 'eval_steps_per_second': 2.018, 'epoch': 6.0}                                                                                                                        
{'eval_loss': 0.01252685021609068, 'eval_precision': 0.9121212121212121, 'eval_recall': 0.9290123456790124, 'eval_f1': 0.9204892966360856, 'eval_accuracy': 0.9946408327321447, 'eval_runtime': 2.9447, 'eval_samples_per_second': 110.028, 'eval_steps_per_second': 2.038, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0156, 'grad_norm': 0.21152007579803467, 'learning_rate': 7.618951034339303e-06, 'epoch': 7.52}                                                                                                
{'eval_loss': 0.01384216733276844, 'eval_precision': 0.9310344827586207, 'eval_recall': 0.9166666666666666, 'eval_f1': 0.9237947122861586, 'eval_accuracy': 0.9949500154591363, 'eval_runtime': 2.979, 'eval_samples_per_second': 108.762, 'eval_steps_per_second': 2.014, 'epoch': 8.0}                                                                                                                          
{'eval_loss': 0.010594554245471954, 'eval_precision': 0.94375, 'eval_recall': 0.9320987654320988, 'eval_f1': 0.937888198757764, 'eval_accuracy': 0.9958775636401113, 'eval_runtime': 2.9752, 'eval_samples_per_second': 108.902, 'eval_steps_per_second': 2.017, 'epoch': 9.0}                                                                                                                                    
{'loss': 0.004, 'grad_norm': 0.4541817009449005, 'learning_rate': 1.4939119675175105e-07, 'epoch': 10.0}                                                                                                 
{'eval_loss': 0.009398921392858028, 'eval_precision': 0.9528301886792453, 'eval_recall': 0.9351851851851852, 'eval_f1': 0.9439252336448598, 'eval_accuracy': 0.9962898072761002, 'eval_runtime': 2.9357, 'eval_samples_per_second': 110.365, 'eval_steps_per_second': 2.044, 'epoch': 10.0}                                                                                                                       
{'train_runtime': 783.9047, 'train_samples_per_second': 31.216, 'train_steps_per_second': 0.255, 'train_loss': 0.061704845353960994, 'epoch': 10.0}                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [13:03<00:00,  3.92s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.97it/s]
[I 2025-11-08 02:14:43,076] Trial 4 finished with value: 0.9439252336448598 and parameters: {'lr': 2.823493618608095e-05, 'weight_decay': 0.08289936636356571, 'warmup_ratio': 0.05053707081154507, 'batch_size': 32}. Best is trial 2 with value: 0.9657320872274143.
Best trial: 2. Best value: 0.965732:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                            | 5/20 [1:07:31<3:20:53, 803.58s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.4753, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.03}                                                                                                                                  
{'eval_loss': 0.112965427339077, 'eval_precision': 0.6545454545454545, 'eval_recall': 0.2222222222222222, 'eval_f1': 0.3317972350230415, 'eval_accuracy': 0.970112336390807, 'eval_runtime': 3.0362, 'eval_samples_per_second': 106.714, 'eval_steps_per_second': 3.623, 'epoch': 1.0}                                                                                                                            
{'loss': 0.3164, 'grad_norm': 2.7189273834228516, 'learning_rate': 1.5895174437694096e-05, 'epoch': 1.29}                                                                                                
{'eval_loss': 0.07801862061023712, 'eval_precision': 0.5737051792828686, 'eval_recall': 0.4444444444444444, 'eval_f1': 0.5008695652173913, 'eval_accuracy': 0.9704215191177986, 'eval_runtime': 3.0651, 'eval_samples_per_second': 105.705, 'eval_steps_per_second': 3.589, 'epoch': 2.0}                                                                                                                         
{'loss': 0.0673, 'grad_norm': 0.38235893845558167, 'learning_rate': 3.211474019044317e-05, 'epoch': 2.58}                                                                                                
{'eval_loss': 0.03403668850660324, 'eval_precision': 0.9269406392694064, 'eval_recall': 0.6265432098765432, 'eval_f1': 0.7476979742173112, 'eval_accuracy': 0.9858806554673812, 'eval_runtime': 3.0816, 'eval_samples_per_second': 105.142, 'eval_steps_per_second': 3.57, 'epoch': 3.0}                                                                                                                          
{'loss': 0.0305, 'grad_norm': 0.48276495933532715, 'learning_rate': 2.768815037042207e-05, 'epoch': 3.86}                                                                                                
{'eval_loss': 0.01988052949309349, 'eval_precision': 0.8785942492012779, 'eval_recall': 0.8487654320987654, 'eval_f1': 0.8634222919937206, 'eval_accuracy': 0.9910337009172421, 'eval_runtime': 3.0844, 'eval_samples_per_second': 105.046, 'eval_steps_per_second': 3.566, 'epoch': 4.0}                                                                                                                         
{'eval_loss': 0.015675026923418045, 'eval_precision': 0.9548611111111112, 'eval_recall': 0.8487654320987654, 'eval_f1': 0.8986928104575164, 'eval_accuracy': 0.9936102236421726, 'eval_runtime': 3.0521, 'eval_samples_per_second': 106.155, 'eval_steps_per_second': 3.604, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0138, 'grad_norm': 1.5884965658187866, 'learning_rate': 2.1943720832990103e-05, 'epoch': 5.13}                                                                                                
{'eval_loss': 0.011925746686756611, 'eval_precision': 0.9485530546623794, 'eval_recall': 0.9104938271604939, 'eval_f1': 0.9291338582677166, 'eval_accuracy': 0.9953622590951252, 'eval_runtime': 3.0377, 'eval_samples_per_second': 106.66, 'eval_steps_per_second': 3.621, 'epoch': 6.0}                                                                                                                         
{'loss': 0.0082, 'grad_norm': 1.5993754863739014, 'learning_rate': 1.619929129555814e-05, 'epoch': 6.42}                                                                                                 
{'eval_loss': 0.012171278707683086, 'eval_precision': 0.9207317073170732, 'eval_recall': 0.9320987654320988, 'eval_f1': 0.9263803680981595, 'eval_accuracy': 0.9950530763681336, 'eval_runtime': 3.0692, 'eval_samples_per_second': 105.566, 'eval_steps_per_second': 3.584, 'epoch': 7.0}                                                                                                                        
{'loss': 0.0058, 'grad_norm': 0.3737912178039551, 'learning_rate': 1.0454861758126174e-05, 'epoch': 7.71}                                                                                                
{'eval_loss': 0.01064781192690134, 'eval_precision': 0.943217665615142, 'eval_recall': 0.9228395061728395, 'eval_f1': 0.9329173166926678, 'eval_accuracy': 0.9955683809131196, 'eval_runtime': 3.0456, 'eval_samples_per_second': 106.383, 'eval_steps_per_second': 3.612, 'epoch': 8.0}                                                                                                                          
{'loss': 0.0029, 'grad_norm': 0.7654417157173157, 'learning_rate': 4.710432220694211e-06, 'epoch': 8.99}                                                                                                 
{'eval_loss': 0.01027024257928133, 'eval_precision': 0.9612903225806452, 'eval_recall': 0.9197530864197531, 'eval_f1': 0.9400630914826499, 'eval_accuracy': 0.9960836854581058, 'eval_runtime': 3.046, 'eval_samples_per_second': 106.368, 'eval_steps_per_second': 3.611, 'epoch': 9.0}                                                                                                                          
{'eval_loss': 0.007808566093444824, 'eval_precision': 0.987012987012987, 'eval_recall': 0.9382716049382716, 'eval_f1': 0.9620253164556962, 'eval_accuracy': 0.9975265381840668, 'eval_runtime': 3.0947, 'eval_samples_per_second': 104.694, 'eval_steps_per_second': 3.554, 'epoch': 10.0}                                                                                                                        
{'train_runtime': 850.4041, 'train_samples_per_second': 28.775, 'train_steps_per_second': 0.459, 'train_loss': 0.06015709224037635, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [14:10<00:00,  2.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.68it/s]
[I 2025-11-08 02:28:57,640] Trial 5 finished with value: 0.9620253164556962 and parameters: {'lr': 3.3087914135608115e-05, 'weight_decay': 0.09338754187431908, 'warmup_ratio': 0.25922679873154036, 'batch_size': 16}. Best is trial 2 with value: 0.9657320872274143.
Best trial: 2. Best value: 0.965732:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                      | 6/20 [1:21:46<3:11:32, 820.91s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.4753, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.03}                                                                                                                                  
{'eval_loss': 0.11471668630838394, 'eval_precision': 0.6271186440677966, 'eval_recall': 0.3425925925925926, 'eval_f1': 0.4431137724550898, 'eval_accuracy': 0.9712460063897763, 'eval_runtime': 3.0712, 'eval_samples_per_second': 105.496, 'eval_steps_per_second': 3.582, 'epoch': 1.0}                                                                                                                         
{'loss': 0.3622, 'grad_norm': 9.154081344604492, 'learning_rate': 1.0398999391957541e-05, 'epoch': 1.29}                                                                                                 
{'eval_loss': 0.07787350565195084, 'eval_precision': 0.6613756613756614, 'eval_recall': 0.38580246913580246, 'eval_f1': 0.4873294346978557, 'eval_accuracy': 0.9728949809337318, 'eval_runtime': 3.0566, 'eval_samples_per_second': 106.001, 'eval_steps_per_second': 3.599, 'epoch': 2.0}                                                                                                                        
{'loss': 0.0719, 'grad_norm': 0.5644304156303406, 'learning_rate': 1.0354521208074063e-05, 'epoch': 2.58}                                                                                                
{'eval_loss': 0.06581128388643265, 'eval_precision': 0.74, 'eval_recall': 0.4567901234567901, 'eval_f1': 0.5648854961832062, 'eval_accuracy': 0.9765021127486344, 'eval_runtime': 2.0095, 'eval_samples_per_second': 161.235, 'eval_steps_per_second': 5.474, 'epoch': 3.0}                                                                                                                                       
{'loss': 0.0517, 'grad_norm': 0.37748321890830994, 'learning_rate': 8.575393852734877e-06, 'epoch': 3.86}                                                                                                
{'eval_loss': 0.039050690829753876, 'eval_precision': 0.8949771689497716, 'eval_recall': 0.6049382716049383, 'eval_f1': 0.7219152854511971, 'eval_accuracy': 0.9844378027414202, 'eval_runtime': 1.9678, 'eval_samples_per_second': 164.651, 'eval_steps_per_second': 5.59, 'epoch': 4.0}                                                                                                                         
{'eval_loss': 0.030621401965618134, 'eval_precision': 0.8637992831541219, 'eval_recall': 0.7438271604938271, 'eval_f1': 0.7993366500829188, 'eval_accuracy': 0.9875296300113366, 'eval_runtime': 1.9734, 'eval_samples_per_second': 164.187, 'eval_steps_per_second': 5.574, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0303, 'grad_norm': 0.36443254351615906, 'learning_rate': 6.79626649739569e-06, 'epoch': 5.13}                                                                                                 
{'eval_loss': 0.02507217787206173, 'eval_precision': 0.8636363636363636, 'eval_recall': 0.8209876543209876, 'eval_f1': 0.8417721518987342, 'eval_accuracy': 0.9896939091002782, 'eval_runtime': 1.9597, 'eval_samples_per_second': 165.332, 'eval_steps_per_second': 5.613, 'epoch': 6.0}                                                                                                                         
{'loss': 0.0201, 'grad_norm': 0.7937950491905212, 'learning_rate': 5.017139142056504e-06, 'epoch': 6.42}                                                                                                 
{'eval_loss': 0.02089882828295231, 'eval_precision': 0.9175257731958762, 'eval_recall': 0.8240740740740741, 'eval_f1': 0.8682926829268293, 'eval_accuracy': 0.9916520663712254, 'eval_runtime': 1.9674, 'eval_samples_per_second': 164.682, 'eval_steps_per_second': 5.591, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0138, 'grad_norm': 0.7667312622070312, 'learning_rate': 3.2380117867173183e-06, 'epoch': 7.71}                                                                                                
{'eval_loss': 0.01998543180525303, 'eval_precision': 0.9220338983050848, 'eval_recall': 0.8395061728395061, 'eval_f1': 0.8788368336025848, 'eval_accuracy': 0.9922704318252087, 'eval_runtime': 1.9441, 'eval_samples_per_second': 166.656, 'eval_steps_per_second': 5.658, 'epoch': 8.0}                                                                                                                         
{'loss': 0.009, 'grad_norm': 0.6306845545768738, 'learning_rate': 1.4588844313781325e-06, 'epoch': 8.99}                                                                                                 
{'eval_loss': 0.018904240801930428, 'eval_precision': 0.9305555555555556, 'eval_recall': 0.8271604938271605, 'eval_f1': 0.8758169934640523, 'eval_accuracy': 0.9921673709162114, 'eval_runtime': 1.9674, 'eval_samples_per_second': 164.68, 'eval_steps_per_second': 5.591, 'epoch': 9.0}                                                                                                                         
{'eval_loss': 0.018971053883433342, 'eval_precision': 0.9261744966442953, 'eval_recall': 0.8518518518518519, 'eval_f1': 0.887459807073955, 'eval_accuracy': 0.9927857363701947, 'eval_runtime': 1.9226, 'eval_samples_per_second': 168.523, 'eval_steps_per_second': 5.721, 'epoch': 10.0}                                                                                                                        
{'train_runtime': 594.7957, 'train_samples_per_second': 41.14, 'train_steps_per_second': 0.656, 'train_loss': 0.07524037215954218, 'epoch': 10.0}                                                        
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [09:54<00:00,  1.53s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  8.33it/s]
[I 2025-11-08 02:38:55,340] Trial 6 finished with value: 0.887459807073955 and parameters: {'lr': 1.1884570733665762e-05, 'weight_decay': 0.0033757084618920245, 'warmup_ratio': 0.14171546748925465, 'batch_size': 16}. Best is trial 2 with value: 0.9657320872274143.
Best trial: 2. Best value: 0.965732:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                | 7/20 [1:31:43<2:42:03, 747.94s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.4006, 'grad_norm': 1.296099066734314, 'learning_rate': 8.421188083266363e-06, 'epoch': 0.65}                                                                                                  
{'eval_loss': 0.08565505594015121, 'eval_precision': 0.6025641025641025, 'eval_recall': 0.4351851851851852, 'eval_f1': 0.5053763440860215, 'eval_accuracy': 0.971555189116768, 'eval_runtime': 2.1687, 'eval_samples_per_second': 149.395, 'eval_steps_per_second': 9.683, 'epoch': 1.0}                                                                                                                          
{'loss': 0.0786, 'grad_norm': 0.4227561354637146, 'learning_rate': 1.7014237147823877e-05, 'epoch': 1.3}                                                                                                 
{'loss': 0.0475, 'grad_norm': 1.4635474681854248, 'learning_rate': 2.5607286212381392e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.03832170367240906, 'eval_precision': 0.9148936170212766, 'eval_recall': 0.6635802469135802, 'eval_f1': 0.7692307692307693, 'eval_accuracy': 0.9867051427393589, 'eval_runtime': 2.1634, 'eval_samples_per_second': 149.761, 'eval_steps_per_second': 9.707, 'epoch': 2.0}                                                                                                                         
{'loss': 0.0278, 'grad_norm': 0.905055582523346, 'learning_rate': 2.5133476981741845e-05, 'epoch': 2.6}                                                                                                  
{'eval_loss': 0.01183296088129282, 'eval_precision': 0.9593220338983051, 'eval_recall': 0.8734567901234568, 'eval_f1': 0.9143780290791599, 'eval_accuracy': 0.9945377718231475, 'eval_runtime': 2.1658, 'eval_samples_per_second': 149.6, 'eval_steps_per_second': 9.696, 'epoch': 3.0}                                                                                                                           
{'loss': 0.0145, 'grad_norm': 0.6696469783782959, 'learning_rate': 2.2932647123445707e-05, 'epoch': 3.25}                                                                                                
{'loss': 0.0091, 'grad_norm': 0.8218445181846619, 'learning_rate': 2.0731817265149576e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.009832869283854961, 'eval_precision': 0.9616613418530351, 'eval_recall': 0.9290123456790124, 'eval_f1': 0.945054945054945, 'eval_accuracy': 0.9963928681850974, 'eval_runtime': 2.1377, 'eval_samples_per_second': 151.567, 'eval_steps_per_second': 9.824, 'epoch': 4.0}                                                                                                                         
{'loss': 0.0088, 'grad_norm': 0.3848358392715454, 'learning_rate': 1.8530987406853445e-05, 'epoch': 4.55}                                                                                                
{'eval_loss': 0.010331599973142147, 'eval_precision': 0.9678456591639871, 'eval_recall': 0.9290123456790124, 'eval_f1': 0.9480314960629921, 'eval_accuracy': 0.9965989900030918, 'eval_runtime': 2.1421, 'eval_samples_per_second': 151.254, 'eval_steps_per_second': 9.803, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0071, 'grad_norm': 0.18154984712600708, 'learning_rate': 1.633015754855731e-05, 'epoch': 5.2}                                                                                                 
{'loss': 0.0048, 'grad_norm': 0.10496688634157181, 'learning_rate': 1.4129327690261175e-05, 'epoch': 5.85}                                                                                               
{'eval_loss': 0.00799291767179966, 'eval_precision': 0.9592476489028213, 'eval_recall': 0.9444444444444444, 'eval_f1': 0.9517884914463453, 'eval_accuracy': 0.9968051118210862, 'eval_runtime': 2.1851, 'eval_samples_per_second': 148.28, 'eval_steps_per_second': 9.611, 'epoch': 6.0}                                                                                                                          
{'loss': 0.002, 'grad_norm': 0.09697991609573364, 'learning_rate': 1.1928497831965044e-05, 'epoch': 6.5}                                                                                                 
{'eval_loss': 0.021668151021003723, 'eval_precision': 0.9009584664536742, 'eval_recall': 0.8703703703703703, 'eval_f1': 0.8854003139717426, 'eval_accuracy': 0.9924765536432031, 'eval_runtime': 2.158, 'eval_samples_per_second': 150.139, 'eval_steps_per_second': 9.731, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0039, 'grad_norm': 0.03463592752814293, 'learning_rate': 9.727667973668911e-06, 'epoch': 7.14}                                                                                                
{'loss': 0.0016, 'grad_norm': 0.058259304612874985, 'learning_rate': 7.526838115372776e-06, 'epoch': 7.8}                                                                                                
{'eval_loss': 0.005482925567775965, 'eval_precision': 0.9935064935064936, 'eval_recall': 0.9444444444444444, 'eval_f1': 0.9683544303797469, 'eval_accuracy': 0.9979387818200557, 'eval_runtime': 2.1128, 'eval_samples_per_second': 153.352, 'eval_steps_per_second': 9.939, 'epoch': 8.0}                                                                                                                        
{'loss': 0.0016, 'grad_norm': 0.028030529618263245, 'learning_rate': 5.326008257076643e-06, 'epoch': 8.44}                                                                                               
{'eval_loss': 0.004846047610044479, 'eval_precision': 0.9842767295597484, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.9750778816199377, 'eval_accuracy': 0.9983510254560445, 'eval_runtime': 2.1414, 'eval_samples_per_second': 151.304, 'eval_steps_per_second': 9.807, 'epoch': 9.0}                                                                                                                        
{'loss': 0.001, 'grad_norm': 0.03811517357826233, 'learning_rate': 3.1251783987805095e-06, 'epoch': 9.09}                                                                                                
{'loss': 0.0004, 'grad_norm': 0.027785329148173332, 'learning_rate': 9.24348540484376e-07, 'epoch': 9.75}                                                                                                
{'eval_loss': 0.0048637851141393185, 'eval_precision': 0.9873417721518988, 'eval_recall': 0.9629629629629629, 'eval_f1': 0.975, 'eval_accuracy': 0.9983510254560445, 'eval_runtime': 2.131, 'eval_samples_per_second': 152.042, 'eval_steps_per_second': 9.855, 'epoch': 10.0}                                                                                                                                    
{'train_runtime': 543.6121, 'train_samples_per_second': 45.014, 'train_steps_per_second': 1.416, 'train_loss': 0.04102244464765218, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [09:03<00:00,  1.42it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 13.33it/s]
[I 2025-11-08 02:48:01,861] Trial 7 finished with value: 0.9750778816199377 and parameters: {'lr': 2.6982174062710595e-05, 'weight_decay': 0.06360772982103924, 'warmup_ratio': 0.20376868613392649, 'batch_size': 8}. Best is trial 7 with value: 0.9750778816199377.
Best trial: 7. Best value: 0.975078:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                         | 8/20 [1:40:50<2:16:45, 683.82s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.2281, 'grad_norm': 1.3907086849212646, 'learning_rate': 4.373536794587831e-05, 'epoch': 0.65}                                                                                                 
{'eval_loss': 0.052316199988126755, 'eval_precision': 0.9308176100628931, 'eval_recall': 0.4567901234567901, 'eval_f1': 0.6128364389233955, 'eval_accuracy': 0.9807276100175204, 'eval_runtime': 2.1549, 'eval_samples_per_second': 150.354, 'eval_steps_per_second': 9.745, 'epoch': 1.0}                                                                                                                        
{'loss': 0.0527, 'grad_norm': 0.29112663865089417, 'learning_rate': 8.836329442126434e-05, 'epoch': 1.3}                                                                                                 
{'loss': 0.02, 'grad_norm': 0.2734830975532532, 'learning_rate': 8.272818609317829e-05, 'epoch': 1.95}                                                                                                   
{'eval_loss': 0.015690170228481293, 'eval_precision': 0.9881422924901185, 'eval_recall': 0.7716049382716049, 'eval_f1': 0.8665511265164645, 'eval_accuracy': 0.9920643100072143, 'eval_runtime': 2.1459, 'eval_samples_per_second': 150.985, 'eval_steps_per_second': 9.786, 'epoch': 2.0}                                                                                                                        
{'loss': 0.0141, 'grad_norm': 0.25237542390823364, 'learning_rate': 7.60673015446132e-05, 'epoch': 2.6}                                                                                                  
{'eval_loss': 0.0062881032936275005, 'eval_precision': 0.9870967741935484, 'eval_recall': 0.9444444444444444, 'eval_f1': 0.9652996845425867, 'eval_accuracy': 0.9977326600020612, 'eval_runtime': 2.1373, 'eval_samples_per_second': 151.592, 'eval_steps_per_second': 9.825, 'epoch': 3.0}                                                                                                                       
{'loss': 0.0092, 'grad_norm': 1.3945950269699097, 'learning_rate': 6.940641699604813e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0075, 'grad_norm': 0.27419307827949524, 'learning_rate': 6.274553244748305e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.004276950377970934, 'eval_precision': 0.9810725552050473, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9703588143525741, 'eval_accuracy': 0.9980418427290528, 'eval_runtime': 2.151, 'eval_samples_per_second': 150.625, 'eval_steps_per_second': 9.763, 'epoch': 4.0}                                                                                                                         
{'loss': 0.0071, 'grad_norm': 0.2912459373474121, 'learning_rate': 5.608464789891797e-05, 'epoch': 4.55}                                                                                                 
{'eval_loss': 0.007029665634036064, 'eval_precision': 0.9442724458204335, 'eval_recall': 0.941358024691358, 'eval_f1': 0.9428129829984544, 'eval_accuracy': 0.9961867463671029, 'eval_runtime': 1.909, 'eval_samples_per_second': 169.722, 'eval_steps_per_second': 11.0, 'epoch': 5.0}                                                                                                                           
{'loss': 0.0041, 'grad_norm': 0.42007899284362793, 'learning_rate': 4.942376335035289e-05, 'epoch': 5.2}                                                                                                 
{'loss': 0.0044, 'grad_norm': 0.4775455892086029, 'learning_rate': 4.276287880178781e-05, 'epoch': 5.85}                                                                                                 
{'eval_loss': 0.01156993955373764, 'eval_precision': 0.91875, 'eval_recall': 0.9074074074074074, 'eval_f1': 0.9130434782608695, 'eval_accuracy': 0.9942285890961559, 'eval_runtime': 1.9061, 'eval_samples_per_second': 169.982, 'eval_steps_per_second': 11.017, 'epoch': 6.0}                                                                                                                                   
{'loss': 0.004, 'grad_norm': 0.03422054275870323, 'learning_rate': 3.6101994253222734e-05, 'epoch': 6.5}                                                                                                 
{'eval_loss': 0.004601289983838797, 'eval_precision': 0.9873817034700315, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.9765990639625585, 'eval_accuracy': 0.9984540863650417, 'eval_runtime': 1.8708, 'eval_samples_per_second': 173.19, 'eval_steps_per_second': 11.225, 'epoch': 7.0}                                                                                                                        
{'loss': 0.0017, 'grad_norm': 0.018852559849619865, 'learning_rate': 2.9441109704657652e-05, 'epoch': 7.14}                                                                                              
{'loss': 0.0011, 'grad_norm': 0.06988491117954254, 'learning_rate': 2.2780225156092574e-05, 'epoch': 7.8}                                                                                                
{'eval_loss': 0.005510907620191574, 'eval_precision': 0.9903846153846154, 'eval_recall': 0.9537037037037037, 'eval_f1': 0.9716981132075472, 'eval_accuracy': 0.9981449036380501, 'eval_runtime': 1.8977, 'eval_samples_per_second': 170.732, 'eval_steps_per_second': 11.066, 'epoch': 8.0}                                                                                                                       
{'loss': 0.0002, 'grad_norm': 0.0035787750966846943, 'learning_rate': 1.6119340607527493e-05, 'epoch': 8.44}                                                                                             
{'eval_loss': 0.00473764119669795, 'eval_precision': 0.9936507936507937, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.9796557120500783, 'eval_accuracy': 0.9986602081830361, 'eval_runtime': 1.8982, 'eval_samples_per_second': 170.685, 'eval_steps_per_second': 11.063, 'epoch': 9.0}                                                                                                                        
{'loss': 0.0004, 'grad_norm': 0.016192516312003136, 'learning_rate': 9.458456058962413e-06, 'epoch': 9.09}                                                                                               
{'loss': 0.0001, 'grad_norm': 0.05646957829594612, 'learning_rate': 2.797571510397333e-06, 'epoch': 9.75}                                                                                                
{'eval_loss': 0.005017099902033806, 'eval_precision': 0.9904761904761905, 'eval_recall': 0.9629629629629629, 'eval_f1': 0.9765258215962441, 'eval_accuracy': 0.9984540863650417, 'eval_runtime': 1.8905, 'eval_samples_per_second': 171.385, 'eval_steps_per_second': 11.108, 'epoch': 10.0}                                                                                                                      
{'train_runtime': 496.7364, 'train_samples_per_second': 49.262, 'train_steps_per_second': 1.55, 'train_loss': 0.024706383757051323, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [08:16<00:00,  1.55it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.11it/s]
[I 2025-11-08 02:56:21,243] Trial 8 finished with value: 0.9796557120500783 and parameters: {'lr': 8.925585295077206e-05, 'weight_decay': 0.044695455161333164, 'warmup_ratio': 0.1287069872091781, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                   | 9/20 [1:49:09<1:54:47, 626.16s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.4753, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.03}                                                                                                                                  
{'eval_loss': 0.12434640526771545, 'eval_precision': 0.6206896551724138, 'eval_recall': 0.2222222222222222, 'eval_f1': 0.32727272727272727, 'eval_accuracy': 0.9694939709368237, 'eval_runtime': 1.7053, 'eval_samples_per_second': 189.991, 'eval_steps_per_second': 6.45, 'epoch': 1.0}                                                                                                                         
{'loss': 0.4109, 'grad_norm': 0.9871952533721924, 'learning_rate': 7.158464574604968e-06, 'epoch': 1.29}                                                                                                 
{'eval_loss': 0.08820120245218277, 'eval_precision': 0.6458333333333334, 'eval_recall': 0.28703703703703703, 'eval_f1': 0.3974358974358974, 'eval_accuracy': 0.9709368236627847, 'eval_runtime': 1.6895, 'eval_samples_per_second': 191.768, 'eval_steps_per_second': 6.511, 'epoch': 2.0}                                                                                                                        
{'loss': 0.0807, 'grad_norm': 1.9426817893981934, 'learning_rate': 1.3881637259208967e-05, 'epoch': 2.58}                                                                                                
{'eval_loss': 0.07655836641788483, 'eval_precision': 0.695906432748538, 'eval_recall': 0.36728395061728397, 'eval_f1': 0.4808080808080808, 'eval_accuracy': 0.9735133463877151, 'eval_runtime': 1.74, 'eval_samples_per_second': 186.21, 'eval_steps_per_second': 6.322, 'epoch': 3.0}                                                                                                                            
{'loss': 0.0646, 'grad_norm': 2.9509310722351074, 'learning_rate': 1.149647621810777e-05, 'epoch': 3.86}                                                                                                 
{'eval_loss': 0.06206945702433586, 'eval_precision': 0.7680412371134021, 'eval_recall': 0.45987654320987653, 'eval_f1': 0.5752895752895753, 'eval_accuracy': 0.9773266000206122, 'eval_runtime': 1.706, 'eval_samples_per_second': 189.922, 'eval_steps_per_second': 6.448, 'epoch': 4.0}                                                                                                                         
{'eval_loss': 0.04295722395181656, 'eval_precision': 0.831275720164609, 'eval_recall': 0.6234567901234568, 'eval_f1': 0.7125220458553791, 'eval_accuracy': 0.9832010718334536, 'eval_runtime': 1.735, 'eval_samples_per_second': 186.74, 'eval_steps_per_second': 6.34, 'epoch': 5.0}                                                                                                                             
{'loss': 0.0463, 'grad_norm': 1.1103160381317139, 'learning_rate': 9.111315177006574e-06, 'epoch': 5.13}                                                                                                 
{'eval_loss': 0.03011929616332054, 'eval_precision': 0.8438538205980066, 'eval_recall': 0.7839506172839507, 'eval_f1': 0.8128, 'eval_accuracy': 0.9879418736473256, 'eval_runtime': 1.7032, 'eval_samples_per_second': 190.23, 'eval_steps_per_second': 6.458, 'epoch': 6.0}                                                                                                                                      
{'loss': 0.0267, 'grad_norm': 0.7316149473190308, 'learning_rate': 6.726154135905376e-06, 'epoch': 6.42}                                                                                                 
{'eval_loss': 0.024790823459625244, 'eval_precision': 0.8653198653198653, 'eval_recall': 0.7932098765432098, 'eval_f1': 0.8276972624798712, 'eval_accuracy': 0.9889724827372978, 'eval_runtime': 1.7134, 'eval_samples_per_second': 189.094, 'eval_steps_per_second': 6.42, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0163, 'grad_norm': 0.607079029083252, 'learning_rate': 4.340993094804179e-06, 'epoch': 7.71}                                                                                                  
{'eval_loss': 0.020260322839021683, 'eval_precision': 0.8993506493506493, 'eval_recall': 0.8549382716049383, 'eval_f1': 0.8765822784810127, 'eval_accuracy': 0.991961249098217, 'eval_runtime': 1.7083, 'eval_samples_per_second': 189.658, 'eval_steps_per_second': 6.439, 'epoch': 8.0}                                                                                                                         
{'loss': 0.0094, 'grad_norm': 0.44685959815979004, 'learning_rate': 1.9558320537029815e-06, 'epoch': 8.99}                                                                                               
{'eval_loss': 0.016165979206562042, 'eval_precision': 0.9253246753246753, 'eval_recall': 0.8796296296296297, 'eval_f1': 0.9018987341772152, 'eval_accuracy': 0.9936102236421726, 'eval_runtime': 1.7157, 'eval_samples_per_second': 188.843, 'eval_steps_per_second': 6.411, 'epoch': 9.0}                                                                                                                        
{'eval_loss': 0.015580862760543823, 'eval_precision': 0.9262820512820513, 'eval_recall': 0.8919753086419753, 'eval_f1': 0.9088050314465409, 'eval_accuracy': 0.9940224672781613, 'eval_runtime': 1.7099, 'eval_samples_per_second': 189.48, 'eval_steps_per_second': 6.433, 'epoch': 10.0}                                                                                                                        
{'train_runtime': 420.5504, 'train_samples_per_second': 58.186, 'train_steps_per_second': 0.927, 'train_loss': 0.08733426355398619, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [07:00<00:00,  1.08s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00,  9.88it/s]
[I 2025-11-08 03:03:24,269] Trial 9 finished with value: 0.9088050314465409 and parameters: {'lr': 1.402474692167504e-05, 'weight_decay': 0.08412451458079678, 'warmup_ratio': 0.24423555762750374, 'batch_size': 16}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                             | 10/20 [1:56:12<1:33:54, 563.45s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.1008, 'grad_norm': 0.28913599252700806, 'learning_rate': 8.966557572403242e-05, 'epoch': 0.65}                                                                                                
{'eval_loss': 0.020678438246250153, 'eval_precision': 0.9205776173285198, 'eval_recall': 0.7870370370370371, 'eval_f1': 0.848585690515807, 'eval_accuracy': 0.9906214572812532, 'eval_runtime': 1.8638, 'eval_samples_per_second': 173.835, 'eval_steps_per_second': 11.267, 'epoch': 1.0}                                                                                                                        
{'loss': 0.0263, 'grad_norm': 0.17911522090435028, 'learning_rate': 8.344743593734501e-05, 'epoch': 1.3}                                                                                                 
{'loss': 0.0185, 'grad_norm': 0.38741248846054077, 'learning_rate': 7.72292961506576e-05, 'epoch': 1.95}                                                                                                 
{'eval_loss': 0.011624620296061039, 'eval_precision': 0.9536423841059603, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.9201277955271565, 'eval_accuracy': 0.9948469545501392, 'eval_runtime': 1.8927, 'eval_samples_per_second': 171.182, 'eval_steps_per_second': 11.095, 'epoch': 2.0}                                                                                                                       
{'loss': 0.0106, 'grad_norm': 0.3543032109737396, 'learning_rate': 7.10111563639702e-05, 'epoch': 2.6}                                                                                                   
{'eval_loss': 0.006023391615599394, 'eval_precision': 0.9620253164556962, 'eval_recall': 0.9382716049382716, 'eval_f1': 0.95, 'eval_accuracy': 0.9967020509120891, 'eval_runtime': 1.885, 'eval_samples_per_second': 171.885, 'eval_steps_per_second': 11.141, 'epoch': 3.0}                                                                                                                                      
{'loss': 0.0081, 'grad_norm': 0.1607065349817276, 'learning_rate': 6.479301657728279e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0057, 'grad_norm': 0.43753448128700256, 'learning_rate': 5.857487679059538e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.005972534418106079, 'eval_precision': 0.971875, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9658385093167702, 'eval_accuracy': 0.9977326600020612, 'eval_runtime': 1.8789, 'eval_samples_per_second': 172.438, 'eval_steps_per_second': 11.177, 'epoch': 4.0}                                                                                                                                 
{'loss': 0.0078, 'grad_norm': 0.8415619134902954, 'learning_rate': 5.2356737003907974e-05, 'epoch': 4.55}                                                                                                
{'eval_loss': 0.008595744147896767, 'eval_precision': 0.9290123456790124, 'eval_recall': 0.9290123456790124, 'eval_f1': 0.9290123456790124, 'eval_accuracy': 0.995259198186128, 'eval_runtime': 1.8761, 'eval_samples_per_second': 172.697, 'eval_steps_per_second': 11.193, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0044, 'grad_norm': 0.033934518694877625, 'learning_rate': 4.613859721722057e-05, 'epoch': 5.2}                                                                                                
{'loss': 0.0039, 'grad_norm': 0.04078055918216705, 'learning_rate': 3.992045743053316e-05, 'epoch': 5.85}                                                                                                
{'eval_loss': 0.0064817327074706554, 'eval_precision': 0.9775641025641025, 'eval_recall': 0.941358024691358, 'eval_f1': 0.9591194968553459, 'eval_accuracy': 0.9973204163660724, 'eval_runtime': 1.8919, 'eval_samples_per_second': 171.257, 'eval_steps_per_second': 11.1, 'epoch': 6.0}                                                                                                                         
{'loss': 0.002, 'grad_norm': 0.05915895476937294, 'learning_rate': 3.3702317643845746e-05, 'epoch': 6.5}                                                                                                 
{'eval_loss': 0.013297007419168949, 'eval_precision': 0.9331210191082803, 'eval_recall': 0.904320987654321, 'eval_f1': 0.9184952978056427, 'eval_accuracy': 0.9946408327321447, 'eval_runtime': 1.8848, 'eval_samples_per_second': 171.9, 'eval_steps_per_second': 11.142, 'epoch': 7.0}                                                                                                                          
{'train_runtime': 317.1398, 'train_samples_per_second': 77.158, 'train_steps_per_second': 2.428, 'train_loss': 0.020271392210848036, 'epoch': 7.0}                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 539/770 [05:17<02:15,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.14it/s]
[I 2025-11-08 03:08:44,111] Trial 10 finished with value: 0.9658385093167702 and parameters: {'lr': 9.526190153205109e-05, 'weight_decay': 0.025124693501219934, 'warmup_ratio': 0.004753052569526267, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                       | 11/20 [2:01:32<1:13:20, 488.89s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 0.9085, 'grad_norm': 35.31827163696289, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                    
{'loss': 0.2184, 'grad_norm': 1.0787333250045776, 'learning_rate': 1.898639112462487e-05, 'epoch': 0.65}                                                                                                 
{'eval_loss': 0.07347903400659561, 'eval_precision': 0.7076023391812866, 'eval_recall': 0.3734567901234568, 'eval_f1': 0.4888888888888889, 'eval_accuracy': 0.973925590023704, 'eval_runtime': 1.8546, 'eval_samples_per_second': 174.703, 'eval_steps_per_second': 11.323, 'epoch': 1.0}                                                                                                                         
{'loss': 0.0683, 'grad_norm': 0.4549991488456726, 'learning_rate': 3.836025961914004e-05, 'epoch': 1.3}                                                                                                  
{'loss': 0.0362, 'grad_norm': 0.5718110203742981, 'learning_rate': 5.58246396348358e-05, 'epoch': 1.95}                                                                                                  
{'eval_loss': 0.04869873449206352, 'eval_precision': 0.7439446366782007, 'eval_recall': 0.6635802469135802, 'eval_f1': 0.7014681892332789, 'eval_accuracy': 0.9811398536535092, 'eval_runtime': 1.8834, 'eval_samples_per_second': 172.026, 'eval_steps_per_second': 11.15, 'epoch': 2.0}                                                                                                                         
{'loss': 0.0199, 'grad_norm': 0.20480172336101532, 'learning_rate': 5.1329902144108273e-05, 'epoch': 2.6}                                                                                                
{'eval_loss': 0.0161115862429142, 'eval_precision': 0.8963414634146342, 'eval_recall': 0.9074074074074074, 'eval_f1': 0.901840490797546, 'eval_accuracy': 0.993404101824178, 'eval_runtime': 1.8862, 'eval_samples_per_second': 171.77, 'eval_steps_per_second': 11.133, 'epoch': 3.0}                                                                                                                            
{'loss': 0.0139, 'grad_norm': 0.6030291318893433, 'learning_rate': 4.683516465338076e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0088, 'grad_norm': 0.12159062922000885, 'learning_rate': 4.234042716265324e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.007903923280537128, 'eval_precision': 0.9300911854103343, 'eval_recall': 0.9444444444444444, 'eval_f1': 0.9372128637059725, 'eval_accuracy': 0.9957745027311141, 'eval_runtime': 1.8995, 'eval_samples_per_second': 170.574, 'eval_steps_per_second': 11.056, 'epoch': 4.0}                                                                                                                       
{'loss': 0.0061, 'grad_norm': 0.44020789861679077, 'learning_rate': 3.784568967192572e-05, 'epoch': 4.55}                                                                                                
{'eval_loss': 0.009694033302366734, 'eval_precision': 0.934984520123839, 'eval_recall': 0.9320987654320988, 'eval_f1': 0.9335394126738794, 'eval_accuracy': 0.9955683809131196, 'eval_runtime': 1.8644, 'eval_samples_per_second': 173.781, 'eval_steps_per_second': 11.264, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0055, 'grad_norm': 0.35837098956108093, 'learning_rate': 3.33509521811982e-05, 'epoch': 5.2}                                                                                                  
{'loss': 0.0063, 'grad_norm': 0.05206337571144104, 'learning_rate': 2.8856214690470676e-05, 'epoch': 5.85}                                                                                               
{'eval_loss': 0.007340862415730953, 'eval_precision': 0.9537037037037037, 'eval_recall': 0.9537037037037037, 'eval_f1': 0.9537037037037037, 'eval_accuracy': 0.9969081727300835, 'eval_runtime': 1.8592, 'eval_samples_per_second': 174.264, 'eval_steps_per_second': 11.295, 'epoch': 6.0}                                                                                                                       
{'loss': 0.0022, 'grad_norm': 0.011129498481750488, 'learning_rate': 2.4361477199743157e-05, 'epoch': 6.5}                                                                                               
{'eval_loss': 0.00908869318664074, 'eval_precision': 0.9566563467492261, 'eval_recall': 0.9537037037037037, 'eval_f1': 0.955177743431221, 'eval_accuracy': 0.9970112336390807, 'eval_runtime': 1.8852, 'eval_samples_per_second': 171.861, 'eval_steps_per_second': 11.139, 'epoch': 7.0}                                                                                                                         
{'loss': 0.0017, 'grad_norm': 2.7910070419311523, 'learning_rate': 1.986673970901564e-05, 'epoch': 7.14}                                                                                                 
{'loss': 0.0022, 'grad_norm': 0.39954254031181335, 'learning_rate': 1.537200221828812e-05, 'epoch': 7.8}                                                                                                 
{'eval_loss': 0.005761478561908007, 'eval_precision': 0.9719626168224299, 'eval_recall': 0.9629629629629629, 'eval_f1': 0.9674418604651163, 'eval_accuracy': 0.9978357209110584, 'eval_runtime': 1.8448, 'eval_samples_per_second': 175.631, 'eval_steps_per_second': 11.383, 'epoch': 8.0}                                                                                                                       
{'loss': 0.0015, 'grad_norm': 0.06656600534915924, 'learning_rate': 1.0877264727560598e-05, 'epoch': 8.44}                                                                                               
{'eval_loss': 0.008581212721765041, 'eval_precision': 0.9748427672955975, 'eval_recall': 0.9567901234567902, 'eval_f1': 0.9657320872274143, 'eval_accuracy': 0.9977326600020612, 'eval_runtime': 1.8777, 'eval_samples_per_second': 172.548, 'eval_steps_per_second': 11.184, 'epoch': 9.0}                                                                                                                       
{'loss': 0.0006, 'grad_norm': 0.015308310277760029, 'learning_rate': 6.3825272368330785e-06, 'epoch': 9.09}                                                                                              
{'loss': 0.0002, 'grad_norm': 0.04458414390683174, 'learning_rate': 1.8877897461055583e-06, 'epoch': 9.75}                                                                                               
{'eval_loss': 0.00911839958280325, 'eval_precision': 0.9717868338557993, 'eval_recall': 0.9567901234567902, 'eval_f1': 0.9642301710730948, 'eval_accuracy': 0.997629599093064, 'eval_runtime': 1.8906, 'eval_samples_per_second': 171.37, 'eval_steps_per_second': 11.107, 'epoch': 10.0}                                                                                                                         
{'train_runtime': 452.4463, 'train_samples_per_second': 54.084, 'train_steps_per_second': 1.702, 'train_loss': 0.026348963941374866, 'epoch': 10.0}                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:32<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.20it/s]
[I 2025-11-08 03:16:19,284] Trial 11 finished with value: 0.9674418604651163 and parameters: {'lr': 5.6184218634094e-05, 'weight_decay': 0.04384439833949236, 'warmup_ratio': 0.1870910311780661, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 12/20 [2:09:07<1:03:49, 478.63s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.2275, 'grad_norm': 1.1442424058914185, 'learning_rate': 4.314672318103241e-05, 'epoch': 0.65}                                                                                                 
{'eval_loss': 0.03602024167776108, 'eval_precision': 0.8858447488584474, 'eval_recall': 0.5987654320987654, 'eval_f1': 0.714548802946593, 'eval_accuracy': 0.9840255591054313, 'eval_runtime': 1.881, 'eval_samples_per_second': 172.245, 'eval_steps_per_second': 11.164, 'epoch': 1.0}                                                                                                                          
{'loss': 0.0475, 'grad_norm': 0.6673410534858704, 'learning_rate': 8.71739917331063e-05, 'epoch': 1.3}                                                                                                   
{'loss': 0.0211, 'grad_norm': 0.18517136573791504, 'learning_rate': 8.729334276231372e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.018484748899936676, 'eval_precision': 0.9566787003610109, 'eval_recall': 0.8179012345679012, 'eval_f1': 0.8818635607321131, 'eval_accuracy': 0.9926826754611976, 'eval_runtime': 1.8534, 'eval_samples_per_second': 174.816, 'eval_steps_per_second': 11.331, 'epoch': 2.0}                                                                                                                       
{'loss': 0.0144, 'grad_norm': 0.34031012654304504, 'learning_rate': 8.026489326454289e-05, 'epoch': 2.6}                                                                                                 
{'eval_loss': 0.010722476989030838, 'eval_precision': 0.9590443686006825, 'eval_recall': 0.8672839506172839, 'eval_f1': 0.9108589951377634, 'eval_accuracy': 0.994331650005153, 'eval_runtime': 1.9175, 'eval_samples_per_second': 168.972, 'eval_steps_per_second': 10.952, 'epoch': 3.0}                                                                                                                        
{'loss': 0.0128, 'grad_norm': 0.18997609615325928, 'learning_rate': 7.323644376677206e-05, 'epoch': 3.25}                                                                                                
{'loss': 0.0086, 'grad_norm': 0.14991872012615204, 'learning_rate': 6.620799426900124e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.012211528606712818, 'eval_precision': 0.9413680781758957, 'eval_recall': 0.8919753086419753, 'eval_f1': 0.9160063391442155, 'eval_accuracy': 0.9945377718231475, 'eval_runtime': 1.8484, 'eval_samples_per_second': 175.288, 'eval_steps_per_second': 11.361, 'epoch': 4.0}                                                                                                                       
{'loss': 0.0071, 'grad_norm': 0.298639178276062, 'learning_rate': 5.9179544771230395e-05, 'epoch': 4.55}                                                                                                 
{'eval_loss': 0.005666709039360285, 'eval_precision': 0.9749216300940439, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9673405909797823, 'eval_accuracy': 0.9978357209110584, 'eval_runtime': 1.8676, 'eval_samples_per_second': 173.486, 'eval_steps_per_second': 11.244, 'epoch': 5.0}                                                                                                                       
{'loss': 0.0054, 'grad_norm': 0.06923982501029968, 'learning_rate': 5.215109527345956e-05, 'epoch': 5.2}                                                                                                 
{'loss': 0.0048, 'grad_norm': 0.24998869001865387, 'learning_rate': 4.5122645775688735e-05, 'epoch': 5.85}                                                                                               
{'eval_loss': 0.006663412321358919, 'eval_precision': 0.9620253164556962, 'eval_recall': 0.9382716049382716, 'eval_f1': 0.95, 'eval_accuracy': 0.9967020509120891, 'eval_runtime': 1.8646, 'eval_samples_per_second': 173.764, 'eval_steps_per_second': 11.262, 'epoch': 6.0}                                                                                                                                     
{'loss': 0.003, 'grad_norm': 1.0288022756576538, 'learning_rate': 3.809419627791791e-05, 'epoch': 6.5}                                                                                                   
{'eval_loss': 0.004283835645765066, 'eval_precision': 0.9841269841269841, 'eval_recall': 0.9567901234567902, 'eval_f1': 0.9702660406885759, 'eval_accuracy': 0.9980418427290528, 'eval_runtime': 1.8679, 'eval_samples_per_second': 173.461, 'eval_steps_per_second': 11.243, 'epoch': 7.0}                                                                                                                       
{'loss': 0.0022, 'grad_norm': 0.07019016146659851, 'learning_rate': 3.1065746780147074e-05, 'epoch': 7.14}                                                                                               
{'loss': 0.0013, 'grad_norm': 0.07962409406900406, 'learning_rate': 2.403729728237624e-05, 'epoch': 7.8}                                                                                                 
{'eval_loss': 0.004400326870381832, 'eval_precision': 0.9780564263322884, 'eval_recall': 0.9629629629629629, 'eval_f1': 0.9704510108864697, 'eval_accuracy': 0.9980418427290528, 'eval_runtime': 1.8902, 'eval_samples_per_second': 171.415, 'eval_steps_per_second': 11.11, 'epoch': 8.0}                                                                                                                        
{'loss': 0.0004, 'grad_norm': 0.0027605067007243633, 'learning_rate': 1.700884778460541e-05, 'epoch': 8.44}                                                                                              
{'eval_loss': 0.004140163771808147, 'eval_precision': 0.98125, 'eval_recall': 0.9691358024691358, 'eval_f1': 0.9751552795031055, 'eval_accuracy': 0.9983510254560445, 'eval_runtime': 1.8618, 'eval_samples_per_second': 174.022, 'eval_steps_per_second': 11.279, 'epoch': 9.0}                                                                                                                                  
{'loss': 0.0003, 'grad_norm': 0.00963857676833868, 'learning_rate': 9.98039828683458e-06, 'epoch': 9.09}                                                                                                 
{'loss': 0.0002, 'grad_norm': 0.011304983869194984, 'learning_rate': 2.951948789063749e-06, 'epoch': 9.75}                                                                                               
{'eval_loss': 0.004344651009887457, 'eval_precision': 0.9904458598726115, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9749216300940439, 'eval_accuracy': 0.9983510254560445, 'eval_runtime': 1.841, 'eval_samples_per_second': 175.996, 'eval_steps_per_second': 11.407, 'epoch': 10.0}                                                                                                                       
{'train_runtime': 452.7402, 'train_samples_per_second': 54.049, 'train_steps_per_second': 1.701, 'train_loss': 0.024832227243588294, 'epoch': 10.0}                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:32<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 15.78it/s]
[I 2025-11-08 03:23:54,679] Trial 12 finished with value: 0.9751552795031055 and parameters: {'lr': 9.333780933039664e-05, 'weight_decay': 0.04639239375736043, 'warmup_ratio': 0.1364754878013656, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                           | 13/20 [2:16:43<55:01, 471.59s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.2168, 'grad_norm': 3.625521659851074, 'learning_rate': 4.751940638416516e-05, 'epoch': 0.65}                                                                                                  
{'eval_loss': 0.04535488411784172, 'eval_precision': 0.9631901840490797, 'eval_recall': 0.4845679012345679, 'eval_f1': 0.6447638603696099, 'eval_accuracy': 0.9821704627434814, 'eval_runtime': 1.8839, 'eval_samples_per_second': 171.983, 'eval_steps_per_second': 11.147, 'epoch': 1.0}                                                                                                                        
{'loss': 0.0505, 'grad_norm': 0.5048646926879883, 'learning_rate': 9.600859657208879e-05, 'epoch': 1.3}                                                                                                  
{'loss': 0.0223, 'grad_norm': 0.15976004302501678, 'learning_rate': 8.988593166179277e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.012969263829290867, 'eval_precision': 0.9423728813559322, 'eval_recall': 0.8580246913580247, 'eval_f1': 0.8982229402261712, 'eval_accuracy': 0.9935071627331753, 'eval_runtime': 1.8743, 'eval_samples_per_second': 172.867, 'eval_steps_per_second': 11.204, 'epoch': 2.0}                                                                                                                       
{'loss': 0.011, 'grad_norm': 0.26531982421875, 'learning_rate': 8.264873909643103e-05, 'epoch': 2.6}                                                                                                     
{'eval_loss': 0.0070255170576274395, 'eval_precision': 0.9766666666666667, 'eval_recall': 0.904320987654321, 'eval_f1': 0.9391025641025641, 'eval_accuracy': 0.9960836854581058, 'eval_runtime': 1.8699, 'eval_samples_per_second': 173.274, 'eval_steps_per_second': 11.231, 'epoch': 3.0}                                                                                                                       
{'loss': 0.0102, 'grad_norm': 0.6299492120742798, 'learning_rate': 7.541154653106929e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0077, 'grad_norm': 0.047905392944812775, 'learning_rate': 6.817435396570755e-05, 'epoch': 3.9}                                                                                                
{'eval_loss': 0.008308188058435917, 'eval_precision': 0.9792387543252595, 'eval_recall': 0.8734567901234568, 'eval_f1': 0.9233278955954323, 'eval_accuracy': 0.9951561372771308, 'eval_runtime': 1.8514, 'eval_samples_per_second': 175.002, 'eval_steps_per_second': 11.343, 'epoch': 4.0}                                                                                                                       
{'loss': 0.0066, 'grad_norm': 0.36066940426826477, 'learning_rate': 6.0937161400345816e-05, 'epoch': 4.55}                                                                                               
{'eval_loss': 0.007929928600788116, 'eval_precision': 0.9446153846153846, 'eval_recall': 0.9475308641975309, 'eval_f1': 0.9460708782742681, 'eval_accuracy': 0.9963928681850974, 'eval_runtime': 1.8874, 'eval_samples_per_second': 171.661, 'eval_steps_per_second': 11.126, 'epoch': 5.0}                                                                                                                       
{'loss': 0.005, 'grad_norm': 0.06280754506587982, 'learning_rate': 5.369996883498408e-05, 'epoch': 5.2}                                                                                                  
{'loss': 0.0054, 'grad_norm': 0.1751643568277359, 'learning_rate': 4.646277626962235e-05, 'epoch': 5.85}                                                                                                 
{'eval_loss': 0.0069925375282764435, 'eval_precision': 0.9652996845425867, 'eval_recall': 0.9444444444444444, 'eval_f1': 0.9547581903276131, 'eval_accuracy': 0.9970112336390807, 'eval_runtime': 1.8998, 'eval_samples_per_second': 170.544, 'eval_steps_per_second': 11.054, 'epoch': 6.0}                                                                                                                      
{'loss': 0.0018, 'grad_norm': 0.023566020652651787, 'learning_rate': 3.922558370426061e-05, 'epoch': 6.5}                                                                                                
{'eval_loss': 0.0037157211918383837, 'eval_precision': 0.9781931464174455, 'eval_recall': 0.9691358024691358, 'eval_f1': 0.9736434108527132, 'eval_accuracy': 0.9982479645470473, 'eval_runtime': 1.8831, 'eval_samples_per_second': 172.055, 'eval_steps_per_second': 11.152, 'epoch': 7.0}                                                                                                                      
{'loss': 0.0015, 'grad_norm': 0.005319565534591675, 'learning_rate': 3.198839113889888e-05, 'epoch': 7.14}                                                                                               
{'loss': 0.0012, 'grad_norm': 0.028772754594683647, 'learning_rate': 2.475119857353714e-05, 'epoch': 7.8}                                                                                                
{'eval_loss': 0.0041912454180419445, 'eval_precision': 0.98125, 'eval_recall': 0.9691358024691358, 'eval_f1': 0.9751552795031055, 'eval_accuracy': 0.9983510254560445, 'eval_runtime': 1.8884, 'eval_samples_per_second': 171.573, 'eval_steps_per_second': 11.12, 'epoch': 8.0}                                                                                                                                  
{'loss': 0.0017, 'grad_norm': 0.009817833080887794, 'learning_rate': 1.75140060081754e-05, 'epoch': 8.44}                                                                                                
{'eval_loss': 0.006382194347679615, 'eval_precision': 0.9715189873417721, 'eval_recall': 0.9475308641975309, 'eval_f1': 0.959375, 'eval_accuracy': 0.9973204163660724, 'eval_runtime': 1.9018, 'eval_samples_per_second': 170.361, 'eval_steps_per_second': 11.042, 'epoch': 9.0}                                                                                                                                 
{'loss': 0.0007, 'grad_norm': 0.027944814413785934, 'learning_rate': 1.0276813442813665e-05, 'epoch': 9.09}                                                                                              
{'loss': 0.0002, 'grad_norm': 0.07119189202785492, 'learning_rate': 3.039620877451929e-06, 'epoch': 9.75}                                                                                                
{'eval_loss': 0.005586247891187668, 'eval_precision': 0.9810725552050473, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9703588143525741, 'eval_accuracy': 0.9980418427290528, 'eval_runtime': 1.8608, 'eval_samples_per_second': 174.121, 'eval_steps_per_second': 11.286, 'epoch': 10.0}                                                                                                                      
{'train_runtime': 452.6179, 'train_samples_per_second': 54.063, 'train_steps_per_second': 1.701, 'train_loss': 0.023938468893288406, 'epoch': 10.0}                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:32<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 15.78it/s]
[I 2025-11-08 03:31:29,979] Trial 13 finished with value: 0.9751552795031055 and parameters: {'lr': 9.697838037584727e-05, 'weight_decay': 0.03689345899179272, 'warmup_ratio': 0.12868042886989442, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                     | 14/20 [2:24:18<46:40, 466.67s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.2317, 'grad_norm': 0.5769002437591553, 'learning_rate': 3.8832055659132383e-05, 'epoch': 0.65}                                                                                                
{'eval_loss': 0.04265730455517769, 'eval_precision': 0.7946768060836502, 'eval_recall': 0.6450617283950617, 'eval_f1': 0.7120954003407155, 'eval_accuracy': 0.9825827063794703, 'eval_runtime': 1.9085, 'eval_samples_per_second': 169.771, 'eval_steps_per_second': 11.004, 'epoch': 1.0}                                                                                                                        
{'loss': 0.0444, 'grad_norm': 0.5973975658416748, 'learning_rate': 6.16534974203557e-05, 'epoch': 1.3}                                                                                                   
{'loss': 0.0184, 'grad_norm': 0.86285799741745, 'learning_rate': 5.705934709097003e-05, 'epoch': 1.95}                                                                                                   
{'eval_loss': 0.01741655357182026, 'eval_precision': 0.9140893470790378, 'eval_recall': 0.8209876543209876, 'eval_f1': 0.865040650406504, 'eval_accuracy': 0.991445944553231, 'eval_runtime': 1.9034, 'eval_samples_per_second': 170.225, 'eval_steps_per_second': 11.033, 'epoch': 2.0}                                                                                                                          
{'loss': 0.0122, 'grad_norm': 0.15566176176071167, 'learning_rate': 5.246519676158436e-05, 'epoch': 2.6}                                                                                                 
{'eval_loss': 0.013920662924647331, 'eval_precision': 0.9364548494983278, 'eval_recall': 0.8641975308641975, 'eval_f1': 0.898876404494382, 'eval_accuracy': 0.9935071627331753, 'eval_runtime': 1.8927, 'eval_samples_per_second': 171.183, 'eval_steps_per_second': 11.095, 'epoch': 3.0}                                                                                                                        
{'loss': 0.0083, 'grad_norm': 0.6470680236816406, 'learning_rate': 4.787104643219869e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0067, 'grad_norm': 0.2069912999868393, 'learning_rate': 4.3276896102813016e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.00571626890450716, 'eval_precision': 0.9838709677419355, 'eval_recall': 0.941358024691358, 'eval_f1': 0.9621451104100947, 'eval_accuracy': 0.9975265381840668, 'eval_runtime': 1.883, 'eval_samples_per_second': 172.068, 'eval_steps_per_second': 11.153, 'epoch': 4.0}                                                                                                                          
{'loss': 0.0044, 'grad_norm': 0.10056892037391663, 'learning_rate': 3.868274577342735e-05, 'epoch': 4.55}                                                                                                
{'eval_loss': 0.00659753056243062, 'eval_precision': 0.9619047619047619, 'eval_recall': 0.9351851851851852, 'eval_f1': 0.9483568075117371, 'eval_accuracy': 0.9965989900030918, 'eval_runtime': 1.8663, 'eval_samples_per_second': 173.603, 'eval_steps_per_second': 11.252, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0046, 'grad_norm': 0.1102982759475708, 'learning_rate': 3.408859544404167e-05, 'epoch': 5.2}                                                                                                  
{'loss': 0.0043, 'grad_norm': 0.16964906454086304, 'learning_rate': 2.9494445114656006e-05, 'epoch': 5.85}                                                                                               
{'eval_loss': 0.006248649209737778, 'eval_precision': 0.9711538461538461, 'eval_recall': 0.9351851851851852, 'eval_f1': 0.9528301886792453, 'eval_accuracy': 0.9969081727300835, 'eval_runtime': 1.9034, 'eval_samples_per_second': 170.223, 'eval_steps_per_second': 11.033, 'epoch': 6.0}                                                                                                                       
{'loss': 0.0017, 'grad_norm': 0.42945724725723267, 'learning_rate': 2.4900294785270333e-05, 'epoch': 6.5}                                                                                                
{'eval_loss': 0.004747181665152311, 'eval_precision': 0.9749216300940439, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9673405909797823, 'eval_accuracy': 0.9978357209110584, 'eval_runtime': 1.905, 'eval_samples_per_second': 170.079, 'eval_steps_per_second': 11.024, 'epoch': 7.0}                                                                                                                        
{'loss': 0.0017, 'grad_norm': 0.12449683994054794, 'learning_rate': 2.0306144455884664e-05, 'epoch': 7.14}                                                                                               
{'loss': 0.0006, 'grad_norm': 0.10111179202795029, 'learning_rate': 1.5711994126498995e-05, 'epoch': 7.8}                                                                                                
{'eval_loss': 0.0058636534959077835, 'eval_precision': 0.9811320754716981, 'eval_recall': 0.9629629629629629, 'eval_f1': 0.9719626168224299, 'eval_accuracy': 0.9981449036380501, 'eval_runtime': 1.8621, 'eval_samples_per_second': 174.001, 'eval_steps_per_second': 11.278, 'epoch': 8.0}                                                                                                                      
{'loss': 0.0004, 'grad_norm': 0.013955923728644848, 'learning_rate': 1.1117843797113323e-05, 'epoch': 8.44}                                                                                              
{'eval_loss': 0.006071175914257765, 'eval_precision': 0.9717868338557993, 'eval_recall': 0.9567901234567902, 'eval_f1': 0.9642301710730948, 'eval_accuracy': 0.997629599093064, 'eval_runtime': 1.8854, 'eval_samples_per_second': 171.844, 'eval_steps_per_second': 11.138, 'epoch': 9.0}                                                                                                                        
{'loss': 0.0002, 'grad_norm': 0.007295695133507252, 'learning_rate': 6.523693467727652e-06, 'epoch': 9.09}                                                                                               
{'loss': 0.0001, 'grad_norm': 0.016445111483335495, 'learning_rate': 1.929543138341982e-06, 'epoch': 9.75}                                                                                               
{'eval_loss': 0.006321118213236332, 'eval_precision': 0.9717868338557993, 'eval_recall': 0.9567901234567902, 'eval_f1': 0.9642301710730948, 'eval_accuracy': 0.997629599093064, 'eval_runtime': 1.8757, 'eval_samples_per_second': 172.738, 'eval_steps_per_second': 11.196, 'epoch': 10.0}                                                                                                                       
{'train_runtime': 452.8835, 'train_samples_per_second': 54.032, 'train_steps_per_second': 1.7, 'train_loss': 0.023724530115511944, 'epoch': 10.0}                                                        
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:32<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.15it/s]
[I 2025-11-08 03:39:05,530] Trial 14 finished with value: 0.9719626168224299 and parameters: {'lr': 6.339927454552226e-05, 'weight_decay': 0.023604863681832698, 'warmup_ratio': 0.10374605581806014, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                               | 15/20 [2:31:54<38:36, 463.32s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.3432, 'grad_norm': 1.1665382385253906, 'learning_rate': 1.34268332850119e-05, 'epoch': 0.65}                                                                                                  
{'eval_loss': 0.08493418991565704, 'eval_precision': 0.638095238095238, 'eval_recall': 0.41358024691358025, 'eval_f1': 0.50187265917603, 'eval_accuracy': 0.9725857982067402, 'eval_runtime': 1.8323, 'eval_samples_per_second': 176.823, 'eval_steps_per_second': 11.461, 'epoch': 1.0}                                                                                                                          
{'loss': 0.073, 'grad_norm': 0.685804009437561, 'learning_rate': 2.7127683575840368e-05, 'epoch': 1.3}                                                                                                   
{'loss': 0.0434, 'grad_norm': 0.7122721672058105, 'learning_rate': 4.082853386666884e-05, 'epoch': 1.95}                                                                                                 
{'eval_loss': 0.030625950545072556, 'eval_precision': 0.9233870967741935, 'eval_recall': 0.7067901234567902, 'eval_f1': 0.8006993006993007, 'eval_accuracy': 0.9882510563743172, 'eval_runtime': 1.8567, 'eval_samples_per_second': 174.5, 'eval_steps_per_second': 11.31, 'epoch': 2.0}                                                                                                                          
{'loss': 0.0269, 'grad_norm': 1.0757925510406494, 'learning_rate': 5.452938415749731e-05, 'epoch': 2.6}                                                                                                  
{'eval_loss': 0.01400856301188469, 'eval_precision': 0.9241379310344827, 'eval_recall': 0.8271604938271605, 'eval_f1': 0.8729641693811075, 'eval_accuracy': 0.991961249098217, 'eval_runtime': 1.8918, 'eval_samples_per_second': 171.267, 'eval_steps_per_second': 11.101, 'epoch': 3.0}                                                                                                                         
{'loss': 0.018, 'grad_norm': 0.6842853426933289, 'learning_rate': 6.080640334629538e-05, 'epoch': 3.25}                                                                                                  
{'loss': 0.0152, 'grad_norm': 0.483695924282074, 'learning_rate': 5.497085600020178e-05, 'epoch': 3.9}                                                                                                   
{'eval_loss': 0.019864855334162712, 'eval_precision': 0.8908450704225352, 'eval_recall': 0.7808641975308642, 'eval_f1': 0.8322368421052632, 'eval_accuracy': 0.9894877872822838, 'eval_runtime': 1.879, 'eval_samples_per_second': 172.43, 'eval_steps_per_second': 11.176, 'epoch': 4.0}                                                                                                                         
{'loss': 0.0107, 'grad_norm': 0.11413059383630753, 'learning_rate': 4.9135308654108175e-05, 'epoch': 4.55}                                                                                               
{'eval_loss': 0.006997487973421812, 'eval_precision': 0.9735973597359736, 'eval_recall': 0.9104938271604939, 'eval_f1': 0.9409888357256778, 'eval_accuracy': 0.9961867463671029, 'eval_runtime': 1.8844, 'eval_samples_per_second': 171.942, 'eval_steps_per_second': 11.144, 'epoch': 5.0}                                                                                                                       
{'loss': 0.0073, 'grad_norm': 0.24059288203716278, 'learning_rate': 4.329976130801456e-05, 'epoch': 5.2}                                                                                                 
{'loss': 0.0067, 'grad_norm': 0.13958270847797394, 'learning_rate': 3.746421396192096e-05, 'epoch': 5.85}                                                                                                
{'eval_loss': 0.008800442330539227, 'eval_precision': 0.9577922077922078, 'eval_recall': 0.9104938271604939, 'eval_f1': 0.9335443037974683, 'eval_accuracy': 0.9956714418221169, 'eval_runtime': 1.8928, 'eval_samples_per_second': 171.171, 'eval_steps_per_second': 11.094, 'epoch': 6.0}                                                                                                                       
{'loss': 0.0048, 'grad_norm': 0.122907854616642, 'learning_rate': 3.1628666615827354e-05, 'epoch': 6.5}                                                                                                  
{'eval_loss': 0.013637930154800415, 'eval_precision': 0.9411764705882353, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.9142857142857143, 'eval_accuracy': 0.9944347109141503, 'eval_runtime': 1.9018, 'eval_samples_per_second': 170.363, 'eval_steps_per_second': 11.042, 'epoch': 7.0}                                                                                                                       
{'loss': 0.0049, 'grad_norm': 0.8650350570678711, 'learning_rate': 2.5793119269733743e-05, 'epoch': 7.14}                                                                                                
{'loss': 0.0021, 'grad_norm': 0.05846940353512764, 'learning_rate': 1.9957571923640136e-05, 'epoch': 7.8}                                                                                                
{'eval_loss': 0.006676900666207075, 'eval_precision': 0.977491961414791, 'eval_recall': 0.9382716049382716, 'eval_f1': 0.9574803149606299, 'eval_accuracy': 0.9972173554570751, 'eval_runtime': 1.86, 'eval_samples_per_second': 174.196, 'eval_steps_per_second': 11.29, 'epoch': 8.0}                                                                                                                           
{'loss': 0.001, 'grad_norm': 0.031736988574266434, 'learning_rate': 1.4122024577546529e-05, 'epoch': 8.44}                                                                                               
{'eval_loss': 0.005384789779782295, 'eval_precision': 0.9808917197452229, 'eval_recall': 0.9506172839506173, 'eval_f1': 0.9655172413793104, 'eval_accuracy': 0.9977326600020612, 'eval_runtime': 1.8559, 'eval_samples_per_second': 174.574, 'eval_steps_per_second': 11.315, 'epoch': 9.0}                                                                                                                       
{'loss': 0.0007, 'grad_norm': 0.013196542859077454, 'learning_rate': 8.286477231452922e-06, 'epoch': 9.09}                                                                                               
{'loss': 0.0003, 'grad_norm': 0.025867171585559845, 'learning_rate': 2.450929885359315e-06, 'epoch': 9.75}                                                                                               
{'eval_loss': 0.006114346906542778, 'eval_precision': 0.9746031746031746, 'eval_recall': 0.9475308641975309, 'eval_f1': 0.9608763693270735, 'eval_accuracy': 0.9974234772750695, 'eval_runtime': 1.8708, 'eval_samples_per_second': 173.192, 'eval_steps_per_second': 11.225, 'epoch': 10.0}                                                                                                                      
{'train_runtime': 452.7627, 'train_samples_per_second': 54.046, 'train_steps_per_second': 1.701, 'train_loss': 0.03778266537626117, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:32<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 15.94it/s]
[I 2025-11-08 03:46:41,040] Trial 15 finished with value: 0.9655172413793104 and parameters: {'lr': 6.302391133781096e-05, 'weight_decay': 0.05606647368809439, 'warmup_ratio': 0.29764264890671366, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 16/20 [2:39:29<30:43, 460.97s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.2067, 'grad_norm': 0.2196061909198761, 'learning_rate': 6.229002046260305e-05, 'epoch': 0.65}                                                                                                 
{'eval_loss': 0.02861245535314083, 'eval_precision': 0.9080459770114943, 'eval_recall': 0.7314814814814815, 'eval_f1': 0.8102564102564103, 'eval_accuracy': 0.9885602391013089, 'eval_runtime': 1.9363, 'eval_samples_per_second': 167.328, 'eval_steps_per_second': 10.845, 'epoch': 1.0}                                                                                                                        
{'loss': 0.0379, 'grad_norm': 0.25677490234375, 'learning_rate': 7.338858488687157e-05, 'epoch': 1.3}                                                                                                    
{'loss': 0.0165, 'grad_norm': 0.9675071239471436, 'learning_rate': 6.791998690722391e-05, 'epoch': 1.95}                                                                                                 
{'eval_loss': 0.010930866934359074, 'eval_precision': 0.9790209790209791, 'eval_recall': 0.8641975308641975, 'eval_f1': 0.9180327868852459, 'eval_accuracy': 0.9948469545501392, 'eval_runtime': 1.9052, 'eval_samples_per_second': 170.065, 'eval_steps_per_second': 11.023, 'epoch': 2.0}                                                                                                                       
{'loss': 0.011, 'grad_norm': 1.2760827541351318, 'learning_rate': 6.245138892757625e-05, 'epoch': 2.6}                                                                                                   
{'eval_loss': 0.00948372296988964, 'eval_precision': 0.9536423841059603, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.9201277955271565, 'eval_accuracy': 0.9948469545501392, 'eval_runtime': 1.906, 'eval_samples_per_second': 169.985, 'eval_steps_per_second': 11.018, 'epoch': 3.0}                                                                                                                         
{'loss': 0.009, 'grad_norm': 0.6345376968383789, 'learning_rate': 5.69827909479286e-05, 'epoch': 3.25}                                                                                                   
{'loss': 0.0083, 'grad_norm': 0.19142360985279083, 'learning_rate': 5.151419296828094e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.008628052659332752, 'eval_precision': 0.941358024691358, 'eval_recall': 0.941358024691358, 'eval_f1': 0.941358024691358, 'eval_accuracy': 0.9960836854581058, 'eval_runtime': 1.9112, 'eval_samples_per_second': 169.524, 'eval_steps_per_second': 10.988, 'epoch': 4.0}                                                                                                                          
{'loss': 0.0046, 'grad_norm': 0.06417229026556015, 'learning_rate': 4.604559498863328e-05, 'epoch': 4.55}                                                                                                
{'eval_loss': 0.00891124363988638, 'eval_precision': 0.9668874172185431, 'eval_recall': 0.9012345679012346, 'eval_f1': 0.9329073482428115, 'eval_accuracy': 0.9956714418221169, 'eval_runtime': 1.8897, 'eval_samples_per_second': 171.452, 'eval_steps_per_second': 11.113, 'epoch': 5.0}                                                                                                                        
{'loss': 0.0079, 'grad_norm': 0.12924329936504364, 'learning_rate': 4.057699700898562e-05, 'epoch': 5.2}                                                                                                 
{'loss': 0.0025, 'grad_norm': 0.030346235260367393, 'learning_rate': 3.510839902933796e-05, 'epoch': 5.85}                                                                                               
{'eval_loss': 0.004312113393098116, 'eval_precision': 0.9719626168224299, 'eval_recall': 0.9629629629629629, 'eval_f1': 0.9674418604651163, 'eval_accuracy': 0.9978357209110584, 'eval_runtime': 1.8699, 'eval_samples_per_second': 173.271, 'eval_steps_per_second': 11.231, 'epoch': 6.0}                                                                                                                       
{'loss': 0.0064, 'grad_norm': 0.19715432822704315, 'learning_rate': 2.9639801049690307e-05, 'epoch': 6.5}                                                                                                
{'eval_loss': 0.003860680852085352, 'eval_precision': 0.9874213836477987, 'eval_recall': 0.9691358024691358, 'eval_f1': 0.9781931464174455, 'eval_accuracy': 0.998557147274039, 'eval_runtime': 1.9035, 'eval_samples_per_second': 170.211, 'eval_steps_per_second': 11.032, 'epoch': 7.0}                                                                                                                        
{'loss': 0.0016, 'grad_norm': 0.0013465993106365204, 'learning_rate': 2.417120307004265e-05, 'epoch': 7.14}                                                                                              
{'loss': 0.001, 'grad_norm': 0.1272096335887909, 'learning_rate': 1.870260509039499e-05, 'epoch': 7.8}                                                                                                   
{'eval_loss': 0.005097123794257641, 'eval_precision': 0.9873817034700315, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.9765990639625585, 'eval_accuracy': 0.9984540863650417, 'eval_runtime': 1.8776, 'eval_samples_per_second': 172.559, 'eval_steps_per_second': 11.184, 'epoch': 8.0}                                                                                                                       
{'loss': 0.0004, 'grad_norm': 0.008703213185071945, 'learning_rate': 1.3234007110747333e-05, 'epoch': 8.44}                                                                                              
{'eval_loss': 0.0038662354927510023, 'eval_precision': 0.990506329113924, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.978125, 'eval_accuracy': 0.998557147274039, 'eval_runtime': 1.8797, 'eval_samples_per_second': 172.364, 'eval_steps_per_second': 11.172, 'epoch': 9.0}                                                                                                                                  
{'loss': 0.0004, 'grad_norm': 0.011470537632703781, 'learning_rate': 7.765409131099673e-06, 'epoch': 9.09}                                                                                               
{'loss': 0.0002, 'grad_norm': 0.015372464433312416, 'learning_rate': 2.2968111514520163e-06, 'epoch': 9.75}                                                                                              
{'eval_loss': 0.004485678393393755, 'eval_precision': 0.9873817034700315, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.9765990639625585, 'eval_accuracy': 0.9984540863650417, 'eval_runtime': 1.8788, 'eval_samples_per_second': 172.45, 'eval_steps_per_second': 11.177, 'epoch': 10.0}                                                                                                                       
{'train_runtime': 452.8668, 'train_samples_per_second': 54.034, 'train_steps_per_second': 1.7, 'train_loss': 0.022112090704968657, 'epoch': 10.0}                                                        
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:32<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 15.95it/s]
[I 2025-11-08 03:54:16,637] Trial 16 finished with value: 0.9781931464174455 and parameters: {'lr': 7.754471935140379e-05, 'weight_decay': 0.0323128125454913, 'warmup_ratio': 0.07878495047606676, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 17/20 [2:47:05<22:58, 459.35s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.2131, 'grad_norm': 0.6741694211959839, 'learning_rate': 4.943971207754008e-05, 'epoch': 0.65}                                                                                                 
{'eval_loss': 0.03451550379395485, 'eval_precision': 0.9948453608247423, 'eval_recall': 0.595679012345679, 'eval_f1': 0.7451737451737451, 'eval_accuracy': 0.9863959600123673, 'eval_runtime': 1.8662, 'eval_samples_per_second': 173.615, 'eval_steps_per_second': 11.253, 'epoch': 1.0}                                                                                                                         
{'loss': 0.0391, 'grad_norm': 0.3469950556755066, 'learning_rate': 4.701537245469018e-05, 'epoch': 1.3}                                                                                                  
{'loss': 0.0199, 'grad_norm': 0.4271867275238037, 'learning_rate': 4.3511991496814614e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.014487626031041145, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9925796145522003, 'eval_runtime': 1.8899, 'eval_samples_per_second': 171.436, 'eval_steps_per_second': 11.112, 'epoch': 2.0}                                                                                                                       
{'loss': 0.0115, 'grad_norm': 0.2765466570854187, 'learning_rate': 4.0008610538939033e-05, 'epoch': 2.6}                                                                                                 
{'eval_loss': 0.007205256726592779, 'eval_precision': 0.9738562091503268, 'eval_recall': 0.9197530864197531, 'eval_f1': 0.946031746031746, 'eval_accuracy': 0.9964959290940946, 'eval_runtime': 1.8755, 'eval_samples_per_second': 172.751, 'eval_steps_per_second': 11.197, 'epoch': 3.0}                                                                                                                        
{'loss': 0.0091, 'grad_norm': 0.2786388695240021, 'learning_rate': 3.650522958106347e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0083, 'grad_norm': 4.944118499755859, 'learning_rate': 3.3001848623187894e-05, 'epoch': 3.9}                                                                                                  
{'eval_loss': 0.009841082617640495, 'eval_precision': 0.9451612903225807, 'eval_recall': 0.904320987654321, 'eval_f1': 0.9242902208201893, 'eval_accuracy': 0.9950530763681336, 'eval_runtime': 1.9345, 'eval_samples_per_second': 167.482, 'eval_steps_per_second': 10.855, 'epoch': 4.0}                                                                                                                        
{'loss': 0.0064, 'grad_norm': 0.08115016669034958, 'learning_rate': 2.949846766531232e-05, 'epoch': 4.55}                                                                                                
{'eval_loss': 0.0050706504844129086, 'eval_precision': 0.971875, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.9658385093167702, 'eval_accuracy': 0.9977326600020612, 'eval_runtime': 1.9738, 'eval_samples_per_second': 164.149, 'eval_steps_per_second': 10.639, 'epoch': 5.0}                                                                                                                                
{'loss': 0.0031, 'grad_norm': 0.13642250001430511, 'learning_rate': 2.5995086707436743e-05, 'epoch': 5.2}                                                                                                
{'loss': 0.0064, 'grad_norm': 0.07539591938257217, 'learning_rate': 2.2491705749561177e-05, 'epoch': 5.85}                                                                                               
{'eval_loss': 0.00605742959305644, 'eval_precision': 0.956386292834891, 'eval_recall': 0.9475308641975309, 'eval_f1': 0.951937984496124, 'eval_accuracy': 0.9968051118210862, 'eval_runtime': 1.8725, 'eval_samples_per_second': 173.03, 'eval_steps_per_second': 11.215, 'epoch': 6.0}                                                                                                                           
{'loss': 0.0023, 'grad_norm': 0.05296948179602623, 'learning_rate': 1.8988324791685603e-05, 'epoch': 6.5}                                                                                                
{'eval_loss': 0.006900009699165821, 'eval_precision': 0.9777070063694268, 'eval_recall': 0.9475308641975309, 'eval_f1': 0.9623824451410659, 'eval_accuracy': 0.9975265381840668, 'eval_runtime': 1.8778, 'eval_samples_per_second': 172.546, 'eval_steps_per_second': 11.184, 'epoch': 7.0}                                                                                                                       
{'loss': 0.0024, 'grad_norm': 0.013452799990773201, 'learning_rate': 1.548494383381003e-05, 'epoch': 7.14}                                                                                               
{'loss': 0.0011, 'grad_norm': 0.029452664777636528, 'learning_rate': 1.1981562875934457e-05, 'epoch': 7.8}                                                                                               
{'eval_loss': 0.006543712690472603, 'eval_precision': 0.9746031746031746, 'eval_recall': 0.9475308641975309, 'eval_f1': 0.9608763693270735, 'eval_accuracy': 0.9974234772750695, 'eval_runtime': 1.888, 'eval_samples_per_second': 171.606, 'eval_steps_per_second': 11.123, 'epoch': 8.0}                                                                                                                        
{'train_runtime': 362.2111, 'train_samples_per_second': 67.557, 'train_steps_per_second': 2.126, 'train_loss': 0.028333805419819114, 'epoch': 8.0}                                                       
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                | 616/770 [06:02<01:30,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 15.45it/s]
[I 2025-11-08 04:00:21,604] Trial 17 finished with value: 0.9658385093167702 and parameters: {'lr': 5.044868579340824e-05, 'weight_decay': 0.026275591839658604, 'warmup_ratio': 0.06479178943438976, 'batch_size': 8}. Best is trial 8 with value: 0.9796557120500783.
Best trial: 8. Best value: 0.979656:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 18/20 [2:53:10<14:21, 430.99s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 0.5604, 'grad_norm': 30.180463790893555, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                   
{'loss': 0.0999, 'grad_norm': 0.33393996953964233, 'learning_rate': 7.344192257402193e-05, 'epoch': 0.65}                                                                                                
{'eval_loss': 0.025067541748285294, 'eval_precision': 0.8576512455516014, 'eval_recall': 0.7438271604938271, 'eval_f1': 0.7966942148760331, 'eval_accuracy': 0.9873235081933422, 'eval_runtime': 1.8773, 'eval_samples_per_second': 172.587, 'eval_steps_per_second': 11.186, 'epoch': 1.0}                                                                                                                       
{'loss': 0.0316, 'grad_norm': 0.3040189743041992, 'learning_rate': 6.834886275612859e-05, 'epoch': 1.3}                                                                                                  
{'loss': 0.0187, 'grad_norm': 0.34550321102142334, 'learning_rate': 6.325580293823526e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.013979092240333557, 'eval_precision': 0.930921052631579, 'eval_recall': 0.8734567901234568, 'eval_f1': 0.9012738853503185, 'eval_accuracy': 0.9936102236421726, 'eval_runtime': 1.9025, 'eval_samples_per_second': 170.301, 'eval_steps_per_second': 11.038, 'epoch': 2.0}                                                                                                                        
{'loss': 0.0128, 'grad_norm': 0.5553922057151794, 'learning_rate': 5.816274312034192e-05, 'epoch': 2.6}                                                                                                  
{'eval_loss': 0.0064004105515778065, 'eval_precision': 0.9685534591194969, 'eval_recall': 0.9506172839506173, 'eval_f1': 0.9595015576323987, 'eval_accuracy': 0.9973204163660724, 'eval_runtime': 1.8834, 'eval_samples_per_second': 172.033, 'eval_steps_per_second': 11.15, 'epoch': 3.0}                                                                                                                       
{'loss': 0.0086, 'grad_norm': 0.29742905497550964, 'learning_rate': 5.3069683302448575e-05, 'epoch': 3.25}                                                                                               
{'loss': 0.0058, 'grad_norm': 0.12217039614915848, 'learning_rate': 4.797662348455524e-05, 'epoch': 3.9}                                                                                                 
{'eval_loss': 0.006711088586598635, 'eval_precision': 0.9898648648648649, 'eval_recall': 0.904320987654321, 'eval_f1': 0.9451612903225807, 'eval_accuracy': 0.9964959290940946, 'eval_runtime': 1.9146, 'eval_samples_per_second': 169.222, 'eval_steps_per_second': 10.968, 'epoch': 4.0}                                                                                                                        
{'loss': 0.0074, 'grad_norm': 0.9417201280593872, 'learning_rate': 4.28835636666619e-05, 'epoch': 4.55}                                                                                                  
{'eval_loss': 0.004127130843698978, 'eval_precision': 0.9841772151898734, 'eval_recall': 0.9598765432098766, 'eval_f1': 0.971875, 'eval_accuracy': 0.9981449036380501, 'eval_runtime': 1.8995, 'eval_samples_per_second': 170.574, 'eval_steps_per_second': 11.056, 'epoch': 5.0}                                                                                                                                 
{'loss': 0.0041, 'grad_norm': 0.043814633041620255, 'learning_rate': 3.7790503848768563e-05, 'epoch': 5.2}                                                                                               
{'loss': 0.0047, 'grad_norm': 0.16635769605636597, 'learning_rate': 3.269744403087523e-05, 'epoch': 5.85}                                                                                                
{'eval_loss': 0.004398277960717678, 'eval_precision': 0.9692307692307692, 'eval_recall': 0.9722222222222222, 'eval_f1': 0.9707241910631741, 'eval_accuracy': 0.9980418427290528, 'eval_runtime': 1.8761, 'eval_samples_per_second': 172.698, 'eval_steps_per_second': 11.193, 'epoch': 6.0}                                                                                                                       
{'loss': 0.0019, 'grad_norm': 0.020357241854071617, 'learning_rate': 2.760438421298189e-05, 'epoch': 6.5}                                                                                                
{'eval_loss': 0.00422768434509635, 'eval_precision': 0.978125, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.9720496894409938, 'eval_accuracy': 0.9981449036380501, 'eval_runtime': 1.8862, 'eval_samples_per_second': 171.775, 'eval_steps_per_second': 11.134, 'epoch': 7.0}                                                                                                                                  
{'loss': 0.0023, 'grad_norm': 0.003465148387476802, 'learning_rate': 2.2511324395088555e-05, 'epoch': 7.14}                                                                                              
{'loss': 0.0011, 'grad_norm': 0.03820185735821724, 'learning_rate': 1.7418264577195213e-05, 'epoch': 7.8}                                                                                                
{'eval_loss': 0.0048094382509589195, 'eval_precision': 0.9750778816199377, 'eval_recall': 0.9660493827160493, 'eval_f1': 0.9705426356589147, 'eval_accuracy': 0.9980418427290528, 'eval_runtime': 1.88, 'eval_samples_per_second': 172.344, 'eval_steps_per_second': 11.17, 'epoch': 8.0}                                                                                                                         
{'loss': 0.0006, 'grad_norm': 0.004278091248124838, 'learning_rate': 1.2325204759301878e-05, 'epoch': 8.44}                                                                                              
{'eval_loss': 0.0031889225356280804, 'eval_precision': 0.9844236760124611, 'eval_recall': 0.9753086419753086, 'eval_f1': 0.9798449612403101, 'eval_accuracy': 0.9986602081830361, 'eval_runtime': 1.8581, 'eval_samples_per_second': 174.372, 'eval_steps_per_second': 11.302, 'epoch': 9.0}                                                                                                                      
{'loss': 0.0003, 'grad_norm': 0.011458320543169975, 'learning_rate': 7.232144941408539e-06, 'epoch': 9.09}                                                                                               
{'loss': 0.0002, 'grad_norm': 0.005458345636725426, 'learning_rate': 2.1390851235152018e-06, 'epoch': 9.75}                                                                                              
{'eval_loss': 0.0036246702075004578, 'eval_precision': 0.9813084112149533, 'eval_recall': 0.9722222222222222, 'eval_f1': 0.9767441860465116, 'eval_accuracy': 0.9984540863650417, 'eval_runtime': 1.8646, 'eval_samples_per_second': 173.76, 'eval_steps_per_second': 11.262, 'epoch': 10.0}                                                                                                                      
{'train_runtime': 453.0788, 'train_samples_per_second': 54.008, 'train_steps_per_second': 1.699, 'train_loss': 0.013573872348801657, 'epoch': 10.0}                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:33<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.18it/s]
[I 2025-11-08 04:07:57,367] Trial 18 finished with value: 0.9798449612403101 and parameters: {'lr': 7.75163704283366e-05, 'weight_decay': 0.004977175505480186, 'warmup_ratio': 0.010851577853849617, 'batch_size': 8}. Best is trial 18 with value: 0.9798449612403101.
Best trial: 18. Best value: 0.979845:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 19/20 [3:00:45<07:18, 438.43s/it]Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.4604, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.05}                                                                                                                                  
{'eval_loss': 0.07257027924060822, 'eval_precision': 0.5748792270531401, 'eval_recall': 0.36728395061728397, 'eval_f1': 0.448210922787194, 'eval_accuracy': 0.9698031536638153, 'eval_runtime': 1.6812, 'eval_samples_per_second': 192.715, 'eval_steps_per_second': 3.569, 'epoch': 1.0}                                                                                                                         
{'eval_loss': 0.06110584735870361, 'eval_precision': 0.8278145695364238, 'eval_recall': 0.38580246913580246, 'eval_f1': 0.5263157894736842, 'eval_accuracy': 0.9768112954756261, 'eval_runtime': 1.6954, 'eval_samples_per_second': 191.102, 'eval_steps_per_second': 3.539, 'epoch': 2.0}                                                                                                                        
{'loss': 0.1087, 'grad_norm': 0.8956701159477234, 'learning_rate': 3.2889253514228005e-05, 'epoch': 2.52}                                                                                                
{'eval_loss': 0.045214105397462845, 'eval_precision': 0.6923076923076923, 'eval_recall': 0.6944444444444444, 'eval_f1': 0.6933744221879815, 'eval_accuracy': 0.9794908791095538, 'eval_runtime': 1.6813, 'eval_samples_per_second': 192.712, 'eval_steps_per_second': 3.569, 'epoch': 3.0}                                                                                                                        
{'eval_loss': 0.020271381363272667, 'eval_precision': 0.900990099009901, 'eval_recall': 0.8425925925925926, 'eval_f1': 0.8708133971291866, 'eval_accuracy': 0.9916520663712254, 'eval_runtime': 1.6939, 'eval_samples_per_second': 191.274, 'eval_steps_per_second': 3.542, 'epoch': 4.0}                                                                                                                         
{'loss': 0.0244, 'grad_norm': 0.36503735184669495, 'learning_rate': 2.1998772218126017e-05, 'epoch': 5.0}                                                                                                
{'eval_loss': 0.02587042935192585, 'eval_precision': 0.8842105263157894, 'eval_recall': 0.7777777777777778, 'eval_f1': 0.8275862068965517, 'eval_accuracy': 0.9891786045552922, 'eval_runtime': 1.6581, 'eval_samples_per_second': 195.404, 'eval_steps_per_second': 3.619, 'epoch': 5.0}                                                                                                                         
{'eval_loss': 0.017674904316663742, 'eval_precision': 0.9271523178807947, 'eval_recall': 0.8641975308641975, 'eval_f1': 0.8945686900958466, 'eval_accuracy': 0.9931979800061836, 'eval_runtime': 1.7025, 'eval_samples_per_second': 190.304, 'eval_steps_per_second': 3.524, 'epoch': 6.0}                                                                                                                        
{'eval_loss': 0.013956275768578053, 'eval_precision': 0.9337539432176656, 'eval_recall': 0.9135802469135802, 'eval_f1': 0.9235569422776911, 'eval_accuracy': 0.9949500154591363, 'eval_runtime': 1.6881, 'eval_samples_per_second': 191.934, 'eval_steps_per_second': 3.554, 'epoch': 7.0}                                                                                                                        
{'loss': 0.009, 'grad_norm': 0.7834632396697998, 'learning_rate': 1.110829092202403e-05, 'epoch': 7.52}                                                                                                  
{'eval_loss': 0.01270048413425684, 'eval_precision': 0.9376947040498442, 'eval_recall': 0.9290123456790124, 'eval_f1': 0.9333333333333333, 'eval_accuracy': 0.9955683809131196, 'eval_runtime': 1.7121, 'eval_samples_per_second': 189.24, 'eval_steps_per_second': 3.504, 'epoch': 8.0}                                                                                                                          
{'eval_loss': 0.01127571240067482, 'eval_precision': 0.9589905362776026, 'eval_recall': 0.9382716049382716, 'eval_f1': 0.9485179407176287, 'eval_accuracy': 0.9965989900030918, 'eval_runtime': 1.6983, 'eval_samples_per_second': 190.784, 'eval_steps_per_second': 3.533, 'epoch': 9.0}                                                                                                                         
{'loss': 0.0037, 'grad_norm': 0.48413243889808655, 'learning_rate': 2.1780962592203976e-07, 'epoch': 10.0}                                                                                               
{'eval_loss': 0.011080438271164894, 'eval_precision': 0.9528301886792453, 'eval_recall': 0.9351851851851852, 'eval_f1': 0.9439252336448598, 'eval_accuracy': 0.9962898072761002, 'eval_runtime': 1.6631, 'eval_samples_per_second': 194.818, 'eval_steps_per_second': 3.608, 'epoch': 10.0}                                                                                                                       
{'train_runtime': 385.167, 'train_samples_per_second': 63.531, 'train_steps_per_second': 0.519, 'train_loss': 0.043184915035963056, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [06:25<00:00,  1.93s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.22it/s]
[I 2025-11-08 04:14:25,046] Trial 19 finished with value: 0.9485179407176287 and parameters: {'lr': 4.290849630664184e-05, 'weight_decay': 0.001128427949064613, 'warmup_ratio': 0.010046171996490383, 'batch_size': 32}. Best is trial 18 with value: 0.9798449612403101.
Best trial: 18. Best value: 0.979845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [3:07:13<00:00, 561.68s/it]

Best params: {'lr': 7.75163704283366e-05, 'weight_decay': 0.004977175505480186, 'warmup_ratio': 0.010851577853849617, 'batch_size': 8}
Best F1: 0.9798

Training final model for ModernBERT-base...
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /workspace/wandb/run-20251108_041425-3g2rr1jh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ModernBERT-base_final
wandb: â­ï¸ View project at https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder
wandb: ðŸš€ View run at https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder/runs/3g2rr1jh
Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'loss': 1.5126, 'grad_norm': inf, 'learning_rate': 0.0, 'epoch': 0.01}                                                                                                                                  
{'loss': 0.2489, 'grad_norm': 0.49325960874557495, 'learning_rate': 3.181818181818182e-05, 'epoch': 0.65}                                                                                                
{'eval_loss': 0.0419943705201149, 'eval_precision': 0.869198312236287, 'eval_recall': 0.6358024691358025, 'eval_f1': 0.7344028520499108, 'eval_accuracy': 0.9846439245594146, 'eval_runtime': 1.9031, 'eval_samples_per_second': 170.247, 'eval_steps_per_second': 11.034, 'epoch': 1.0}                                                                                                                          
{'loss': 0.0475, 'grad_norm': 0.30009010434150696, 'learning_rate': 4.841269841269841e-05, 'epoch': 1.3}                                                                                                 
{'loss': 0.0174, 'grad_norm': 0.3441453278064728, 'learning_rate': 4.4805194805194805e-05, 'epoch': 1.95}                                                                                                
{'eval_loss': 0.011432218365371227, 'eval_precision': 0.9623287671232876, 'eval_recall': 0.8672839506172839, 'eval_f1': 0.9123376623376623, 'eval_accuracy': 0.9944347109141503, 'eval_runtime': 1.9093, 'eval_samples_per_second': 169.698, 'eval_steps_per_second': 10.999, 'epoch': 2.0}                                                                                                                       
{'loss': 0.0092, 'grad_norm': 1.4979723691940308, 'learning_rate': 4.1197691197691204e-05, 'epoch': 2.6}                                                                                                 
{'eval_loss': 0.00851494912058115, 'eval_precision': 0.9671052631578947, 'eval_recall': 0.9074074074074074, 'eval_f1': 0.9363057324840764, 'eval_accuracy': 0.9958775636401113, 'eval_runtime': 1.8876, 'eval_samples_per_second': 171.647, 'eval_steps_per_second': 11.125, 'epoch': 3.0}                                                                                                                        
{'loss': 0.0094, 'grad_norm': 0.3561115860939026, 'learning_rate': 3.759018759018759e-05, 'epoch': 3.25}                                                                                                 
{'loss': 0.0061, 'grad_norm': 0.5444101095199585, 'learning_rate': 3.398268398268398e-05, 'epoch': 3.9}                                                                                                  
{'eval_loss': 0.004620914813131094, 'eval_precision': 0.9871794871794872, 'eval_recall': 0.9506172839506173, 'eval_f1': 0.9685534591194969, 'eval_accuracy': 0.9979387818200557, 'eval_runtime': 1.8794, 'eval_samples_per_second': 172.396, 'eval_steps_per_second': 11.174, 'epoch': 4.0}                                                                                                                       
{'loss': 0.0058, 'grad_norm': 0.38761770725250244, 'learning_rate': 3.0375180375180378e-05, 'epoch': 4.55}                                                                                               
{'eval_loss': 0.004120070952922106, 'eval_precision': 0.9751552795031055, 'eval_recall': 0.9691358024691358, 'eval_f1': 0.9721362229102167, 'eval_accuracy': 0.9981449036380501, 'eval_runtime': 1.8907, 'eval_samples_per_second': 171.363, 'eval_steps_per_second': 11.107, 'epoch': 5.0}                                                                                                                       
{'loss': 0.0032, 'grad_norm': 0.01267165131866932, 'learning_rate': 2.676767676767677e-05, 'epoch': 5.2}                                                                                                 
{'loss': 0.0029, 'grad_norm': 0.2468048483133316, 'learning_rate': 2.3160173160173163e-05, 'epoch': 5.85}                                                                                                
{'eval_loss': 0.005075548775494099, 'eval_precision': 0.9627329192546584, 'eval_recall': 0.9567901234567902, 'eval_f1': 0.9597523219814241, 'eval_accuracy': 0.9973204163660724, 'eval_runtime': 1.8687, 'eval_samples_per_second': 173.379, 'eval_steps_per_second': 11.238, 'epoch': 6.0}                                                                                                                       
{'loss': 0.0024, 'grad_norm': 0.36288881301879883, 'learning_rate': 1.9552669552669552e-05, 'epoch': 6.5}                                                                                                
{'eval_loss': 0.0032651887740939856, 'eval_precision': 0.9937304075235109, 'eval_recall': 0.9783950617283951, 'eval_f1': 0.9860031104199067, 'eval_accuracy': 0.999072451819025, 'eval_runtime': 1.8933, 'eval_samples_per_second': 171.128, 'eval_steps_per_second': 11.092, 'epoch': 7.0}                                                                                                                       
{'loss': 0.001, 'grad_norm': 0.000737135240342468, 'learning_rate': 1.5945165945165948e-05, 'epoch': 7.14}                                                                                               
{'loss': 0.0015, 'grad_norm': 0.10336069762706757, 'learning_rate': 1.2337662337662339e-05, 'epoch': 7.8}                                                                                                
{'eval_loss': 0.003667749697342515, 'eval_precision': 0.987460815047022, 'eval_recall': 0.9722222222222222, 'eval_f1': 0.9797822706065319, 'eval_accuracy': 0.9986602081830361, 'eval_runtime': 1.9248, 'eval_samples_per_second': 168.333, 'eval_steps_per_second': 10.91, 'epoch': 8.0}                                                                                                                         
{'loss': 0.0006, 'grad_norm': 0.0018989163218066096, 'learning_rate': 8.73015873015873e-06, 'epoch': 8.44}                                                                                               
{'eval_loss': 0.0030928743071854115, 'eval_precision': 0.9875776397515528, 'eval_recall': 0.9814814814814815, 'eval_f1': 0.9845201238390093, 'eval_accuracy': 0.9989693909100278, 'eval_runtime': 1.9005, 'eval_samples_per_second': 170.482, 'eval_steps_per_second': 11.05, 'epoch': 9.0}                                                                                                                       
{'loss': 0.0004, 'grad_norm': 0.02151804231107235, 'learning_rate': 5.122655122655123e-06, 'epoch': 9.09}                                                                                                
{'loss': 0.0002, 'grad_norm': 0.013604472391307354, 'learning_rate': 1.5151515151515152e-06, 'epoch': 9.75}                                                                                              
{'eval_loss': 0.0044084410183131695, 'eval_precision': 0.984375, 'eval_recall': 0.9722222222222222, 'eval_f1': 0.9782608695652174, 'eval_accuracy': 0.998557147274039, 'eval_runtime': 1.917, 'eval_samples_per_second': 169.016, 'eval_steps_per_second': 10.955, 'epoch': 10.0}                                                                                                                                 
{'train_runtime': 452.5048, 'train_samples_per_second': 54.077, 'train_steps_per_second': 1.702, 'train_loss': 0.02479785777652612, 'epoch': 10.0}                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 770/770 [07:32<00:00,  1.70it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 15.68it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 16.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:01<00:00, 16.07it/s]

ModernBERT-base Results:
  Dev F1: 0.9860
  Dev Acc: 0.9991
  OOD F1: 0.8229
  OOD Acc: 0.9802
wandb: 
wandb: Run history:
wandb:   ModernBERT-base/best_batch_size â–
wandb:           ModernBERT-base/best_lr â–
wandb: ModernBERT-base/best_warmup_ratio â–
wandb: ModernBERT-base/best_weight_decay â–
wandb:      ModernBERT-base/dev_accuracy â–
wandb:            ModernBERT-base/dev_f1 â–
wandb:     ModernBERT-base/dev_precision â–
wandb:        ModernBERT-base/dev_recall â–
wandb:      ModernBERT-base/ood_accuracy â–
wandb:            ModernBERT-base/ood_f1 â–
wandb:                               +15 ...
wandb: 
wandb: Run summary:
wandb:   ModernBERT-base/best_batch_size 8
wandb:           ModernBERT-base/best_lr 8e-05
wandb: ModernBERT-base/best_warmup_ratio 0.01085
wandb: ModernBERT-base/best_weight_decay 0.00498
wandb:      ModernBERT-base/dev_accuracy 0.99907
wandb:            ModernBERT-base/dev_f1 0.986
wandb:     ModernBERT-base/dev_precision 0.99373
wandb:        ModernBERT-base/dev_recall 0.9784
wandb:      ModernBERT-base/ood_accuracy 0.98017
wandb:            ModernBERT-base/ood_f1 0.82286
wandb:                               +20 ...
wandb: 
wandb: ðŸš€ View run ModernBERT-base_final at: https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder/runs/3g2rr1jh
wandb: â­ï¸ View project at: https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251108_041425-3g2rr1jh/logs

================================================================================
FINAL RESULTS
================================================================================
                      Model   Dev F1  Dev Acc   OOD F1  OOD Acc  Best LR  Best WD
bert-base-italian-xxl-cased 0.834921 0.990959 0.677778 0.962892 0.000025 0.080062
            ModernBERT-base 0.986003 0.999072 0.822857 0.980166 0.000078 0.004977
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /workspace/wandb/run-20251108_042205-9bm8ev0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run final_summary
wandb: â­ï¸ View project at https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder
wandb: ðŸš€ View run at https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder/runs/9bm8ev0a
wandb: ðŸš€ View run final_summary at: https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder/runs/9bm8ev0a
wandb: â­ï¸ View project at: https://wandb.ai/architk2003-sapienza-universit-di-roma/sentence_splitting_encoder
wandb: Synced 4 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251108_042205-9bm8ev0a/logs

âœ… Complete! Results in 